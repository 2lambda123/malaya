{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malaya provided basic interface for XLNET, specific to Malay language, we called it [XLNET-Bahasa](https://github.com/huseinzol05/Malaya/tree/master/xlnet). This interface not able us to use it to do custom training.\n",
    "\n",
    "If you want to download pretrained model for [XLNET-Bahasa](https://github.com/huseinzol05/Malaya/tree/master/xlnet) and use it for custom transfer-learning, you can download it here, https://github.com/huseinzol05/Malaya/tree/master/xlnet, some notebooks to help you get started,\n",
    "\n",
    "1. [Text classification](https://github.com/huseinzol05/Malaya/tree/master/xlnet/finetune-subjectivity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why XLNET\n",
    "\n",
    "1. Transformer model learn the context of a word based on all of its surroundings (live string), bidirectionally. So it much better understand left and right hand side relationships, plus permutation combination of the sentence to understand more about the context.\n",
    "2. Because of transformer able to leverage to context during live string, we dont need to capture available words in this world, instead capture substrings and build the attention after that. XLNET will never have Out-Of-Vocab problem.\n",
    "3. XLNET achieved new state-of-art for modern NLP and able to outperform BERT, you can read more about the benchmark [here](https://github.com/zihangdai/xlnet#results-on-reading-comprehension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.97 s, sys: 1.63 s, total: 7.6 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list XLNET-Bahasa available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base', 'small']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.xlnet.available_xlnet_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `base` is pretrained model size `BASE` trained on malay language, released by Malaya.\n",
    "2. `small` is pretrained model size `SMALL` trained on malay language, released by Malaya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load XLNET-Bahasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 19:02:47.416335 4414723520 deprecation_wrapper.py:119] From /Users/huseinzol/Documents/Malaya/malaya/_xlnet/xlnet.py:70: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0806 19:02:47.421904 4414723520 deprecation_wrapper.py:119] From /Users/huseinzol/Documents/Malaya/malaya/xlnet.py:62: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 19:02:47.439782 4414723520 deprecation_wrapper.py:119] From /Users/huseinzol/Documents/Malaya/malaya/_xlnet/xlnet.py:253: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0806 19:02:47.441549 4414723520 deprecation_wrapper.py:119] From /Users/huseinzol/Documents/Malaya/malaya/_xlnet/xlnet.py:253: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0806 19:02:47.449923 4414723520 deprecation_wrapper.py:119] From /Users/huseinzol/Documents/Malaya/malaya/_xlnet/modeling.py:686: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0806 19:02:47.453914 4414723520 deprecation_wrapper.py:119] From /Users/huseinzol/Documents/Malaya/malaya/_xlnet/modeling.py:693: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0806 19:02:47.568154 4414723520 deprecation.py:323] From /Users/huseinzol/Documents/Malaya/malaya/_xlnet/modeling.py:797: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0806 19:02:49.158231 4414723520 deprecation.py:323] From /Users/huseinzol/Documents/Malaya/malaya/_xlnet/modeling.py:99: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0806 19:02:59.735135 4414723520 deprecation_wrapper.py:119] From /Users/huseinzol/Documents/Malaya/malaya/xlnet.py:75: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "W0806 19:03:01.226956 4414723520 deprecation_wrapper.py:119] From /Users/huseinzol/Documents/Malaya/malaya/xlnet.py:81: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0806 19:03:01.715428 4414723520 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 1.83 s, total: 15.5 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = malaya.xlnet.xlnet(model = 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ['Kerajaan galakkan rakyat naik public transport tapi parking kat lrt ada 15. Reserved utk staff rapid je dah berpuluh. Park kereta tepi jalan kang kene saman dgn majlis perbandaran. Kereta pulak senang kene curi. Cctv pun tak ada. Naik grab dah 5-10 ringgit tiap hari. Gampang juga',\n",
    "           'Alaa Tun lek ahhh npe muka masam cmni kn agong kata usaha kerajaan terdahulu sejak selepas merdeka',\n",
    "           \"Orang ramai cakap nurse kerajaan garang. So i tell u this. Most of our local ppl will treat us as hamba abdi and they don't respect us as a nurse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have random sentences copied from Twitter, searched using `kerajan` keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = model.vectorize(strings)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Vector size for `base` is 512.\n",
    "2. Vector size for `small` is 256."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention\n",
    "\n",
    "Attention is to get which part of the sentence give the impact. Method available for attention,\n",
    "\n",
    "* ``'last'`` - attention from last layer.\n",
    "* ``'first'`` - attention from first layer.\n",
    "* ``'mean'`` - average attentions from all layers.\n",
    "\n",
    "You can give list of strings or a string to get the attention, in this documentation, I just want to use a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.042688485),\n",
       "  ('Tun', 0.057717055),\n",
       "  ('lek', 0.06485453),\n",
       "  ('ahhh', 0.045797937),\n",
       "  ('npe', 0.07240139),\n",
       "  ('muka', 0.06268131),\n",
       "  ('masam', 0.045819648),\n",
       "  ('cmni', 0.06796275),\n",
       "  ('kn', 0.100742154),\n",
       "  ('agong', 0.10299317),\n",
       "  ('kata', 0.084064975),\n",
       "  ('usaha', 0.035359822),\n",
       "  ('kerajaan', 0.030469837),\n",
       "  ('terdahulu', 0.04009748),\n",
       "  ('sejak', 0.049386293),\n",
       "  ('selepas', 0.049373068),\n",
       "  ('merdeka', 0.04759017)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention(strings[1], method = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.0208059),\n",
       "  ('Tun', 0.02863956),\n",
       "  ('lek', 0.03288769),\n",
       "  ('ahhh', 0.053664364),\n",
       "  ('npe', 0.060574025),\n",
       "  ('muka', 0.06008208),\n",
       "  ('masam', 0.071261086),\n",
       "  ('cmni', 0.05584477),\n",
       "  ('kn', 0.062477697),\n",
       "  ('agong', 0.050815508),\n",
       "  ('kata', 0.06935718),\n",
       "  ('usaha', 0.06918364),\n",
       "  ('kerajaan', 0.07442247),\n",
       "  ('terdahulu', 0.06999181),\n",
       "  ('sejak', 0.077083915),\n",
       "  ('selepas', 0.07548738),\n",
       "  ('merdeka', 0.067420855)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention(strings[1], method = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.06647704),\n",
       "  ('Tun', 0.05647921),\n",
       "  ('lek', 0.0548396),\n",
       "  ('ahhh', 0.062701255),\n",
       "  ('npe', 0.055179868),\n",
       "  ('muka', 0.054572195),\n",
       "  ('masam', 0.054664183),\n",
       "  ('cmni', 0.06586684),\n",
       "  ('kn', 0.056376744),\n",
       "  ('agong', 0.06807073),\n",
       "  ('kata', 0.06906264),\n",
       "  ('usaha', 0.057989392),\n",
       "  ('kerajaan', 0.05028565),\n",
       "  ('terdahulu', 0.054037325),\n",
       "  ('sejak', 0.06337146),\n",
       "  ('selepas', 0.05514585),\n",
       "  ('merdeka', 0.054879967)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention(strings[1], method = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

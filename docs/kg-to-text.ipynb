{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End\n",
    "\n",
    "Generate EN Knowledge Graph Triples format -> MS text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [Malaya/example/kg-to-text](https://github.com/huseinzol05/Malaya/tree/master/example/kg-to-text).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "This module only trained on standard language structure, so it is not save to use it for local language structure.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "This input must be an english knowledge graph triples format.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.59 s, sys: 3.04 s, total: 6.64 s\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available HuggingFace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:malaya.kg_to_text:tested on test set 02 part translated KELM, https://huggingface.co/datasets/mesolitica/translated-KELM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>SacreBLEU Verbose</th>\n",
       "      <th>Suggested length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-ttkg-t5-tiny-standard-bahasa-cased</th>\n",
       "      <td>139</td>\n",
       "      <td>61.067843</td>\n",
       "      <td>86.1/68.4/55.8/45.9 (BP = 0.980 ratio = 0.980 ...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-ttkg-t5-small-standard-bahasa-cased</th>\n",
       "      <td>242</td>\n",
       "      <td>61.559203</td>\n",
       "      <td>86.0/68.4/56.1/46.3 (BP = 0.984 ratio = 0.984 ...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-ttkg-t5-base-standard-bahasa-cased</th>\n",
       "      <td>892</td>\n",
       "      <td>58.764876</td>\n",
       "      <td>84.5/65.8/53.0/43.1 (BP = 0.984 ratio = 0.985 ...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Size (MB)       BLEU  \\\n",
       "mesolitica/finetune-ttkg-t5-tiny-standard-bahas...       139  61.067843   \n",
       "mesolitica/finetune-ttkg-t5-small-standard-baha...       242  61.559203   \n",
       "mesolitica/finetune-ttkg-t5-base-standard-bahas...       892  58.764876   \n",
       "\n",
       "                                                                                    SacreBLEU Verbose  \\\n",
       "mesolitica/finetune-ttkg-t5-tiny-standard-bahas...  86.1/68.4/55.8/45.9 (BP = 0.980 ratio = 0.980 ...   \n",
       "mesolitica/finetune-ttkg-t5-small-standard-baha...  86.0/68.4/56.1/46.3 (BP = 0.984 ratio = 0.984 ...   \n",
       "mesolitica/finetune-ttkg-t5-base-standard-bahas...  84.5/65.8/53.0/43.1 (BP = 0.984 ratio = 0.985 ...   \n",
       "\n",
       "                                                   Suggested length  \n",
       "mesolitica/finetune-ttkg-t5-tiny-standard-bahas...              256  \n",
       "mesolitica/finetune-ttkg-t5-small-standard-baha...              256  \n",
       "mesolitica/finetune-ttkg-t5-base-standard-bahas...              256  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.kg_to_text.available_huggingface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HuggingFace model\n",
    "\n",
    "```python\n",
    "def huggingface(model: str = 'mesolitica/finetune-ttkg-t5-small-standard-bahasa-cased', **kwargs):\n",
    "    \"\"\"\n",
    "    Load HuggingFace model to knowledge graph to text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: str, optional (default='mesolitica/finetune-ttkg-t5-small-standard-bahasa-cased')\n",
    "        Check available models at `malaya.kg_to_text.available_huggingface()`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: malaya.torch_model.huggingface.KGtoText\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttkg = malaya.text_to_kg.e2e.huggingface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = malaya.kg_to_text.huggingface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = \"Yang Berhormat Dato Sri Haji Mohammad Najib bin Tun Haji Abdul Razak ialah ahli politik Malaysia dan merupakan bekas Perdana Menteri Malaysia ke-6 yang mana beliau menjawat jawatan dari 3 April 2009 hingga 9 Mei 2018. Beliau juga pernah berkhidmat sebagai bekas Menteri Kewangan dan merupakan Ahli Parlimen Pekan Pahang\"\n",
    "string2 = \"Pahang ialah negeri yang ketiga terbesar di Malaysia Terletak di lembangan Sungai Pahang yang amat luas negeri Pahang bersempadan dengan Kelantan di utara Perak Selangor serta Negeri Sembilan di barat Johor di selatan dan Terengganu dan Laut China Selatan di timur.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'G': <networkx.classes.multidigraph.MultiDiGraph at 0x7fc379f1cfa0>,\n",
       "  'triple': [{'head': 'Najib Razak',\n",
       "    'type': 'position held',\n",
       "    'tail': 'Prime Minister of Malaysia'}],\n",
       "  'rebel': '<triplet> Najib Razak <subj> Prime Minister of Malaysia <obj> position held'},\n",
       " {'G': <networkx.classes.multidigraph.MultiDiGraph at 0x7fc37a5053d0>,\n",
       "  'triple': [{'head': 'Pahang', 'type': 'country', 'tail': 'Malaysia'},\n",
       "   {'head': 'Malaysia',\n",
       "    'type': 'contains administrative territorial entity',\n",
       "    'tail': 'Pahang'},\n",
       "   {'head': 'Pahang', 'type': 'country', 'tail': 'Malaysia'},\n",
       "   {'head': 'Perak Selangor', 'type': 'country', 'tail': 'Malaysia'},\n",
       "   {'head': 'Negeri Sembilan', 'type': 'country', 'tail': 'Malaysia'},\n",
       "   {'head': 'Johor', 'type': 'country', 'tail': 'Malaysia'},\n",
       "   {'head': 'Terengganu', 'type': 'country', 'tail': 'Malaysia'},\n",
       "   {'head': 'South China Sea', 'type': 'basin country', 'tail': 'Malaysia'}],\n",
       "  'rebel': '<triplet> Pahang <subj> Malaysia <obj> country <triplet> Malaysia <subj> Pahang <obj> contains administrative territorial entity <triplet> Pahang <subj> Malaysia <obj> country <triplet> Perak Selangor <subj> Malaysia <obj> country <triplet> Negeri Sembilan <subj> Malaysia <obj> country <triplet> Johor <subj> Malaysia <obj> country <triplet> Terengganu <subj> Malaysia <obj> country <triplet> South China Sea <subj> Malaysia <obj> basin country'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = ttkg.generate([string1, string2], do_sample=True, \n",
    "    max_length=256, \n",
    "    top_k=0, \n",
    "    temperature=0.7)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 'Najib Razak',\n",
       "  'type': 'position held',\n",
       "  'tail': 'Prime Minister of Malaysia'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]['triple']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict\n",
    "\n",
    "```python\n",
    "def generate(self, kgs: List[List[Dict]], **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a text from list of knowledge graph dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kg: List[List[Dict]]\n",
    "        list of list of {'head', 'type', 'tail'}\n",
    "    **kwargs: vector arguments pass to huggingface `generate` method.\n",
    "        Read more at https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: List[str]\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Beliau adalah Perdana Menteri Malaysia selama enam tahun pada tahun 1974 dan beliau kemudiannya menggantikan bekas Perdana Menteri yang memerintah, yang diketuai oleh Najib Razak.',\n",
       " 'Ia ditubuhkan pada 4 Jun 2020 oleh bekas Perdana Menteri Malaysia, Najib Razak sebagai tindak balas kepada keputusan yang dibuat oleh bekas perdana menteri Malaysia yang mendakwa tidak berjaya untuk menamatkan krisis politik semasa Perang Saudara Asia.',\n",
       " 'Beliau merupakan pemimpin Parti Perikatan Rakyat Malaysia yang dikenali sebagai Barisan Rakyat yang disokong oleh Presiden Najib Razak dan Perdana Menteri Malaysia yang ketiga, Syed Ali.',\n",
       " 'Ia dijumpai di Pahang, Malaysia, di mana ia telah direkodkan dari Perak Selangor, Negeri Sembilan dan Johor di bahagian atas Laut China Selatan.',\n",
       " 'Ia dijumpai di Pahang, Malaysia, di Perak Selangor, Negeri Sembilan, Johor, Terengganu, dan Laut China Selatan.',\n",
       " 'Spesies ini endemik kepada Pahang (negeri Malaysia Perak Selangor, Negeri Sembilan, Johor, Terengganu, Selangor, dan Laut China Selatan).']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate([r_['triple'] for r_ in r], do_sample=True, \n",
    "    max_length=100, \n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "permulaan = [\n",
    "    'bel',\n",
    "    'se',\n",
    "    'ter',\n",
    "    'men',\n",
    "    'meng',\n",
    "    'mem',\n",
    "    'memper',\n",
    "    'di',\n",
    "    'pe',\n",
    "    'me',\n",
    "    'ke',\n",
    "    'ber',\n",
    "    'pen',\n",
    "    'per',\n",
    "]\n",
    "\n",
    "hujung = ['kan', 'kah', 'lah', 'tah', 'nya', 'an', 'wan', 'wati', 'ita']\n",
    "\n",
    "def naive_stemmer(word):\n",
    "    assert isinstance(word, str), 'input must be a string'\n",
    "    hujung_result = re.findall(r'^(.*?)(%s)$' % ('|'.join(hujung)), word)\n",
    "    word = hujung_result[0][0] if len(hujung_result) else word\n",
    "    permulaan_result = re.findall(r'^(.*?)(%s)' % ('|'.join(permulaan[::-1])), word)\n",
    "    permulaan_result.extend(re.findall(r'^(.*?)(%s)' % ('|'.join(permulaan)), word))\n",
    "    mula = permulaan_result if len(permulaan_result) else ''\n",
    "    if len(mula):\n",
    "        mula = mula[1][1] if len(mula[1][1]) > len(mula[0][1]) else mula[0][1]\n",
    "    return word.replace(mula, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [['GO', 0], ['PAD', 1], ['EOS', 2], ['UNK', 3]]\n",
    "    counter = collections.Counter(words).most_common(n_words)\n",
    "    count.extend(counter)\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 3)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "\n",
    "def classification_textcleaning(string):\n",
    "    string = re.sub(\n",
    "        'http\\S+|www.\\S+',\n",
    "        '',\n",
    "        ' '.join(\n",
    "            [i for i in string.split() if i.find('#') < 0 and i.find('@') < 0]\n",
    "        ),\n",
    "    )\n",
    "    string = unidecode(string).replace('.', ' . ').replace(',', ' , ')\n",
    "    string = re.sub('[^A-Za-z ]+', ' ', string)\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    string = ' '.join(\n",
    "        [i for i in re.findall('[\\\\w\\']+|[;:\\-\\(\\)&.,!?\"]', string) if len(i)]\n",
    "    )\n",
    "    string = string.lower().split()\n",
    "    string = [(naive_stemmer(word), word) for word in string]\n",
    "    return (\n",
    "        ' '.join([word[0] for word in string if len(word[0]) > 1]),\n",
    "        ' '.join([word[1] for word in string if len(word[0]) > 1]),\n",
    "    )\n",
    "\n",
    "def str_idx(corpus, dic, maxlen, UNK = 3):\n",
    "    X = np.zeros((len(corpus), maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i].split()[:maxlen][::-1]):\n",
    "            val = dic[k] if k in dic else UNK\n",
    "            X[i, -1 - no] = val\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Lebih-lebih lagi dengan  kemudahan internet da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>boleh memberi teguran kepada parti tetapi perl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Adalah membingungkan mengapa masyarakat Cina b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Kami menurunkan defisit daripada 6.7 peratus p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Ini masalahnya. Bukan rakyat, tetapi sistem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  Negative  Lebih-lebih lagi dengan  kemudahan internet da...\n",
       "1  Positive  boleh memberi teguran kepada parti tetapi perl...\n",
       "2  Negative  Adalah membingungkan mengapa masyarakat Cina b...\n",
       "3  Positive  Kami menurunkan defisit daripada 6.7 peratus p...\n",
       "4  Negative        Ini masalahnya. Bukan rakyat, tetapi sistem"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/sentiment-data-v2.csv')\n",
    "Y = LabelEncoder().fit_transform(df.label)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/polarity-negative-translated.txt','r') as fopen:\n",
    "    texts = fopen.read().split('\\n')\n",
    "labels = [0] * len(texts)\n",
    "\n",
    "with open('dataset/polarity-positive-translated.txt','r') as fopen:\n",
    "    positive_texts = fopen.read().split('\\n')\n",
    "labels += [1] * len(positive_texts)\n",
    "texts += positive_texts\n",
    "texts += df.iloc[:,1].tolist()\n",
    "labels += Y.tolist()\n",
    "\n",
    "assert len(labels) == len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(texts)):\n",
    "    texts[i] = classification_textcleaning(texts[i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab from size: 13325\n",
      "Most common words [('yang', 14899), ('tidak', 4588), ('untuk', 4038), ('filem', 3698), ('deng', 3350), ('ada', 3190)]\n",
      "Sample data [1353, 196, 178, 98, 98, 126, 354, 4, 90, 210] ['ringkas', 'bodoh', 'bosan', 'kanak', 'kanak', 'lelaki', 'remaja', 'yang', 'begitu', 'muda']\n"
     ]
    }
   ],
   "source": [
    "concat = ' '.join(texts).split()\n",
    "vocabulary_size = len(list(set(concat)))\n",
    "data, count, dictionary, rev_dictionary = build_dataset(concat, vocabulary_size)\n",
    "print('vocab from size: %d'%(vocabulary_size))\n",
    "print('Most common words', count[4:10])\n",
    "print('Sample data', data[:10], [rev_dictionary[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        size_layer,\n",
    "        num_layers,\n",
    "        dimension_output,\n",
    "        learning_rate,\n",
    "        dropout,\n",
    "        dict_size,\n",
    "    ):\n",
    "        def cells(size, reuse = False):\n",
    "            return tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.nn.rnn_cell.LSTMCell(\n",
    "                    size,\n",
    "                    initializer = tf.orthogonal_initializer(),\n",
    "                    reuse = reuse,\n",
    "                ),\n",
    "                state_keep_prob = dropout,\n",
    "                output_keep_prob = dropout,\n",
    "            )\n",
    "\n",
    "\n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None])\n",
    "        encoder_embeddings = tf.Variable(\n",
    "            tf.random_uniform([dict_size, size_layer], -1, 1)\n",
    "        )\n",
    "        encoder_embedded = tf.nn.embedding_lookup(encoder_embeddings, self.X)\n",
    "        attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "            num_units = size_layer, memory = encoder_embedded\n",
    "        )\n",
    "        rnn_cells = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                [cells(size_layer) for _ in range(num_layers)]\n",
    "            ),\n",
    "            attention_mechanism = attention_mechanism,\n",
    "            attention_layer_size = size_layer,\n",
    "            alignment_history = True,\n",
    "        )\n",
    "        outputs, last_state = tf.nn.dynamic_rnn(\n",
    "            rnn_cells, encoder_embedded, dtype = tf.float32\n",
    "        )\n",
    "        self.alignments = tf.transpose(\n",
    "            last_state.alignment_history.stack(), [1, 2, 0]\n",
    "        )\n",
    "        W = tf.get_variable(\n",
    "            'w',\n",
    "            shape = (size_layer, dimension_output),\n",
    "            initializer = tf.glorot_uniform_initializer(),\n",
    "        )\n",
    "        b = tf.get_variable(\n",
    "            'b',\n",
    "            shape = (dimension_output),\n",
    "            initializer = tf.zeros_initializer(),\n",
    "        )\n",
    "        self.logits = tf.add(tf.matmul(outputs[:, -1], W), b, name = 'logits')\n",
    "        self.cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits = self.logits, labels = self.Y\n",
    "            )\n",
    "        )\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate = learning_rate\n",
    "        ).minimize(self.cost)\n",
    "        correct_pred = tf.equal(\n",
    "            tf.argmax(self.logits, 1, output_type = tf.int32), self.Y\n",
    "        )\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        self.attention = tf.nn.softmax(\n",
    "            tf.reduce_sum(self.alignments[0], 1), name = 'alphas'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bahdanau/model.ckpt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_layer = 256\n",
    "num_layers = 2\n",
    "dimension_output = 2\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "dropout = 0.8\n",
    "maxlen = 80\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(\n",
    "    size_layer,\n",
    "    num_layers,\n",
    "    dimension_output,\n",
    "    learning_rate,\n",
    "    dropout,\n",
    "    len(dictionary),\n",
    ")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'bahdanau/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Variable',\n",
       " 'memory_layer/kernel',\n",
       " 'rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/kernel',\n",
       " 'rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/bias',\n",
       " 'rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/kernel',\n",
       " 'rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/bias',\n",
       " 'rnn/attention_wrapper/attention_layer/kernel',\n",
       " 'w',\n",
       " 'b',\n",
       " 'logits',\n",
       " 'gradients/logits_grad/Shape',\n",
       " 'gradients/logits_grad/Shape_1',\n",
       " 'gradients/logits_grad/BroadcastGradientArgs',\n",
       " 'gradients/logits_grad/Sum',\n",
       " 'gradients/logits_grad/Reshape',\n",
       " 'gradients/logits_grad/Sum_1',\n",
       " 'gradients/logits_grad/Reshape_1',\n",
       " 'gradients/logits_grad/tuple/group_deps',\n",
       " 'gradients/logits_grad/tuple/control_dependency',\n",
       " 'gradients/logits_grad/tuple/control_dependency_1',\n",
       " 'alphas']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(13329, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'memory_layer/kernel:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/kernel:0' shape=(512, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/attention_layer/kernel:0' shape=(512, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'w:0' shape=(256, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'b:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = str_idx(texts, dictionary, maxlen)\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    vectors, labels, test_size = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 357/357 [01:46<00:00,  2.77it/s, accuracy=0.516, cost=0.672]\n",
      "test minibatch loop: 100%|██████████| 90/90 [00:13<00:00,  6.55it/s, accuracy=0.625, cost=0.569]\n",
      "train minibatch loop:   0%|          | 0/357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.000000, current acc: 0.623950\n",
      "time taken: 119.65434527397156\n",
      "epoch: 0, training loss: 0.670557, training acc: 0.592884, valid loss: 0.654818, valid acc: 0.623950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 357/357 [02:07<00:00,  2.73it/s, accuracy=0.774, cost=0.582]\n",
      "test minibatch loop: 100%|██████████| 90/90 [00:12<00:00,  6.93it/s, accuracy=0.625, cost=0.578]\n",
      "train minibatch loop:   0%|          | 0/357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, pass acc: 0.623950, current acc: 0.655812\n",
      "time taken: 140.0224642753601\n",
      "epoch: 1, training loss: 0.616485, training acc: 0.661453, valid loss: 0.635684, valid acc: 0.655812\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 357/357 [02:06<00:00,  2.75it/s, accuracy=0.806, cost=0.559]\n",
      "test minibatch loop: 100%|██████████| 90/90 [00:13<00:00,  6.74it/s, accuracy=0.625, cost=0.644]\n",
      "train minibatch loop:   0%|          | 0/357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 139.5311439037323\n",
      "epoch: 2, training loss: 0.561311, training acc: 0.709079, valid loss: 0.637543, valid acc: 0.653711\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 357/357 [02:06<00:00,  2.76it/s, accuracy=0.806, cost=0.425]\n",
      "test minibatch loop: 100%|██████████| 90/90 [00:12<00:00,  6.66it/s, accuracy=0.625, cost=0.71] \n",
      "train minibatch loop:   0%|          | 0/357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, pass acc: 0.655812, current acc: 0.665966\n",
      "time taken: 139.43606162071228\n",
      "epoch: 3, training loss: 0.498594, training acc: 0.760291, valid loss: 0.668205, valid acc: 0.665966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 357/357 [02:06<00:00,  2.71it/s, accuracy=0.871, cost=0.348]\n",
      "test minibatch loop: 100%|██████████| 90/90 [00:13<00:00,  6.88it/s, accuracy=0.5, cost=1.08]   \n",
      "train minibatch loop:   0%|          | 0/357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 139.22403740882874\n",
      "epoch: 4, training loss: 0.426630, training acc: 0.805732, valid loss: 0.716268, valid acc: 0.652661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 357/357 [02:06<00:00,  2.73it/s, accuracy=0.871, cost=0.287]\n",
      "test minibatch loop: 100%|██████████| 90/90 [00:13<00:00,  7.17it/s, accuracy=0.375, cost=1.19] \n",
      "train minibatch loop:   0%|          | 0/357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 139.42699933052063\n",
      "epoch: 5, training loss: 0.346935, training acc: 0.849853, valid loss: 0.795718, valid acc: 0.653011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 357/357 [02:06<00:00,  2.83it/s, accuracy=0.935, cost=0.209]\n",
      "test minibatch loop: 100%|██████████| 90/90 [00:13<00:00,  6.52it/s, accuracy=0.625, cost=1.01] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 139.71299862861633\n",
      "epoch: 6, training loss: 0.284674, training acc: 0.879973, valid loss: 0.883334, valid acc: 0.661415\n",
      "\n",
      "break epoch:7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "EARLY_STOPPING, CURRENT_CHECKPOINT, CURRENT_ACC, EPOCH = 3, 0, 0, 0\n",
    "\n",
    "while True:\n",
    "    lasttime = time.time()\n",
    "    if CURRENT_CHECKPOINT == EARLY_STOPPING:\n",
    "        print('break epoch:%d\\n' % (EPOCH))\n",
    "        break\n",
    "\n",
    "    train_acc, train_loss, test_acc, test_loss = 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = train_X[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_y = train_Y[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost, _ = sess.run(\n",
    "            [model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    pbar = tqdm(range(0, len(test_X), batch_size), desc = 'test minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost = sess.run(\n",
    "            [model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    train_loss /= len(train_X) / batch_size\n",
    "    train_acc /= len(train_X) / batch_size\n",
    "    test_loss /= len(test_X) / batch_size\n",
    "    test_acc /= len(test_X) / batch_size\n",
    "\n",
    "    if test_acc > CURRENT_ACC:\n",
    "        print(\n",
    "            'epoch: %d, pass acc: %f, current acc: %f'\n",
    "            % (EPOCH, CURRENT_ACC, test_acc)\n",
    "        )\n",
    "        CURRENT_ACC = test_acc\n",
    "        CURRENT_CHECKPOINT = 0\n",
    "    else:\n",
    "        CURRENT_CHECKPOINT += 1\n",
    "\n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, valid loss: %f, valid acc: %f\\n'\n",
    "        % (EPOCH, train_loss, train_acc, test_loss, test_acc)\n",
    "    )\n",
    "    EPOCH += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation minibatch loop: 100%|██████████| 90/90 [00:12<00:00,  7.45it/s]\n"
     ]
    }
   ],
   "source": [
    "real_Y, predict_Y = [], []\n",
    "\n",
    "pbar = tqdm(\n",
    "    range(0, len(test_X), batch_size), desc = 'validation minibatch loop'\n",
    ")\n",
    "for i in pbar:\n",
    "    batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "    predict_Y += np.argmax(\n",
    "        sess.run(\n",
    "            model.logits, feed_dict = {model.X: batch_x, model.Y: batch_y}\n",
    "        ),\n",
    "        1,\n",
    "    ).tolist()\n",
    "    real_Y += batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.62      0.73      0.67      1360\n",
      "   positive       0.71      0.59      0.64      1496\n",
      "\n",
      "avg / total       0.66      0.66      0.66      2856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    metrics.classification_report(\n",
    "        real_Y, predict_Y, target_names = ['negative', 'positive']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61365014, 0.38634986]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = classification_textcleaning('kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya')\n",
    "new_vector = str_idx([text[0]], dictionary, len(text[0].split()))\n",
    "sess.run(tf.nn.softmax(model.logits), feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17618038, 0.82381964]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = classification_textcleaning('kerajaan sebenarnya sangat sayangkan rakyatnya')\n",
    "new_vector = str_idx([text[0]], dictionary, len(text[0].split()))\n",
    "sess.run(tf.nn.softmax(model.logits), feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14107597, 0.8589241 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = classification_textcleaning('kerajaan sebenarnya sangat sayangkan rakyatnya, tetapi sebenarnya benci')\n",
    "new_vector = str_idx([text[0]], dictionary, len(text[0].split()))\n",
    "sess.run(tf.nn.softmax(model.logits), feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('luong-sentiment.json','w') as fopen:\n",
    "    fopen.write(json.dumps({'dictionary':dictionary,'reverse_dictionary':rev_dictionary}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'luong/model.ckpt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, 'luong/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from luong/model.ckpt\n",
      "INFO:tensorflow:Froze 9 variables.\n",
      "INFO:tensorflow:Converted 9 variables to const ops.\n",
      "393 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('luong', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "g = load_graph('luong/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')\n",
    "alphas = g.get_tensor_by_name('import/alphas:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)\n",
    "result = test_sess.run([logits, alphas], feed_dict = {x: new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_string = 'kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = classification_textcleaning(news_string)\n",
    "new_vector = str_idx([text[0]], dictionary, len(text[0].split()))\n",
    "result = test_sess.run([tf.nn.softmax(logits), alphas], feed_dict = {x: new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93ec032208>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "labels = [word for word in text[1].split()]\n",
    "val = [val for val in result[1]]\n",
    "plt.bar(np.arange(len(labels)), val)\n",
    "plt.xticks(np.arange(len(labels)), labels, rotation = 'vertical')\n",
    "plt.title('negative %f positive %f' % (result[0][0,0], result[0][0,1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from unidecode import unidecode\n",
    "from nltk.util import ngrams\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "permulaan = [\n",
    "    'bel',\n",
    "    'se',\n",
    "    'ter',\n",
    "    'men',\n",
    "    'meng',\n",
    "    'mem',\n",
    "    'memper',\n",
    "    'di',\n",
    "    'pe',\n",
    "    'me',\n",
    "    'ke',\n",
    "    'ber',\n",
    "    'pen',\n",
    "    'per',\n",
    "]\n",
    "\n",
    "hujung = ['kan', 'kah', 'lah', 'tah', 'nya', 'an', 'wan', 'wati', 'ita']\n",
    "\n",
    "def naive_stemmer(word):\n",
    "    assert isinstance(word, str), 'input must be a string'\n",
    "    hujung_result = re.findall(r'^(.*?)(%s)$' % ('|'.join(hujung)), word)\n",
    "    word = hujung_result[0][0] if len(hujung_result) else word\n",
    "    permulaan_result = re.findall(r'^(.*?)(%s)' % ('|'.join(permulaan[::-1])), word)\n",
    "    permulaan_result.extend(re.findall(r'^(.*?)(%s)' % ('|'.join(permulaan)), word))\n",
    "    mula = permulaan_result if len(permulaan_result) else ''\n",
    "    if len(mula):\n",
    "        mula = mula[1][1] if len(mula[1][1]) > len(mula[0][1]) else mula[0][1]\n",
    "    return word.replace(mula, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [['GO', 0], ['PAD', 1], ['EOS', 2], ['UNK', 3]]\n",
    "    counter = collections.Counter(words).most_common(n_words)\n",
    "    count.extend(counter)\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 3)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "\n",
    "def classification_textcleaning(string):\n",
    "    string = re.sub(\n",
    "        'http\\S+|www.\\S+',\n",
    "        '',\n",
    "        ' '.join(\n",
    "            [i for i in string.split() if i.find('#') < 0 and i.find('@') < 0]\n",
    "        ),\n",
    "    )\n",
    "    string = unidecode(string).replace('.', ' . ').replace(',', ' , ')\n",
    "    string = re.sub('[^A-Za-z ]+', ' ', string)\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    string = ' '.join(\n",
    "        [i for i in re.findall('[\\\\w\\']+|[;:\\-\\(\\)&.,!?\"]', string) if len(i)]\n",
    "    )\n",
    "    string = string.lower().split()\n",
    "    string = [(naive_stemmer(word), word) for word in string]\n",
    "    return (\n",
    "        ' '.join([word[0] for word in string if len(word[0]) > 1]),\n",
    "        ' '.join([word[1] for word in string if len(word[0]) > 1]),\n",
    "    )\n",
    "\n",
    "\n",
    "def str_idx(corpus, dic, maxlen, UNK = 3):\n",
    "    X = np.zeros((len(corpus), maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i].split()[:maxlen][::-1]):\n",
    "            X[i, -1 - no] = dic.get(k,UNK)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('subjectivity-negative-translated.txt','r') as fopen:\n",
    "    texts = fopen.read().split('\\n')\n",
    "labels = [0] * len(texts)\n",
    "\n",
    "with open('subjectivity-positive-translated.txt','r') as fopen:\n",
    "    positive_texts = fopen.read().split('\\n')\n",
    "labels += [1] * len(positive_texts)\n",
    "texts += positive_texts\n",
    "\n",
    "assert len(labels) == len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(texts)):\n",
    "    texts[i] = classification_textcleaning(texts[i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab from size: 13222\n",
      "Most common words [('yang', 11804), ('untuk', 3879), ('tidak', 2898), ('deng', 2827), ('ada', 2294), ('dalam', 2193)]\n",
      "Sample data [10, 68, 13, 27, 55, 53, 11, 391, 34, 183] ['filem', 'mula', 'pada', 'masa', 'lalu', 'mana', 'orang', 'budak', 'lelaki', 'nama']\n"
     ]
    }
   ],
   "source": [
    "concat = ' '.join(texts).split()\n",
    "vocabulary_size = len(list(set(concat)))\n",
    "data, count, dictionary, rev_dictionary = build_dataset(concat, vocabulary_size)\n",
    "print('vocab from size: %d'%(vocabulary_size))\n",
    "print('Most common words', count[4:10])\n",
    "print('Sample data', data[:10], [rev_dictionary[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        size_layer,\n",
    "        num_layers,\n",
    "        dimension_output,\n",
    "        learning_rate,\n",
    "        dropout,\n",
    "        dict_size,\n",
    "    ):\n",
    "        def cells(size, reuse = False):\n",
    "            return tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.nn.rnn_cell.LSTMCell(\n",
    "                    size,\n",
    "                    initializer = tf.orthogonal_initializer(),\n",
    "                    reuse = reuse,\n",
    "                ),\n",
    "                state_keep_prob = dropout,\n",
    "                output_keep_prob = dropout,\n",
    "            )\n",
    "\n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None])\n",
    "        encoder_embeddings = tf.Variable(\n",
    "            tf.random_uniform([dict_size, size_layer], -1, 1)\n",
    "        )\n",
    "        encoder_embedded = tf.nn.embedding_lookup(encoder_embeddings, self.X)\n",
    "        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "            num_units = size_layer, memory = encoder_embedded\n",
    "        )\n",
    "        rnn_cells = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                [cells(size_layer) for _ in range(num_layers)]\n",
    "            ),\n",
    "            attention_mechanism = attention_mechanism,\n",
    "            attention_layer_size = size_layer,\n",
    "            alignment_history = True,\n",
    "        )\n",
    "        outputs, last_state = tf.nn.dynamic_rnn(\n",
    "            rnn_cells, encoder_embedded, dtype = tf.float32\n",
    "        )\n",
    "        self.alignments = tf.transpose(\n",
    "            last_state.alignment_history.stack(), [1, 2, 0]\n",
    "        )\n",
    "        W = tf.get_variable(\n",
    "            'w',\n",
    "            shape = (size_layer, dimension_output),\n",
    "            initializer = tf.glorot_uniform_initializer(),\n",
    "        )\n",
    "        b = tf.get_variable(\n",
    "            'b',\n",
    "            shape = (dimension_output),\n",
    "            initializer = tf.zeros_initializer(),\n",
    "        )\n",
    "        self.logits = tf.add(tf.matmul(outputs[:, -1], W), b, name = 'logits')\n",
    "        self.cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits = self.logits, labels = self.Y\n",
    "            )\n",
    "        )\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate = learning_rate\n",
    "        ).minimize(self.cost)\n",
    "        correct_pred = tf.equal(\n",
    "            tf.argmax(self.logits, 1, output_type = tf.int32), self.Y\n",
    "        )\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        self.attention = tf.nn.softmax(\n",
    "            tf.reduce_sum(self.alignments[0], 1), name = 'alphas'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bahdanau/model.ckpt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_layer = 256\n",
    "num_layers = 2\n",
    "dimension_output = 2\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "dropout = 0.8\n",
    "maxlen = 80\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(\n",
    "    size_layer,\n",
    "    num_layers,\n",
    "    dimension_output,\n",
    "    learning_rate,\n",
    "    dropout,\n",
    "    len(dictionary),\n",
    ")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'bahdanau/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Variable',\n",
       " 'memory_layer/kernel',\n",
       " 'rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/kernel',\n",
       " 'rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/bias',\n",
       " 'rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/kernel',\n",
       " 'rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/bias',\n",
       " 'rnn/attention_wrapper/bahdanau_attention/query_layer/kernel',\n",
       " 'rnn/attention_wrapper/bahdanau_attention/attention_v',\n",
       " 'rnn/attention_wrapper/attention_layer/kernel',\n",
       " 'w',\n",
       " 'b',\n",
       " 'logits',\n",
       " 'gradients/logits_grad/Shape',\n",
       " 'gradients/logits_grad/Shape_1',\n",
       " 'gradients/logits_grad/BroadcastGradientArgs',\n",
       " 'gradients/logits_grad/Sum',\n",
       " 'gradients/logits_grad/Reshape',\n",
       " 'gradients/logits_grad/Sum_1',\n",
       " 'gradients/logits_grad/Reshape_1',\n",
       " 'gradients/logits_grad/tuple/group_deps',\n",
       " 'gradients/logits_grad/tuple/control_dependency',\n",
       " 'gradients/logits_grad/tuple/control_dependency_1',\n",
       " 'alphas']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(13226, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'memory_layer/kernel:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/kernel:0' shape=(512, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/bahdanau_attention/query_layer/kernel:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/bahdanau_attention/attention_v:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/attention_wrapper/attention_layer/kernel:0' shape=(512, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'w:0' shape=(256, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'b:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = str_idx(texts, dictionary, maxlen)\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    vectors, labels, test_size = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 250/250 [00:51<00:00,  5.48it/s, accuracy=1, cost=0.636]    \n",
      "test minibatch loop: 100%|██████████| 63/63 [00:04<00:00, 15.35it/s, accuracy=0.778, cost=0.424]\n",
      "train minibatch loop:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.000000, current acc: 0.796733\n",
      "time taken: 55.431103467941284\n",
      "epoch: 0, training loss: 0.542290, training acc: 0.726942, valid loss: 0.468603, valid acc: 0.796733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 250/250 [00:51<00:00,  5.54it/s, accuracy=1, cost=0.0143]   \n",
      "test minibatch loop: 100%|██████████| 63/63 [00:04<00:00, 15.48it/s, accuracy=0.778, cost=0.434]\n",
      "train minibatch loop:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, pass acc: 0.796733, current acc: 0.812789\n",
      "time taken: 55.133484840393066\n",
      "epoch: 1, training loss: 0.405482, training acc: 0.823064, valid loss: 0.431048, valid acc: 0.812789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 250/250 [00:51<00:00,  5.48it/s, accuracy=1, cost=0.00734]  \n",
      "test minibatch loop: 100%|██████████| 63/63 [00:04<00:00, 15.39it/s, accuracy=0.778, cost=0.512]\n",
      "train minibatch loop:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, pass acc: 0.812789, current acc: 0.833863\n",
      "time taken: 55.29987168312073\n",
      "epoch: 2, training loss: 0.337022, training acc: 0.856569, valid loss: 0.412868, valid acc: 0.833863\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 250/250 [00:51<00:00,  5.48it/s, accuracy=1, cost=0.000797] \n",
      "test minibatch loop: 100%|██████████| 63/63 [00:04<00:00, 15.39it/s, accuracy=0.778, cost=0.573]\n",
      "train minibatch loop:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 55.40781855583191\n",
      "epoch: 3, training loss: 0.281065, training acc: 0.885306, valid loss: 0.428812, valid acc: 0.828845\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 250/250 [00:51<00:00,  5.50it/s, accuracy=1, cost=4.8e-5]    \n",
      "test minibatch loop: 100%|██████████| 63/63 [00:04<00:00, 15.46it/s, accuracy=0.778, cost=0.505]\n",
      "train minibatch loop:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 55.34353590011597\n",
      "epoch: 4, training loss: 0.232831, training acc: 0.908897, valid loss: 0.453250, valid acc: 0.829849\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 250/250 [00:51<00:00,  5.46it/s, accuracy=1, cost=1.56e-5]   \n",
      "test minibatch loop: 100%|██████████| 63/63 [00:04<00:00, 15.34it/s, accuracy=0.778, cost=0.615]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 55.35534882545471\n",
      "epoch: 5, training loss: 0.185739, training acc: 0.931108, valid loss: 0.498805, valid acc: 0.832358\n",
      "\n",
      "break epoch:6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EARLY_STOPPING, CURRENT_CHECKPOINT, CURRENT_ACC, EPOCH = 3, 0, 0, 0\n",
    "\n",
    "while True:\n",
    "    lasttime = time.time()\n",
    "    if CURRENT_CHECKPOINT == EARLY_STOPPING:\n",
    "        print('break epoch:%d\\n' % (EPOCH))\n",
    "        break\n",
    "\n",
    "    train_acc, train_loss, test_acc, test_loss = 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = train_X[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_y = train_Y[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost, _ = sess.run(\n",
    "            [model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    pbar = tqdm(range(0, len(test_X), batch_size), desc = 'test minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost = sess.run(\n",
    "            [model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.Y: batch_y,\n",
    "                model.X: batch_x\n",
    "            },\n",
    "        )\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    train_loss /= len(train_X) / batch_size\n",
    "    train_acc /= len(train_X) / batch_size\n",
    "    test_loss /= len(test_X) / batch_size\n",
    "    test_acc /= len(test_X) / batch_size\n",
    "\n",
    "    if test_acc > CURRENT_ACC:\n",
    "        print(\n",
    "            'epoch: %d, pass acc: %f, current acc: %f'\n",
    "            % (EPOCH, CURRENT_ACC, test_acc)\n",
    "        )\n",
    "        CURRENT_ACC = test_acc\n",
    "        CURRENT_CHECKPOINT = 0\n",
    "    else:\n",
    "        CURRENT_CHECKPOINT += 1\n",
    "\n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, valid loss: %f, valid acc: %f\\n'\n",
    "        % (EPOCH, train_loss, train_acc, test_loss, test_acc)\n",
    "    )\n",
    "    EPOCH += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation minibatch loop: 100%|██████████| 63/63 [00:04<00:00, 15.42it/s]\n"
     ]
    }
   ],
   "source": [
    "real_Y, predict_Y = [], []\n",
    "\n",
    "pbar = tqdm(\n",
    "    range(0, len(test_X), batch_size), desc = 'validation minibatch loop'\n",
    ")\n",
    "for i in pbar:\n",
    "    batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "    predict_Y += np.argmax(\n",
    "        sess.run(\n",
    "            model.logits, feed_dict = {model.X: batch_x, model.Y: batch_y}\n",
    "        ),\n",
    "        1,\n",
    "    ).tolist()\n",
    "    real_Y += batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.82       983\n",
      "    positive       0.83      0.83      0.83      1010\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1993\n",
      "   macro avg       0.83      0.83      0.83      1993\n",
      "weighted avg       0.83      0.83      0.83      1993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    metrics.classification_report(\n",
    "        real_Y, predict_Y, target_names = ['negative', 'positive']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38582426, 0.6141758 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = classification_textcleaning('kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya')\n",
    "new_vector = str_idx([text[0]], dictionary, len(text[0].split()))\n",
    "sess.run(tf.nn.softmax(model.logits), feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20669125, 0.7933087 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = classification_textcleaning('kerajaan sebenarnya sangat sayangkan rakyatnya')\n",
    "new_vector = str_idx([text[0]], dictionary, len(text[0].split()))\n",
    "sess.run(tf.nn.softmax(model.logits), feed_dict={model.X:new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('bahdanau-subjective.json','w') as fopen:\n",
    "    fopen.write(json.dumps({'dictionary':dictionary,'reverse_dictionary':rev_dictionary}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bahdanau/model.ckpt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, 'bahdanau/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bahdanau/model.ckpt\n",
      "INFO:tensorflow:Froze 11 variables.\n",
      "INFO:tensorflow:Converted 11 variables to const ops.\n",
      "403 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('bahdanau', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "g = load_graph('bahdanau/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')\n",
    "alphas = g.get_tensor_by_name('import/alphas:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)\n",
    "result = test_sess.run([logits, alphas], feed_dict = {x: new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_string = 'kerajaan sebenarnya sangat bencikan rakyatnya, minyak naik dan segalanya'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = classification_textcleaning(news_string)\n",
    "new_vector = str_idx([text[0]], dictionary, len(text[0].split()))\n",
    "result = test_sess.run([tf.nn.softmax(logits), alphas], feed_dict = {x: new_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6bfc515748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "labels = [word for word in text[1].split()]\n",
    "val = [val for val in result[1]]\n",
    "plt.bar(np.arange(len(labels)), val)\n",
    "plt.xticks(np.arange(len(labels)), labels, rotation = 'vertical')\n",
    "plt.title('negative %f positive %f' % (result[0][0,0], result[0][0,1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

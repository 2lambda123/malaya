{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.5.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_addons/utils/resource_loader.py:103: UserWarning: You are currently using TensorFlow 2.5.0 and trying to load a custom op (custom_ops/seq2seq/_beam_search_ops.so).\n",
      "TensorFlow Addons has compiled its custom ops against TensorFlow 2.4.0, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "It might help you to fallback to pure Python ops with TF_ADDONS_PY_OPS . To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.4.0 and strictly below 2.5.0.\n",
      " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
      "  UserWarning,\n",
      "/Users/huseinzolkepli/Documents/malaya-boilerplate/malaya_boilerplate/frozen_graph.py:28: UserWarning: Cannot import beam_search_ops from Tensorflow Addons, `deep_model` for stemmer will not available to use, make sure Tensorflow Addons version >= 0.12.0\n",
      "  'Cannot import beam_search_ops from Tensorflow Addons, `deep_model` for stemmer will not available to use, make sure Tensorflow Addons version >= 0.12.0'\n"
     ]
    }
   ],
   "source": [
    "import malaya\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = 'jom makan di us makanan di sana sedap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = malaya.true_case.available_transformer()\n",
    "for m in models.index:\n",
    "    print(m)\n",
    "    model = malaya.true_case.transformer(model = m)\n",
    "    print(model.greedy_decoder([string1]))\n",
    "    malaya.utils.delete_cache(f'true-case/{m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = malaya.segmentation.available_transformer()\n",
    "for m in models.index:\n",
    "    print(m)\n",
    "    model = malaya.segmentation.transformer(model = m)\n",
    "    print(model.greedy_decoder([string1]))\n",
    "    malaya.utils.delete_cache(f'segmentation/{m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = malaya.stem.deep_model()\n",
    "print(model.stem('saya menyerukanlah'))\n",
    "malaya.utils.delete_cache('stem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'Pada amnya, hanya penjaga gol sahaja yang dibenarkan menyentuh bola dengan tangan di dalam kawasan golnya'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = malaya.tatabahasa.available_transformer()\n",
    "for m in models.index:\n",
    "    print(m)\n",
    "    model = malaya.tatabahasa.transformer(model = m)\n",
    "    print(model.greedy_decoder([string]))\n",
    "    malaya.utils.delete_cache(f'kesalahan-tatabahasa/{m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = 'krajaan patut bagi pencen awal skt kpd warga emas supaya emosi'\n",
    "string2 = 'Husein ska mkn aym dkat kampng Jawa'\n",
    "string3 = 'Melayu malas ni narration dia sama je macam men are trash. True to some, false to some.'\n",
    "string4 = 'Tapi tak pikir ke bahaya perpetuate myths camtu. Nanti kalau ada hiring discrimination despite your good qualifications because of your race tau pulak marah. Your kids will be victims of that too.'\n",
    "string5 = 'DrM cerita Melayu malas semenjak saya kat University (early 1980s) and now as i am edging towards retirement in 4-5 years time after a career of being an Engineer, Project Manager, General Manager'\n",
    "string6 = 'blh bntg dlm kls nlp sy, nnti intch'\n",
    "string7 = '031 313.212-2341'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_corrector = malaya.spell.probability()\n",
    "prob_corrector.correct('sy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_corrector_sp = malaya.spell.probability(sentence_piece = True)\n",
    "prob_corrector_sp.edit_candidates('smbng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = malaya.transformer.load(model = 'electra')\n",
    "transformer_corrector = malaya.spell.transformer(model, sentence_piece = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_corrector.correct_text(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrector = malaya.spell.probability()\n",
    "normalizer = malaya.normalize.normalizer(corrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:index: 0, word: boleh, queue: []\n",
      "DEBUG:root:index: 1, word: dtg, queue: ['boleh']\n",
      "DEBUG:root:index: 2, word: 8, queue: ['boleh', 'datang']\n",
      "DEBUG:root:index: 3, word: pagi, queue: ['boleh', 'datang', 'lapan']\n",
      "DEBUG:root:index: 4, word: esok, queue: ['boleh', 'datang', 'lapan', 'pagi']\n",
      "DEBUG:root:index: 5, word: tak, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok']\n",
      "DEBUG:root:index: 6, word: atau, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak']\n",
      "DEBUG:root:index: 7, word: minggu, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau']\n",
      "DEBUG:root:index: 8, word: depan, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu']\n",
      "DEBUG:root:index: 9, word: ?, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu', 'depan']\n",
      "DEBUG:root:index: 10, word: 2 oktober 2019, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu', 'depan', '?']\n",
      "DEBUG:root:index: 11, word: 2pm, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu', 'depan', '?', '02/10/2019']\n",
      "DEBUG:root:index: 12, word: ,, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu', 'depan', '?', '02/10/2019', '14:00:00']\n",
      "DEBUG:root:index: 13, word: tlong, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu', 'depan', '?', '02/10/2019', '14:00:00', ',']\n",
      "DEBUG:root:index: 14, word: bayar, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu', 'depan', '?', '02/10/2019', '14:00:00', ',', 'tolong']\n",
      "DEBUG:root:index: 15, word: rm 3.2k, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu', 'depan', '?', '02/10/2019', '14:00:00', ',', 'tolong', 'bayar']\n",
      "DEBUG:root:index: 16, word: sekali, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu', 'depan', '?', '02/10/2019', '14:00:00', ',', 'tolong', 'bayar', 'tiga ribu dua ratus ringgit']\n",
      "DEBUG:root:index: 17, word: tau, queue: ['boleh', 'datang', 'lapan', 'pagi', 'esok', 'tidak', 'atau', 'minggu', 'depan', '?', '02/10/2019', '14:00:00', ',', 'tolong', 'bayar', 'tiga ribu dua ratus ringgit', 'sekali']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'normalize': 'boleh datang lapan pagi esok tidak atau minggu depan ? 02/10/2019 14:00:00 , tolong bayar tiga ribu dua ratus ringgit sekali tahu',\n",
       " 'date': {'minggu depan': datetime.datetime(2021, 12, 4, 17, 3, 53, 935279),\n",
       "  '8 AM esok': datetime.datetime(2021, 11, 28, 8, 0),\n",
       "  '2 oktober 2019 2pm': datetime.datetime(2019, 10, 2, 14, 0)},\n",
       " 'money': {'rm 3.2k': 'RM3200.0'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'boleh dtg 8pagi esok tak atau minggu depan? 2 oktober 2019 2pm, tlong bayar rm 3.2k sekali tau'\n",
    "normalizer.normalize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:index: 0, word: 031, queue: []\n",
      "DEBUG:root:index: 1, word: 313.212-2341, queue: ['tiga puluh satu']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'normalize': 'tiga puluh satu tiga satu tiga, dua satu dua dua tiga empat satu',\n",
       " 'date': {},\n",
       " 'money': {}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer.normalize(string7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:index: 0, word: Gambar, queue: []\n",
      "DEBUG:root:index: 1, word: ni, queue: ['Gambar']\n",
      "DEBUG:root:index: 2, word: membantu, queue: ['Gambar', 'ini']\n",
      "DEBUG:root:index: 3, word: ., queue: ['Gambar', 'ini', 'membantu']\n",
      "DEBUG:root:index: 4, word: Gambar, queue: ['Gambar', 'ini', 'membantu', '.']\n",
      "DEBUG:root:index: 5, word: tutorial, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar']\n",
      "DEBUG:root:index: 6, word: >, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial']\n",
      "DEBUG:root:index: 7, word: >, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>']\n",
      "DEBUG:root:index: 8, word: ., queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>']\n",
      "DEBUG:root:index: 9, word: facebook, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.']\n",
      "DEBUG:root:index: 10, word: ., queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook']\n",
      "DEBUG:root:index: 11, word: com, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.']\n",
      "DEBUG:root:index: 12, word: /, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com']\n",
      "DEBUG:root:index: 13, word: story, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com', '/']\n",
      "DEBUG:root:index: 14, word: ., queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com', '/', 'story']\n",
      "DEBUG:root:index: 15, word: story_fbid, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com', '/', 'story', '.']\n",
      "DEBUG:root:index: 16, word: =, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com', '/', 'story', '.', 'story_fbid']\n",
      "DEBUG:root:index: 17, word: 10206183032200965, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com', '/', 'story', '.', 'story_fbid', '=']\n",
      "DEBUG:root:index: 18, word: &, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com', '/', 'story', '.', 'story_fbid', '=', 'sepuluh quadrillion dua ratus enam trilion seratus lapan puluh tiga bilion tiga puluh dua juta dua ratus ribu sembilan ratus enam puluh lima']\n",
      "DEBUG:root:index: 19, word: id, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com', '/', 'story', '.', 'story_fbid', '=', 'sepuluh quadrillion dua ratus enam trilion seratus lapan puluh tiga bilion tiga puluh dua juta dua ratus ribu sembilan ratus enam puluh lima', '&']\n",
      "DEBUG:root:index: 20, word: =, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com', '/', 'story', '.', 'story_fbid', '=', 'sepuluh quadrillion dua ratus enam trilion seratus lapan puluh tiga bilion tiga puluh dua juta dua ratus ribu sembilan ratus enam puluh lima', '&', 'id']\n",
      "DEBUG:root:index: 21, word: 1418962070, queue: ['Gambar', 'ini', 'membantu', '.', 'Gambar', 'tutorial', '>', '>', '.', 'facebook', '.', 'com', '/', 'story', '.', 'story_fbid', '=', 'sepuluh quadrillion dua ratus enam trilion seratus lapan puluh tiga bilion tiga puluh dua juta dua ratus ribu sembilan ratus enam puluh lima', '&', 'id', '=']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'normalize': 'Gambar ini membantu . Gambar tutorial > > . facebook . com / story . story_fbid = sepuluh quadrillion dua ratus enam trilion seratus lapan puluh tiga bilion tiga puluh dua juta dua ratus ribu sembilan ratus enam puluh lima & id = 1418962070',\n",
       " 'date': {},\n",
       " 'money': {}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer.normalize('Gambar ni membantu. Gambar tutorial >>. facebook. com/story. story_fbid=10206183032200965&id=1418962070')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

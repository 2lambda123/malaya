{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [Malaya/example/transformer-huggingface](https://github.com/huseinzol05/Malaya/tree/master/example/transformer-huggingface).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the list of dataset we pretrained,\n",
    "\n",
    "Standard Bahasa dataset, \n",
    "\n",
    "1. [Malay-dataset/dumping](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping).\n",
    "2. [Malay-dataset/pure-text](https://github.com/huseinzol05/Malay-Dataset/tree/master/pure-text).\n",
    "\n",
    "Bahasa social media,\n",
    "\n",
    "1. [Malay-dataset/dumping/instagram](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping/instagram).\n",
    "2. [Malay-dataset/dumping/twitter](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping/twitter).\n",
    "\n",
    "Singlish / Manglish,\n",
    "\n",
    "1. [Malay-dataset/dumping/singlish](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping/singlish-text).\n",
    "2. [Malay-dataset/dumping/singapore-news](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping/singapore-news).\n",
    "\n",
    "For T5 transformer models, the models trained on MNLI both english and malay languages.\n",
    "\n",
    "**This interface not able us to use it to do custom training**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to download pretrained model for Transformer-Bahasa and use it for custom transfer-learning, you can download it here, https://github.com/huseinzol05/Malaya/tree/master/pretrained-model/, some notebooks to help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 3.31 s, total: 6.41 s\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list Transformer HuggingFace available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mesolitica/roberta-base-bahasa-cased</th>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/roberta-tiny-bahasa-cased</th>\n",
       "      <td>66.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/bert-base-standard-bahasa-cased</th>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/bert-tiny-standard-bahasa-cased</th>\n",
       "      <td>66.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/roberta-base-standard-bahasa-cased</th>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/roberta-tiny-standard-bahasa-cased</th>\n",
       "      <td>66.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/electra-base-generator-bahasa-cased</th>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/electra-small-generator-bahasa-cased</th>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-mnli-t5-super-tiny-standard-bahasa-cased</th>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-mnli-t5-tiny-standard-bahasa-cased</th>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-mnli-t5-small-standard-bahasa-cased</th>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-mnli-t5-base-standard-bahasa-cased</th>\n",
       "      <td>892.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Size (MB)\n",
       "mesolitica/roberta-base-bahasa-cased                    443.0\n",
       "mesolitica/roberta-tiny-bahasa-cased                     66.1\n",
       "mesolitica/bert-base-standard-bahasa-cased              443.0\n",
       "mesolitica/bert-tiny-standard-bahasa-cased               66.1\n",
       "mesolitica/roberta-base-standard-bahasa-cased           443.0\n",
       "mesolitica/roberta-tiny-standard-bahasa-cased            66.1\n",
       "mesolitica/electra-base-generator-bahasa-cased          140.0\n",
       "mesolitica/electra-small-generator-bahasa-cased          19.3\n",
       "mesolitica/finetune-mnli-t5-super-tiny-standard...       50.7\n",
       "mesolitica/finetune-mnli-t5-tiny-standard-bahas...      139.0\n",
       "mesolitica/finetune-mnli-t5-small-standard-baha...      242.0\n",
       "mesolitica/finetune-mnli-t5-base-standard-bahas...      892.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.transformer.available_huggingface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ['Kerajaan galakkan rakyat naik public transport tapi parking kat lrt ada 15. Reserved utk staff rapid je dah berpuluh. Park kereta tepi jalan kang kene saman dgn majlis perbandaran. Kereta pulak senang kene curi. Cctv pun tak ada. Naik grab dah 5-10 ringgit tiap hari. Gampang juga',\n",
    "           'Alaa Tun lek ahhh npe muka masam cmni kn agong kata usaha kerajaan terdahulu sejak selepas merdeka',\n",
    "           \"Orang ramai cakap nurse kerajaan garang. So i tell u this. Most of our local ppl will treat us as hamba abdi and they don't respect us as a nurse\",\n",
    "          'Pemuda mogok lapar desak kerajaan prihatin isu iklim',\n",
    "          'kerajaan perlu kisah isu iklim, pemuda mogok lapar',\n",
    "          'Kerajaan dicadang tubuh jawatankuasa khas tangani isu alam sekitar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HuggingFace model\n",
    "\n",
    "```python\n",
    "def huggingface(\n",
    "    model: str = 'mesolitica/electra-base-generator-bahasa-cased',\n",
    "    force_check: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load transformer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: str, optional (default='mesolitica/electra-base-generator-bahasa-cased')\n",
    "        Check available models at `malaya.transformer.available_transformer()`.\n",
    "    force_check: bool, optional (default=True)\n",
    "        Force check model one of malaya model.\n",
    "        Set to False if you have your own huggingface model.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = malaya.transformer.huggingface(model = 'mesolitica/electra-base-generator-bahasa-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = malaya.transformer.huggingface(model = 'mesolitica/finetune-mnli-t5-small-standard-bahasa-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have random sentences copied from Twitter, searched using `kerajaan` keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization\n",
    "\n",
    "Change a string or batch of strings to latent space / vectors representation.\n",
    "\n",
    "```python\n",
    "def vectorize(\n",
    "    self,\n",
    "    strings: List[str],\n",
    "    method: str = 'last',\n",
    "    method_token: str = 'first',\n",
    "    t5_head_logits: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Vectorize string inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strings: List[str]\n",
    "    method: str, optional (default='last')\n",
    "        hidden layers supported. Allowed values:\n",
    "\n",
    "        * ``'last'`` - last layer.\n",
    "        * ``'first'`` - first layer.\n",
    "        * ``'mean'`` - average all layers.\n",
    "\n",
    "        This only applicable for non T5 models.\n",
    "    method_token: str, optional (default='first')\n",
    "        token layers supported. Allowed values:\n",
    "\n",
    "        * ``'last'`` - last token.\n",
    "        * ``'first'`` - first token.\n",
    "        * ``'mean'`` - average all tokens.\n",
    "\n",
    "        usually pretrained models trained on `first` token for classification task.\n",
    "        This only applicable for non T5 models.\n",
    "    t5_head_logits: str, optional (default=True)\n",
    "        if True, will take head logits, else, last token.\n",
    "        This only applicable for T5 models.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: np.array\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 256)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = model.vectorize(strings)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000002 , 0.7221392 , 0.7054833 , 0.66821235, 0.64426583,\n",
       "        0.680184  ],\n",
       "       [0.7221392 , 0.9999999 , 0.6226625 , 0.7186684 , 0.69928503,\n",
       "        0.710604  ],\n",
       "       [0.7054833 , 0.6226625 , 1.        , 0.6309349 , 0.6351998 ,\n",
       "        0.6296929 ],\n",
       "       [0.66821235, 0.7186684 , 0.6309349 , 0.9999999 , 0.95470273,\n",
       "        0.8564712 ],\n",
       "       [0.64426583, 0.69928503, 0.6351998 , 0.95470273, 1.        ,\n",
       "        0.82342035],\n",
       "       [0.680184  , 0.710604  , 0.6296929 , 0.8564712 , 0.82342035,\n",
       "        1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = t5.vectorize(strings)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9999999 ,  0.811328  ,  0.31431305,  0.6870531 ,  0.8720901 ,\n",
       "         0.8247642 ],\n",
       "       [ 0.811328  ,  1.        ,  0.20530072,  0.7460517 ,  0.68824977,\n",
       "         0.8908862 ],\n",
       "       [ 0.31431305,  0.20530072,  0.9999999 , -0.32410604,  0.18822116,\n",
       "         0.14731692],\n",
       "       [ 0.6870531 ,  0.7460517 , -0.32410604,  1.        ,  0.64864993,\n",
       "         0.8376935 ],\n",
       "       [ 0.8720901 ,  0.68824977,  0.18822116,  0.64864993,  0.99999976,\n",
       "         0.7094655 ],\n",
       "       [ 0.8247642 ,  0.8908862 ,  0.14731692,  0.8376935 ,  0.7094655 ,\n",
       "         1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99999994,  0.54898286,  0.36759147,  0.4454881 ,  0.36219484,\n",
       "         0.50276357],\n",
       "       [ 0.54898286,  1.0000002 ,  0.5760975 ,  0.64363074,  0.07843906,\n",
       "         0.7960009 ],\n",
       "       [ 0.36759147,  0.5760975 ,  1.0000001 ,  0.29530543, -0.3313179 ,\n",
       "         0.63890153],\n",
       "       [ 0.4454881 ,  0.64363074,  0.29530543,  0.99999976,  0.22043958,\n",
       "         0.7768799 ],\n",
       "       [ 0.36219484,  0.07843906, -0.3313179 ,  0.22043958,  1.        ,\n",
       "         0.00962304],\n",
       "       [ 0.50276357,  0.7960009 ,  0.63890153,  0.7768799 ,  0.00962304,\n",
       "         0.99999976]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = t5.vectorize(strings, t5_head_logits = False)\n",
    "cosine_similarity(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def attention(\n",
    "    self,\n",
    "    strings: List[str],\n",
    "    method: str = 'last',\n",
    "    method_head: str = 'mean',\n",
    "    t5_attention: str = 'cross_attentions',\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get attention string inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strings: List[str]\n",
    "    method: str, optional (default='last')\n",
    "        Attention layer supported. Allowed values:\n",
    "\n",
    "        * ``'last'`` - attention from last layer.\n",
    "        * ``'first'`` - attention from first layer.\n",
    "        * ``'mean'`` - average attentions from all layers.\n",
    "    method_head: str, optional (default='mean')\n",
    "        attention head layer supported. Allowed values:\n",
    "\n",
    "        * ``'last'`` - attention from last layer.\n",
    "        * ``'first'`` - attention from first layer.\n",
    "        * ``'mean'`` - average attentions from all layers.\n",
    "    t5_attention: str, optional (default='cross_attentions')\n",
    "        attention type for T5 models. Allowed values:\n",
    "\n",
    "        * ``'cross_attentions'`` - cross attention.\n",
    "        * ``'encoder_attentions'`` - encoder attention.\n",
    "        * ``'decoder_attentions'`` - decoder attention.\n",
    "\n",
    "        This only applicable for T5 models.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : List[List[Tuple[str, float]]]\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can give list of strings or a string to get the attention, in this documentation, I just want to use a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.058868613),\n",
       "  ('Tun', 0.061252564),\n",
       "  ('lek', 0.068989426),\n",
       "  ('ahhh', 0.06439798),\n",
       "  ('npe', 0.05082519),\n",
       "  ('muka', 0.07244482),\n",
       "  ('masam', 0.053202268),\n",
       "  ('cmni', 0.048232816),\n",
       "  ('kn', 0.058161996),\n",
       "  ('agong', 0.06559847),\n",
       "  ('kata', 0.05514033),\n",
       "  ('usaha', 0.057437424),\n",
       "  ('kerajaan', 0.041059926),\n",
       "  ('terdahulu', 0.044371374),\n",
       "  ('sejak', 0.06925424),\n",
       "  ('selepas', 0.069484584),\n",
       "  ('merdeka', 0.061277922)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention([strings[1]], method = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.06183809),\n",
       "  ('Tun', 0.053071994),\n",
       "  ('lek', 0.04778199),\n",
       "  ('ahhh', 0.04694453),\n",
       "  ('npe', 0.052150376),\n",
       "  ('muka', 0.053927913),\n",
       "  ('masam', 0.05807442),\n",
       "  ('cmni', 0.08068735),\n",
       "  ('kn', 0.05034357),\n",
       "  ('agong', 0.054398913),\n",
       "  ('kata', 0.057019003),\n",
       "  ('usaha', 0.058209926),\n",
       "  ('kerajaan', 0.069378614),\n",
       "  ('terdahulu', 0.080670245),\n",
       "  ('sejak', 0.057985097),\n",
       "  ('selepas', 0.06437356),\n",
       "  ('merdeka', 0.053144373)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention([strings[1]], method = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.048754193),\n",
       "  ('Tun', 0.054038025),\n",
       "  ('lek', 0.05312951),\n",
       "  ('ahhh', 0.05706034),\n",
       "  ('npe', 0.04947073),\n",
       "  ('muka', 0.060973253),\n",
       "  ('masam', 0.05763235),\n",
       "  ('cmni', 0.0723617),\n",
       "  ('kn', 0.05290027),\n",
       "  ('agong', 0.053802904),\n",
       "  ('kata', 0.07015141),\n",
       "  ('usaha', 0.06137535),\n",
       "  ('kerajaan', 0.06380818),\n",
       "  ('terdahulu', 0.06389959),\n",
       "  ('sejak', 0.056653723),\n",
       "  ('selepas', 0.0524459),\n",
       "  ('merdeka', 0.07154253)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention([strings[1]], method = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.020544203),\n",
       "  ('Tun', 0.014763401),\n",
       "  ('lek', 0.016012296),\n",
       "  ('ahhh', 0.010291392),\n",
       "  ('npe', 0.015250254),\n",
       "  ('muka', 0.025421701),\n",
       "  ('masam', 0.009508574),\n",
       "  ('cmni', 0.02144086),\n",
       "  ('kn', 0.016106293),\n",
       "  ('agong', 0.011552193),\n",
       "  ('kata', 0.054768853),\n",
       "  ('usaha', 0.118117474),\n",
       "  ('kerajaan', 0.09078922),\n",
       "  ('terdahulu', 0.10955463),\n",
       "  ('sejak', 0.08275472),\n",
       "  ('selepas', 0.09991094),\n",
       "  ('merdeka', 0.28321296)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.attention([strings[1]], method = 'last', t5_attention = 'cross_attentions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.06314257),\n",
       "  ('Tun', 0.111133136),\n",
       "  ('lek', 0.02435303),\n",
       "  ('ahhh', 0.038024332),\n",
       "  ('npe', 0.02238715),\n",
       "  ('muka', 0.040521525),\n",
       "  ('masam', 0.017215427),\n",
       "  ('cmni', 0.03169653),\n",
       "  ('kn', 0.031364124),\n",
       "  ('agong', 0.055961456),\n",
       "  ('kata', 0.09224097),\n",
       "  ('usaha', 0.024536965),\n",
       "  ('kerajaan', 0.07011165),\n",
       "  ('terdahulu', 0.14476436),\n",
       "  ('sejak', 0.086011514),\n",
       "  ('selepas', 0.060092986),\n",
       "  ('merdeka', 0.08644233)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.attention([strings[1]], method = 'last', t5_attention = 'encoder_attentions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.20212816),\n",
       "  ('Tun', 0.12662782),\n",
       "  ('lek', 0.043903284),\n",
       "  ('ahhh', 0.06454229),\n",
       "  ('npe', 0.051137008),\n",
       "  ('muka', 0.05798657),\n",
       "  ('masam', 0.023386382),\n",
       "  ('cmni', 0.062053815),\n",
       "  ('kn', 0.052029867),\n",
       "  ('agong', 0.06720375),\n",
       "  ('kata', 0.064140044),\n",
       "  ('usaha', 0.05823552),\n",
       "  ('kerajaan', 0.036468714),\n",
       "  ('terdahulu', 0.025139563),\n",
       "  ('sejak', 0.016029576),\n",
       "  ('selepas', 0.021070626),\n",
       "  ('merdeka', 0.027917115)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.attention([strings[1]], method = 'last', t5_attention = 'decoder_attentions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = malaya.transformer.huggingface(model = 'mesolitica/roberta-base-standard-bahasa-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.052424457),\n",
       "  ('Tun', 0.08523697),\n",
       "  ('lek', 0.06813959),\n",
       "  ('ahhh', 0.06153968),\n",
       "  ('npe', 0.06513652),\n",
       "  ('muka', 0.059199467),\n",
       "  ('masam', 0.061626367),\n",
       "  ('cmni', 0.06737202),\n",
       "  ('kn', 0.06622731),\n",
       "  ('agong', 0.052743737),\n",
       "  ('kata', 0.067238666),\n",
       "  ('usaha', 0.044102527),\n",
       "  ('kerajaan', 0.060376044),\n",
       "  ('terdahulu', 0.041831747),\n",
       "  ('sejak', 0.04189242),\n",
       "  ('selepas', 0.039302666),\n",
       "  ('merdeka', 0.065609865)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta.attention([strings[1]], method = 'last')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

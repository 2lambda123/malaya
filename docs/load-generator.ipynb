{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [Malaya/example/generator](https://github.com/huseinzol05/Malaya/tree/master/example/generator).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.74 s, sys: 901 ms, total: 5.64 s\n",
      "Wall time: 8.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import malaya\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "This module trained heavily on news structure.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>Quantized Size (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small-t5</th>\n",
       "      <td>355.6</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Size (MB)  Quantized Size (MB)\n",
       "t5           1250.0                481.0\n",
       "small-t5      355.6                195.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.generator.available_transformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Transformer\n",
    "\n",
    "Transformer Generator in Malaya is quite unique, most of the text generative model we found on the internet like GPT2 or Markov, simply just continue prefix input from user, but not for Transformer Generator. We want to generate an article or karangan like high school when the users give 'isi penting'.\n",
    "\n",
    "```python\n",
    "def transformer(model: str = 't5', quantized: bool = False, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Load Transformer model to generate a string given a isu penting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str, optional (default='base')\n",
    "        Model architecture supported. Allowed values:\n",
    "\n",
    "        * ``'t5'`` - T5 BASE parameters.\n",
    "        * ``'small-t5'`` - T5 SMALL parameters.\n",
    "\n",
    "    quantized : bool, optional (default=False)\n",
    "        if True, will load 8-bit quantized model. \n",
    "        Quantized model not necessary faster, totally depends on the machine.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: malaya.model.t5.Generator class\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/generator.py:510: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/generator.py:512: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from /Users/huseinzolkepli/Malaya/generator-sample/t5/base/model/variables/variables\n"
     ]
    }
   ],
   "source": [
    "model = malaya.generator.transformer(model = 't5', quantized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isi_penting = ['Dr M perlu dikekalkan sebagai perdana menteri',\n",
    "              'Muhyiddin perlulah menolong Dr M',\n",
    "              'rakyat perlu menolong Muhyiddin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just want to test the model given this isi penting, because we all know, Dr M and Muhyiddin are not supporting each others in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate\n",
    "\n",
    "```python\n",
    "def greedy_decoder(self, strings: List[str]):\n",
    "    \"\"\"\n",
    "    generate a long text given a isi penting. \n",
    "    Decoder is greedy decoder with beam width size 1, alpha 0.5 .\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strings: List[str]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: str\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(': Presiden Bersatu, Tan Sri Muhyiddin Yassin perlu mengekalkan Tun Dr '\n",
      " 'Mahathir Mohamad sebagai perdana menteri berbanding Datuk Seri Anwar Ibrahim '\n",
      " 'yang hanya minta bantuan untuk menyelesaikan kemelut kedudukan '\n",
      " 'negara.Muhyiddin berkata, ini kerana semua pihak tahu masalah yang dihadapi '\n",
      " 'oleh Perdana Menteri adalah di luar bidang kuasa beliau sendiri.Katanya, '\n",
      " 'Muhyiddin perlu membantu beliau kerana beliau percaya rakyat Malaysia tahu '\n",
      " 'apa yang berlaku di luar bidang kuasa beliau.\"Apa yang berlaku di luar '\n",
      " 'bidang kuasa Dr Mahathir... semua tahu bahawa ini berlaku di bawah '\n",
      " 'kepimpinan Anwar.\"Muhyiddin dan seluruh rakyat yang tahu apa yang berlaku di '\n",
      " 'Johor.\"Ini kerana di Johor ini, majoriti menteri-menteri dalam Pakatan '\n",
      " 'Harapan banyak sangat ketua-ketua parti.\"Jadi Muhyiddin perlu bantu Dr '\n",
      " 'Mahathir sebab rakyat tahu apa yang berlaku di Johor Bahru,\" katanya dalam '\n",
      " 'satu kenyataan di sini, pada Jumaat.Dalam pada itu, Muhyiddin berkata, '\n",
      " 'rakyat juga perlu menolong Muhyiddin untuk menyelesaikan masalah yang '\n",
      " 'melanda negara ketika ini.Menurutnya, Muhyiddin perlu menggalas tugas dengan '\n",
      " 'baik dan memastikan keadaan negara berada dalam keadaan baik.')\n"
     ]
    }
   ],
   "source": [
    "pprint(model.greedy_decoder(isi_penting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "isi_penting = ['Neelofa tetap dengan keputusan untuk berkahwin akhir tahun ini',\n",
    "              'Long Tiger sanggup membantu Neelofa',\n",
    "              'Tiba-tiba Long Tiger bergaduh dengan Husein']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can give any isi penting even does not make any sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Kuala Lumpur: Pelakon, Neelofa tetap dengan keputusan dibuat untuk berkahwin '\n",
      " 'penutup tahun ini, selepas mengadakan pertemuan dengan Long Tiger. Neelofa '\n",
      " 'atau nama sebenarnya, Mohd Neelofa Ahmad Noor berkata, dia tidak pernah '\n",
      " 'merancang untuk berkahwin, namun menegaskan dirinya lebih mengutamakan masa '\n",
      " 'depan. \"Saya seronok bersama keluarga. Kalau kami berkahwin awal tahun ini, '\n",
      " 'ia mengambil masa yang lama. Itu impian saya tetapi biarlah, selepas setahun '\n",
      " 'saya berehat, saya akan mula bekerja. \"Jadi, apabila sering sesi pertemuan '\n",
      " 'dengan Long Tiger, saya kena tegas mengenai perkara ini. Bukan soal nak '\n",
      " 'memalukan diri sendiri tetapi siapa yang boleh menghentam saya,\" katanya '\n",
      " 'kepada Bh Online. Dalam sesi pertemuan itu, Neelofa yang juga pengacara '\n",
      " 'acara Top 5, bergaduh dengan Husein, dalam pergaduhan yang berlaku di '\n",
      " 'Kompleks Mahkamah Tinggi Syariah di sini, baru-baru ini. Ditanya mengenai '\n",
      " 'hubungannya dengan wanita itu, Neelofa berkata, mereka masih belum '\n",
      " 'menyelesaikan perkara itu dengan baik. \"Saya tidak tahu pasal semua ini, '\n",
      " 'tetapi ia akan diselesaikan menerusi cara baik. Tidak kiralah apa yang kami '\n",
      " 'tidak cakap pun. \"Pada mulanya kami hanya mahu membebaskan mereka daripada '\n",
      " 'sebarang isu, namun selepas beberapa hari bergaduh, kami akhirnya mengambil '\n",
      " 'keputusan untuk berkahwin dengan Hadiza Aziz. \"Jika mereka mahu, kami akan '\n",
      " 'membendung, namun pada masa yang sama, kami tidak mahu bergaduh dengan '\n",
      " 'lelaki yang digelar Long Tiger,\" katanya.')\n"
     ]
    }
   ],
   "source": [
    "pprint(model.greedy_decoder(isi_penting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about karangan like high school?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://mieadham86.blogspot.com/2016/09/isi-isi-penting-karangan-bahasa-melayu.html\n",
    "# KEBAIKAN AMALAN BERGOTONG-ROYONG\n",
    "\n",
    "isi_penting = ['Dapat memupuk semangat kerjasama',\n",
    "               'Dapat mengeratkan hubungan silaturahim.',\n",
    "               'Kebersihan kawasan persekitaran terpelihara.',\n",
    "               'Terhindar daripada wabak penyakit seperti Denggi',\n",
    "               'Mengisi masa lapang',\n",
    "               'Menerapkan nilai-nilai murni dalam kehidupan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dewasa ini, kes-kes seumpama denggi semakin menular di kalangan masyarakat. '\n",
      " 'Justeru, individu yang bertanggungjawab dan berkesan perlu memainkan peranan '\n",
      " 'penting dalam memastikan persekitaran dalam komuniti terjamin. Persis kata '\n",
      " 'peribahasa Melayu, melentur buluh biarlah dari rebungnya. Oleh itu, tindakan '\n",
      " 'yang wajar perlu diambil terutamanya jika kita mengamalkan sikap-sikap di '\n",
      " 'dalam komuniti supaya kehidupan kita tidak terjejas. Oleh itu, kita perlu '\n",
      " 'mengamalkan sikap bekerjasama dengan masyarakat dalam memastikan '\n",
      " 'persekitaran kita selamat. Jika kita sehati, sikap bekerjasama dapat dipupuk '\n",
      " 'dan dibudayakan dalam masyarakat. Maka, amalan ini secara tidak langsung '\n",
      " 'mampu membantu kita supaya tidak hidup lebih sejahtera. Pada masa yang sama, '\n",
      " 'ia juga dapat mengelakkan berlakunya sebarang masalah kesihatan dan '\n",
      " 'seterusnya membantu yang mungkin akan berlaku pada masa akan datang. '\n",
      " 'Masyarakat yang prihatin perlu meluahkan perasaan dan menitik beratkan soal '\n",
      " 'kebersihan kawasan persekitaran. Bak kata peribahasa Melayu, mencegah lebih '\n",
      " 'baik daripada merawat. Tamsilnya, pihak kerajaan perlu menjalankan usaha '\n",
      " 'yang bersungguh-sungguh sebagai tanggungjawab yang diamanahkan. Selain itu, '\n",
      " 'sikap masyarakat yang mengambil berat tentang kebersihan kawasan '\n",
      " 'persekitaran dapat membantu mengurangkan masalah kesihatan yang kian '\n",
      " 'menular. Secara tidak langsung, masyarakat awam akan melahirkan masyarakat '\n",
      " 'yang peka dan menghargai keberadaan anggota masyarakat di sekeliling mereka. '\n",
      " 'Bagi memastikan kebersihan kawasan persekitaran terjamin, kita perlu '\n",
      " 'memastikan komuniti yang berada ditaarapkan dalam keadaan bersih dan terurus '\n",
      " 'agar keselamatan masyarakat terjamin. Para pekerja dan ahli peniaga perlu '\n",
      " 'memastikan kebersihan kawasan mereka dijaga dengan baik. Hal ini kerana, '\n",
      " 'kita akan berhadapan dengan pelbagai masalah kesihatan yang mengakibatkan '\n",
      " 'Malaysia menjadi negara ketiga yang paling teruk terkena jangkitan demam '\n",
      " 'denggi pada tahun lepas. Sekiranya kita mempraktikkan amalan berkenaan, kita '\n",
      " 'akan berhadapan dengan bahaya. Sekiranya aktiviti ini diteruskan, kita akan '\n",
      " 'terencat daripada jumlah kes penyakit yang menyerang. Secara tidak langsung, '\n",
      " 'kita akan dapat membendung penularan wabak penyakit di kalangan masyarakat. '\n",
      " 'Sebagai contoh, wabak denggi di Malaysia berkemungkinan boleh menularkan '\n",
      " 'jangkitan kepada penduduk di negeri-negeri yang lain. Oleh itu, langkah ini '\n",
      " 'wajar dan mempunyai sistem pengurusan kebersihan yang terbaik bagi '\n",
      " 'membolehkan jumlah pesakit yang dirawat di hospital meningkat. Kesannya, ia '\n",
      " 'dapat membantu kita untuk mengamalkan kaedah yang betul dan matang dalam '\n",
      " 'kehidupan. Selain itu, sekiranya kita mengamalkan sikap kerja, kita akan '\n",
      " 'sentiasa berusaha supaya kita terhindar daripada wabak penyakit yang '\n",
      " 'menyerang penduduk di sekeliling kita. Bak kata peribahasa Melayu, mencegah '\n",
      " 'lebih baik daripada merawat. Semua pihak perlu berganding bahu bagai aur '\n",
      " 'dengan tebing untuk menjaga kesihatan dan keselamatan para pekerja dalam '\n",
      " 'kawasan yang sangat rentan. Kebersihan kawasan persekitaran merupakan elemen '\n",
      " 'yang penting dalam memastikan persekitaran kita selamat daripada jangkitan '\n",
      " 'wabak seperti denggi. Kita tentunya tidak mahu ada tempat yang kotor dan '\n",
      " 'busuk namun kita tidak boleh berbuat demikian kerana ia merupakan elemen '\n",
      " 'yang tidak boleh dijual beli. Oleh itu, jika kita mengamalkan sikap kerja '\n",
      " \"yang 'membersihkan', kita akan menjadi lebih baik dan selamat daripada wabak \"\n",
      " 'penyakit seperti denggi. Jika kita mengamalkan sikap ini, kita akan menjadi '\n",
      " 'lebih baik dan selamat daripada ancaman penyakit-penyakit yang berbahaya. '\n",
      " 'Tidak kira apabila kita sudah terbiasa dengan amalan ini, sudah pasti '\n",
      " 'keselamatan kita akan terjamin. Selain itu, kita perlulah dirikan amalan '\n",
      " 'seperti rajin mencuci tangan menggunakan sabun atau segala benda lain kerana '\n",
      " 'kita juga mempunyai tempat yang sesuai untuk membasuh tangan dengan baik. '\n",
      " 'Perkara ini boleh menjadi perubahan kepada amalan kita dalam kehidupan '\n",
      " 'apabila kita berusaha untuk membersihkan kawasan yang telah dikenal pasti. '\n",
      " 'Secara tidak langsung, kita dapat bertukar-tukar fikiran dan mengamalkan '\n",
      " 'nilai-nilai murni dalam kehidupan. Hal ini demikian kerana, kita antara '\n",
      " 'mereka yang merancang untuk melakukan sesuatu bagi mengelakkan berlakunya '\n",
      " 'kemalangan. Hakikatnya, amalan membasuh tangan menggunakan sabun atau benda '\n",
      " 'lain adalah berniat buruk kerana akan dapat mengganggu kelancaran proses '\n",
      " 'pemanduan terutamanya apabila tidur. Kesannya, kita akan mewujudkan '\n",
      " 'masyarakat yang bertimbang rasa dan bergantung kepada orang lain untuk '\n",
      " 'melakukan kerja mereka walaupun di mana mereka berada. Selain itu, kita '\n",
      " 'dapat mengamalkan cara yang betul dalam memastikan kebersihan kawasan '\n",
      " 'persekitaran adalah terjamin. Kita tidak boleh menyembunyikan diri daripada '\n",
      " 'pengetahuan umum seperti di tempat awam seperti tempat letak kereta yang '\n",
      " 'sering digunakan oleh orang ramai. Jika kita menggunakan tandas awam dan '\n",
      " 'menggunakan botol air untuk membersihkan kawasan berkenaan, kita akan mudah '\n",
      " 'terdedah dengan wabak penyakit yang membahayakan kesihatan. Selain itu, kita '\n",
      " 'juga perlu sentiasa berjaga-jaga dengan memakai penutup mulut dan hidung '\n",
      " 'jika ada demam. Jika kita tidak mengamalkan kebersihan, besar kemungkinan ia '\n",
      " 'boleh mengundang kepada penularan wabak penyakit. Bak kata peribahasa '\n",
      " 'Melayu, mencegah lebih baik daripada merawat. Jika kita membuat keputusan '\n",
      " 'untuk menutup mulut atau hidung dengan pakaian yang bersih dan bijak, kita '\n",
      " 'akan menjadi lebih baik daripada menyelamatkan diri sendiri daripada '\n",
      " 'jangkitan penyakit. Andai kata, pengamal media dapat menggunakan telefon '\n",
      " 'pintar ketika membuat liputan di media massa, proses ini akan membuatkan '\n",
      " 'kehidupan mereka lebih mudah dan sukar. Selain itu, proses nyah kuman juga '\n",
      " 'dapat memastikan kebersihan di kawasan rumah kita terjamin. Contohnya, semua '\n",
      " 'stesen minyak dan restoran makanan segera perlu memakai penutup mulut dan '\n",
      " 'hidung secara betul agar penularan wabak penyakit dapat dihentikan. Penonton '\n",
      " 'yang berada di dalam juga wajar digalakkan untuk menggunakan penutup mulut '\n",
      " 'dan hidung agar mudah terkena jangkitan kuman. Selain itu, pengisian masa '\n",
      " 'lapang yang terdapat di kawasan tempat awam dapat mendidik masyarakat untuk '\n",
      " 'mengamalkan nilai-nilai murni seperti rajin mencuci tangan menggunakan sabun '\n",
      " 'dan air supaya tidak terdedah kepada virus denggi. Walaupun kita mempunyai '\n",
      " 'ramai kenalan yang ramai tetapi tidak dapat mengamalkannya kerana kita perlu '\n",
      " 'adalah rakan yang sedar dan memahami tugas masing-masing. Pelbagai cara yang '\n",
      " 'boleh kita lakukan bagi memastikan hospital atau klinik-klinik kerajaan '\n",
      " 'menjadi')\n"
     ]
    }
   ],
   "source": [
    "pprint(model.greedy_decoder(isi_penting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://mieadham86.blogspot.com/2016/09/isi-isi-penting-karangan-bahasa-melayu.html\n",
    "# CARA MENJADI MURID CEMERLANG\n",
    "\n",
    "isi_penting = ['Rajin berusaha – tidak mudah putus asa',\n",
    "               'Menghormati orang yang lebih tua – mendapat keberkatan',\n",
    "               'Melibatkan diri secara aktif dalam bidang kokurikulum',\n",
    "               'Memberi tumpuan ketika guru mengajar.',\n",
    "               'Berdisiplin – menepati jadual yang disediakan.',\n",
    "               'Bercita-cita tinggi – mempunyai keazaman yang tinggi untuk berjaya']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sejak akhir-akhir ini, pelbagai isu yang hangat diperkatakan oleh masyarakat '\n",
      " 'yang berkait dengan sambutan Hari Raya Aidilfitri. Pelbagai faktor yang '\n",
      " 'melatari perkara yang berlaku dalam kalangan masyarakat hari ini, khususnya '\n",
      " 'bagi golongan muda. Dikatakan bahawa kehidupan kita hari ini semakin '\n",
      " 'mencabar terutamanya kesibukan dalam menjalankan tugas dan mengajar. '\n",
      " 'Justeru, tidak dinafikan apabila semakin jauh kita, semakin ramai yang '\n",
      " 'memilih untuk lalai atau tidak mematuhi arahan yang telah ditetapkan. '\n",
      " 'Mendepani cabaran ini, golongan muda terpaksa menempuhi segala cabaran untuk '\n",
      " 'menjadi lebih baik dan lebih baik. Minda yang perlu diterapkan, terutama di '\n",
      " 'dalam kelas untuk mempelajari ilmu pengetahuan. Jika tidak, kita akan '\n",
      " 'menjadi lebih mudah untuk menilai dan menyelesaikan masalah yang dihadapi. '\n",
      " 'Oleh itu, kita perlu berfikir untuk menetapkan langkah yang patut atau perlu '\n",
      " 'dilaksanakan bagi mengatasi masalah yang berlaku. Selain itu, guru-guru juga '\n",
      " 'harus mendidik peserta-peserta dalam kelas supaya dapat menjalankan kegiatan '\n",
      " 'dengan lebih serius dan berkesan. Guru-Guru juga seharusnya berusaha untuk '\n",
      " 'meningkatkan kemahiran mereka dalam kalangan pelajar. Seperti peribahasa '\n",
      " 'Melayu, melentur buluh biarlah dari rebungnya. Setiap insan mempunyai '\n",
      " 'peranan masing-masing dan tanggungjawab yang masing-masing. Kesempatan untuk '\n",
      " 'memberikan nasihat dan teguran adalah lebih penting dan membantu secara '\n",
      " 'halus dan bijaksana dalam melakukan sesuatu. Selain itu, guru-guru hendaklah '\n",
      " 'berani untuk melakukan sesuatu perkara yang memberi manfaat kepada para '\n",
      " 'pelajar yang lain. Cara ini adalah dengan melakukan aktiviti-aktiviti yang '\n",
      " 'boleh memberi manfaat kepada para pelajar. Selain itu, guru-guru juga '\n",
      " 'perlulah menjaga disiplin mereka dengan sebaik-baiknya. Dalam menyampaikan '\n",
      " 'nasihat dan teguran secara berterusan, pelajar juga boleh melakukan perkara '\n",
      " 'yang boleh mendatangkan mudarat. Anak-Anak awal pelajar dan rakan-rakan '\n",
      " 'mereka juga boleh melakukan tugas yang bermanfaat. Keadaan ini membolehkan '\n",
      " 'mereka untuk lebih berusaha dan memberikan nasihat yang berguna kepada kaum '\n",
      " 'lain. Oleh itu, mereka perlu sentiasa mengingati dan mendidik pelajar dengan '\n",
      " 'nilai-nilai yang murni. Setiap orang mempunyai impian yang tinggi untuk '\n",
      " 'berjaya. Sama ada kita berjaya atau tidak, pencapaian yang diperoleh setelah '\n",
      " 'tamat belajar akan memberikan kita nilai yang baik dan perlu menjadi contoh '\n",
      " 'yang baik untuk negara kita.')\n"
     ]
    }
   ],
   "source": [
    "pprint(model.greedy_decoder(isi_penting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GPT2\n",
    "\n",
    "Malaya provided Pretrained GPT2 model, specific to Malay, we called it GPT2-Bahasa. This interface not able us to use it to do custom training.\n",
    "\n",
    "GPT2-Bahasa was pretrained on ~0.9 billion words, and below is the list of dataset we trained,\n",
    "\n",
    "1. [dumping wikipedia (222MB)](https://github.com/huseinzol05/Malaya-Dataset#wikipedia-1).\n",
    "2. [local news (257MB)](https://github.com/huseinzol05/Malaya-Dataset#public-news).\n",
    "3. [local parliament text (45MB)](https://github.com/huseinzol05/Malaya-Dataset#parliament).\n",
    "4. [IIUM Confession (74MB)](https://github.com/huseinzol05/Malaya-Dataset#iium-confession).\n",
    "5. [Wattpad (74MB)](https://github.com/huseinzol05/Malaya-Dataset#wattpad).\n",
    "6. [Academia PDF (42MB)](https://github.com/huseinzol05/Malaya-Dataset#academia-pdf).\n",
    "7. [Common-Crawl (3GB)](https://github.com/huseinzol05/malaya-dataset#common-crawl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to download pretrained model for GPT2-Bahasa and use it for custom transfer-learning, you can download it here, https://github.com/huseinzol05/Malaya/tree/master/pretrained-model/gpt2, some notebooks to help you get started.\n",
    "\n",
    "**Here we hope these models are not use to finetune for spreading fake news**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load model\n",
    "\n",
    "GPT2-Bahasa only available `117M` and `345M` models.\n",
    "\n",
    "1. `117M` size around 442MB.\n",
    "2. `345M` is around 1.2GB.\n",
    "\n",
    "```python\n",
    "def gpt2(\n",
    "    model: str = '345M',\n",
    "    generate_length: int = 256,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int = 40,\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Load GPT2 model to generate a string given a prefix string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str, optional (default='345M')\n",
    "        Model architecture supported. Allowed values:\n",
    "\n",
    "        * ``'117M'`` - GPT2 117M parameters.\n",
    "        * ``'345M'`` - GPT2 345M parameters.\n",
    "\n",
    "    generate_length : int, optional (default=256)\n",
    "        length of sentence to generate.\n",
    "    temperature : float, optional (default=1.0)\n",
    "        temperature value, value should between 0 and 1.\n",
    "    top_k : int, optional (default=40)\n",
    "        top-k in nucleus sampling selection.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: malaya.transformers.gpt2.Model class\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:19: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:140: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:141: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:142: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:142: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /Users/huseinzolkepli/Malaya/gpt2/117M/gpt2-bahasa-117M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = malaya.generator.gpt2(model = '117M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'ceritanya sebegini, aku bangun pagi baca surat khabar berita harian, tetiba aku nampak cerita seram, '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate\n",
    "\n",
    "`model.generate` accepts a string.\n",
    "\n",
    "```python\n",
    "def generate(self, string: str):\n",
    "    \"\"\"\n",
    "    generate a text given an initial string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: str\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ceritanya sebegini, aku bangun pagi baca surat khabar berita harian, tetiba aku nampak cerita seram, ara aku yang lain keluar, aku pandang cerita tapi tak ingat, aku takut dan bimbang aku terpaksa marah kerana hati aku yang berada di sekeliling aku tadi tak putus-putus.\n",
      "Dalam diam, aku juga merasa kagum dan terharu bila aku bangun pagi untuk bangun dan tengok kisah seram ni, masa tu aku terus pandang, bila aku berada dalam bilik yang indah, aku tahu tentang benda yang nak diperkatakan.\n",
      "“Tu sikit, dengan banyak masa aku nak keluar dan keluar aku dah mula bangun pagi, aku nak keluar lagi, lepas tu nanti terus masuk ke bilik sambil nampak benda yang tak ada yang nak diperkatakan.\n",
      "Tak tau cerita tu macam benda yang boleh aku buat kalau rasa macam cerita.\n",
      "Sampai di bilik, aku pun rasa macam, benda yang nak diperkatakan tu bukan benda yang perlu aku buat.\n",
      "Macam tak percaya apa yang aku buat ni?\n",
      "Mungkin benda yang nak diperkatakan itu boleh buat aku jugak, cuma benda yang boleh bagi aku kata tak logik atau memang betul.\n",
      "Cuma yang paling aku nak cakap ni adalah benda pelik yang aku fikir nak nampak yang tak boleh dan kalau tak logik pun tak patut.\n",
      "So, apa kata dorang mainkan benda yang aku cakap ni.\n",
      "Rasa pelik dan amat pelik kan?\n",
      "Macam nak buat orang lain jadi macam benda pelik dan susah sangat nak buat\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/huseinzolkepli/Malaya/gpt2/345M/gpt2-bahasa-345M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = malaya.generator.gpt2(model = '345M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ceritanya sebegini, aku bangun pagi baca surat khabar berita harian, tetiba aku nampak cerita seram, omputeh-uteh cerita lama-lama, seram tak boleh bayang\n",
      "Sebelum kejadian, dalam 2 jam aku buat panggilan polis , lepas tu kira la sendiri nak ke lokasi.\n",
      "Tengok cerita lama..\n",
      "Sekarang ni, apa yang aku lalui, kita yang jaga diri, kita yang jaga kesihatan dan juga kita yang jaga minda dalam hidup.\n",
      "Maka, inilah jalan penyelesaian terbaiknya.\n",
      "Jangan lupakan manusia\n",
      "Orang yang paling ditakuti untuk berjaya dalam hidup, tidak akan jumpa yang tersayang!\n",
      "Jangan rosakkan masa depannya, ingatlah apa yang kita nak buat, walaupun pahit untuk ditelan.\n",
      "Jangan lupakan orang lain - masa depan mereka.\n",
      "Jangan lupakan orang - masa itulah kita yang lebih dicintai.\n",
      "Jangan lupakan orang - orang yang kita sayang, mereka bukan orang yang tersayang!\n",
      "Jangan lupakan orang - orang yang kita cinta, mereka cinta pada kita.\n",
      "Jangan lupakan diri - diri kita - yang kita punya, yang kita tinggal adalah masa lalu kita.\n",
      "Jangan lupakan orang lain - orang yang kita cinta, lebih indah dari masa lalu kita.\n",
      "Jangan lupakan semua orang - orang yang tinggal ataupun hidup.\n",
      "Jangan cuba lupakan diri kita - kerja keras dan selalu ada masa depan kita.\n",
      "Jangan pernah putus rasa - kecewa kerana kita telah banyak berubah.\n",
      "Jangan pernah putus putus asa kerana kita\n"
     ]
    }
   ],
   "source": [
    "string = 'ceritanya sebegini, aku bangun pagi baca surat khabar berita harian, tetiba aku nampak cerita seram, '\n",
    "print(model.generate(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Babble method\n",
    "\n",
    "We also can generate a text like GPT2 using Transformer-Bahasa. Right now only supported BERT, ALBERT and ELECTRA.\n",
    "\n",
    "```python\n",
    "def babble(\n",
    "    string: str,\n",
    "    model,\n",
    "    generate_length: int = 30,\n",
    "    leed_out_len: int = 1,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int = 100,\n",
    "    burnin: int = 15,\n",
    "    batch_size: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use pretrained transformer models to generate a string given a prefix string.\n",
    "    https://github.com/nyu-dl/bert-gen, https://arxiv.org/abs/1902.04094\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string: str\n",
    "    model: object\n",
    "        transformer interface object. Right now only supported BERT, ALBERT.\n",
    "    generate_length : int, optional (default=256)\n",
    "        length of sentence to generate.\n",
    "    leed_out_len : int, optional (default=1)\n",
    "        length of extra masks for each iteration. \n",
    "    temperature: float, optional (default=1.0)\n",
    "        logits * temperature.\n",
    "    top_k: int, optional (default=100)\n",
    "        k for top-k sampling.\n",
    "    burnin: int, optional (default=15)\n",
    "        for the first burnin steps, sample from the entire next word distribution, instead of top_k.\n",
    "    batch_size: int, optional (default=5)\n",
    "        generate sentences size of batch_size.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: List[str]\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you already installed `tensorflow-probability`,\n",
    "\n",
    "```bash\n",
    "pip3 install tensorflow-probability==0.7.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow-probability==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/modeling.py:242: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:79: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:93: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/sampling.py:26: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:115: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:118: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:119: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:121: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:122: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:128: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:130: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /Users/huseinzolkepli/Malaya/electra-model/base/electra-base/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "electra = malaya.transformer.load(model = 'electra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , terseksa juga hidup di sekeliling aku . Diorang tak tahu sebab diorang tahu titik hitam yang mana kita tengok dari mana kita sendiri nampak cerita ke . Haih .',\n",
       " 'ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , tengah baca benda besar pasal bumbung bilik . Rasanya sejuk macam pulau harapan . So aku baca cerita seram pelik . Jadi sedih juga dengar cerita seram seram ni .',\n",
       " 'ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , lalu ibu ambil pusing bagi buku sejarah . Dah baca marsh pastu aku dah buat thread seram , ada dalam masa terdekat baru bangun . Sedih , hidup lagi',\n",
       " 'ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , mesti seram sampai aku ikut takdir Allah bagi betul2 aib kita kembali menulis mengenai kisah cinta aku ini malam , aku tersedar selepas ada seorang lelaki tersedar .',\n",
       " 'ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , sedangkan yang baca pasal negara berpagarism memang patut berterima kasih . Kata ayah , ingatkan boleh mandi atau bilik pun boleh , kena air dan bukannya ikut kemampuan']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.generator.babble(string, electra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngrams\n",
    "\n",
    "You can generate ngrams pretty easy using this interface,\n",
    "\n",
    "```python\n",
    "def ngrams(\n",
    "    sequence,\n",
    "    n: int,\n",
    "    pad_left = False,\n",
    "    pad_right = False,\n",
    "    left_pad_symbol = None,\n",
    "    right_pad_symbol = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    generate ngrams.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : List[str]\n",
    "        list of tokenize words.\n",
    "    n : int\n",
    "        ngram size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ngram: list\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('saya', 'suka'), ('suka', 'makan'), ('makan', 'ayam')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'saya suka makan ayam'\n",
    "\n",
    "list(malaya.generator.ngrams(string.split(), n = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 'saya'),\n",
       " ('saya', 'suka'),\n",
       " ('suka', 'makan'),\n",
       " ('makan', 'ayam'),\n",
       " ('ayam', None)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(malaya.generator.ngrams(string.split(), n = 2, pad_left = True, pad_right = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('START', 'saya'),\n",
       " ('saya', 'suka'),\n",
       " ('suka', 'makan'),\n",
       " ('makan', 'ayam'),\n",
       " ('ayam', None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(malaya.generator.ngrams(string.split(), n = 2, pad_left = True, pad_right = True,\n",
    "                            left_pad_symbol = 'START'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('START', 'saya'),\n",
       " ('saya', 'suka'),\n",
       " ('suka', 'makan'),\n",
       " ('makan', 'ayam'),\n",
       " ('ayam', 'END')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(malaya.generator.ngrams(string.split(), n = 2, pad_left = True, pad_right = True,\n",
    "                            left_pad_symbol = 'START', right_pad_symbol = 'END'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [Malaya/example/zeroshot-classification](https://github.com/huseinzol05/Malaya/tree/master/example/zeroshot-classification).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.82 s, sys: 654 ms, total: 5.47 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is zero-shot classification\n",
    "\n",
    "Commonly we supervised a machine learning on specific labels, negative / positive for sentiment, anger / happy / sadness for emotion and etc. The model cannot give an output if we want to know how much percentage of 'jealous' in emotion analysis model because supported labels are only {anger, happy, sadness}. Imagine, for example, trying to identify a text without ever having seen one 'jealous' label before, impossible. **So, zero-shot trying to solve this problem.**\n",
    "\n",
    "zero-shot learning refers to the process by which a machine learns how to recognize objects (image, text, any features) without any labeled training data to help in the classification.\n",
    "\n",
    "[Yin et al. (2019)](https://arxiv.org/abs/1909.00161) stated in his paper, any pretrained language model finetuned on text similarity actually can acted as an out-of-the-box zero-shot text classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we are going to use transformer models from `malaya.similarity.transformer` with a little tweaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available Transformer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>423.4</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiny-bert</th>\n",
       "      <td>56.6</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albert</th>\n",
       "      <td>48.3</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiny-albert</th>\n",
       "      <td>21.9</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlnet</th>\n",
       "      <td>448.7</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alxlnet</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Size (MB)  Accuracy\n",
       "bert             423.4     0.885\n",
       "tiny-bert         56.6     0.873\n",
       "albert            48.3     0.873\n",
       "tiny-albert       21.9     0.824\n",
       "xlnet            448.7     0.784\n",
       "alxlnet           49.0     0.888"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.zero_shot.classification.available_transformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained on [Quora Question Pairs](https://github.com/huseinzol05/Malay-Dataset#quora), [translated SNLI](https://github.com/huseinzol05/Malay-Dataset#snli) and [translated MNLI](https://github.com/huseinzol05/Malay-Dataset#mnli)\n",
    "\n",
    "Make sure you can check accuracy chart from here first before select a model, https://malaya.readthedocs.io/en/latest/Accuracy.html#similarity\n",
    "\n",
    "**You might want to use ALXLNET, a very small size, 49MB, but the accuracy is still on the top notch.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load transformer model\n",
    "\n",
    "In this example, I am going to load `alxlnet`, feel free to use any available models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/function/__init__.py:54: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/function/__init__.py:55: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/function/__init__.py:49: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = malaya.zero_shot.classification.transformer(model = 'alxlnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict batch\n",
    "\n",
    "```python\n",
    "def predict_proba(self, strings: List[str], labels: List[str]):\n",
    "    \"\"\"\n",
    "    classify list of strings and return probability.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strings : List[str]\n",
    "    labels : List[str]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list: list of float\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "Because it is a zero-shot, we need to give labels for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy from twitter\n",
    "\n",
    "string = 'gov macam bengong, kami nk pilihan raya, gov backdoor, sakai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'najib razak': 0.011697772,\n",
       "  'mahathir': 0.030579083,\n",
       "  'kerajaan': 0.038274202,\n",
       "  'PRU': 0.74709743,\n",
       "  'anarki': 0.054001417}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([string], labels = ['najib razak', 'mahathir', 'kerajaan', 'PRU', 'anarki'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'tolong order foodpanda jab, lapar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'makan': 0.4262973,\n",
       "  'makanan': 0.94525576,\n",
       "  'novel': 0.0016873145,\n",
       "  'buku': 0.00282516,\n",
       "  'kerajaan': 0.0013985565,\n",
       "  'food delivery': 0.9190869}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([string], labels = ['makan', 'makanan', 'novel', 'buku', 'kerajaan', 'food delivery'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model understood `order foodpanda` got close relationship with `makan`, `makanan` and `food delivery`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'kerajaan sebenarnya sangat prihatin dengan rakyat, bagi duit bantuan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'makan': 0.0010322841,\n",
       "  'makanan': 0.0059771817,\n",
       "  'novel': 0.0068290858,\n",
       "  'buku': 0.00083946186,\n",
       "  'kerajaan': 0.9823078,\n",
       "  'food delivery': 0.017137317,\n",
       "  'kerajaan jahat': 0.4863779,\n",
       "  'kerajaan prihatin': 0.96803045,\n",
       "  'bantuan rakyat': 0.94919217}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([string], labels = ['makan', 'makanan', 'novel', 'buku', 'kerajaan', 'food delivery',\n",
    "                                       'kerajaan jahat', 'kerajaan prihatin', 'bantuan rakyat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking models\n",
    "\n",
    "More information, you can read at https://malaya.readthedocs.io/en/latest/Stack.html\n",
    "\n",
    "If you want to stack zero-shot classification models, you need to pass labels using keyword parameter,\n",
    "\n",
    "```python\n",
    "malaya.stack.predict_stack([model1, model2], List[str], labels = List[str])\n",
    "```\n",
    "\n",
    "We will passed `labels` as `**kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/albert/tokenization.py:240: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:loading sentence piece model\n"
     ]
    }
   ],
   "source": [
    "alxlnet = malaya.zero_shot.classification.transformer(model = 'alxlnet')\n",
    "albert = malaya.zero_shot.classification.transformer(model = 'albert')\n",
    "tiny_bert = malaya.zero_shot.classification.transformer(model = 'tiny-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'makan': 0.0044827852,\n",
       "  'makanan': 0.0027062024,\n",
       "  'novel': 0.0020867025,\n",
       "  'buku': 0.013082165,\n",
       "  'kerajaan': 0.8859287,\n",
       "  'food delivery': 0.0028363755,\n",
       "  'kerajaan jahat': 0.018133936,\n",
       "  'kerajaan prihatin': 0.9922408,\n",
       "  'bantuan rakyat': 0.909674}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'kerajaan sebenarnya sangat prihatin dengan rakyat, bagi duit bantuan'\n",
    "labels = ['makan', 'makanan', 'novel', 'buku', 'kerajaan', 'food delivery', \n",
    " 'kerajaan jahat', 'kerajaan prihatin', 'bantuan rakyat']\n",
    "malaya.stack.predict_stack([alxlnet, albert, tiny_bert], [string], \n",
    "                           labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

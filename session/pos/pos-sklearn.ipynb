{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(string):\n",
    "    string = re.sub('[^A-Za-z0-9\\-\\/ ]+', ' ', string).split()\n",
    "    return [y.strip() for y in string]\n",
    "\n",
    "def to_title(string):\n",
    "    if string.isupper():\n",
    "        string = string.title()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pos-data-v3.json','r') as fopen:\n",
    "    dataset = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = [], []\n",
    "for i in dataset:\n",
    "    try:\n",
    "        texts.append(process_string(i[0])[0].lower())\n",
    "        labels.append(i[-1])\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "def iter_seq(x):\n",
    "    return np.array([x[i: i+seq_len] for i in range(0, len(x)-seq_len, 1)])\n",
    "\n",
    "def to_train_seq(*args):\n",
    "    return [iter_seq(x) for x in args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.util import untag\n",
    "\n",
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'prev_word-prefix-1': '' if index == 0 else sentence[index - 1][0],\n",
    "        'prev_word-prefix-2': '' if index == 0 else sentence[index - 1][:2],\n",
    "        'prev_word-prefix-3': '' if index == 0 else sentence[index - 1][:3],\n",
    "        'prev_word-suffix-1': '' if index == 0 else sentence[index - 1][-1],\n",
    "        'prev_word-suffix-2': '' if index == 0 else sentence[index - 1][-2:],\n",
    "        'prev_word-suffix-3': '' if index == 0 else sentence[index - 1][-3:],\n",
    "        'next_word-prefix-1': '' if index == len(sentence) - 1 else sentence[index + 1][0],\n",
    "        'next_word-prefix-2': '' if index == len(sentence) - 1 else sentence[index + 1][:2],\n",
    "        'next_word-prefix-3': '' if index == len(sentence) - 1 else sentence[index + 1][:3],\n",
    "        'next_word-suffix-1': '' if index == len(sentence) - 1 else sentence[index + 1][-1],\n",
    "        'next_word-suffix-2': '' if index == len(sentence) - 1 else sentence[index + 1][-2:],\n",
    "        'next_word-suffix-3': '' if index == len(sentence) - 1 else sentence[index + 1][-3:],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "    }\n",
    "\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    " \n",
    "    for tagged in tagged_sentences:\n",
    "        X.append([features(untag(tagged), index) for index in range(len(tagged))])\n",
    "        y.append([tag for _, tag in tagged])\n",
    " \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = list(map(lambda X: (X[0],X[1]), list(zip(texts, labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103367, 50, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_seq = to_train_seq(combined)[0]\n",
    "combined_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = transform_to_dataset(combined_seq)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32min 22s, sys: 45.6 s, total: 33min 8s\n",
      "Wall time: 33min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'PROPN',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CCONJ',\n",
       " 'NUM',\n",
       " 'ADJ',\n",
       " 'PART',\n",
       " 'AUX',\n",
       " 'SCONJ',\n",
       " 'SYM']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('X')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917356367386992"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(test_X)\n",
    "metrics.flat_f1_score(test_Y, y_pred,\n",
    "                      average='weighted', labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        PRON      0.998     0.997     0.998     47911\n",
      "         DET      0.990     0.993     0.991     39932\n",
      "        NOUN      0.988     0.988     0.988    270045\n",
      "        VERB      0.997     0.997     0.997    122015\n",
      "       PROPN      0.989     0.988     0.988    225893\n",
      "         ADP      0.997     0.998     0.997    120358\n",
      "         ADV      0.992     0.991     0.991     47753\n",
      "       CCONJ      0.997     0.998     0.997     36696\n",
      "         NUM      0.993     0.995     0.994     43748\n",
      "         ADJ      0.985     0.988     0.986     45244\n",
      "        PART      0.992     0.995     0.993      5975\n",
      "         AUX      1.000     1.000     1.000     10505\n",
      "       SCONJ      0.994     0.987     0.990     14798\n",
      "         SYM      0.998     0.997     0.998      2483\n",
      "\n",
      "   micro avg      0.992     0.992     0.992   1033356\n",
      "   macro avg      0.994     0.994     0.994   1033356\n",
      "weighted avg      0.992     0.992     0.992   1033356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(\n",
    "    test_Y, y_pred, labels=labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('crf-pos.pkl','wb') as fopen:\n",
    "    pickle.dump(crf,fopen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

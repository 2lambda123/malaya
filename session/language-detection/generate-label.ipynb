{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['other', 'malay', 'ind', 'eng'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('formal-language.json') as fopen:\n",
    "    formal = json.load(fopen)\n",
    "    \n",
    "formal.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rojak', 'malay', 'ind'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('social-language.json') as fopen:\n",
    "    social = json.load(fopen)\n",
    "    \n",
    "social.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849593"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('manglish.json') as fopen:\n",
    "    manglish = json.load(fopen)\n",
    "    \n",
    "len(manglish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('eng.json') as fopen:\n",
    "    eng = json.load(fopen)\n",
    "    \n",
    "len(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "for k in formal.keys():\n",
    "    X.extend(formal[k])\n",
    "    Y.extend([k] * len(formal[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in social.keys():\n",
    "    X.extend(social[k])\n",
    "    Y.extend([k] * len(social[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.extend(manglish)\n",
    "Y.extend(['manglish'] * len(manglish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.extend(eng)\n",
    "Y.extend(['eng'] * len(eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X) == len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11277463/11277463 [00:06<00:00, 1696242.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "actual_X, actual_Y = [], []\n",
    "\n",
    "for i in tqdm(range(len(X))):\n",
    "    if len(X[i]):\n",
    "        actual_X.append(X[i])\n",
    "        actual_Y.append(Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11242015, 11277463)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_X), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(actual_X, actual_Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['eng', 'ind', 'malay', 'manglish', 'other', 'rojak'], dtype='<U8'),\n",
       " array([ 439687, 2494778, 4179900,  679692,  265399,  934156]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['eng', 'ind', 'malay', 'manglish', 'other', 'rojak'], dtype='<U8'),\n",
       " array([ 110313,  622928, 1045233,  169901,   66198,  233830]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-test.json', 'w') as fopen:\n",
    "    json.dump({'train_X': train_X, 'test_X': test_X, 'train_Y': train_Y, 'test_Y': test_Y}, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__rus Ты можешь позвонить Тому и сказать, чтобы он немедленно приезжал?\r\n",
      "__label__rus А рыльце-то у него в пушку.\r\n",
      "__label__ind Sebagaimana kita memerlukan udara yang nyaman, juga ikan memerlukan air yang bersih.\r\n",
      "__label__epo Italio havas du montoĉenojn, Alpojn kaj Apeninojn.\r\n",
      "__label__rus Этот ботинок дерьмовый, потому что он из Китая.\r\n",
      "__label__tur Sami bilgisayarların nasıl hackleneceğini bilmiyor.\r\n",
      "__label__rus Президент остался в постели.\r\n",
      "__label__eng I can't remember anything else about Tom.\r\n",
      "__label__eng It's what I wanted.\r\n",
      "__label__ber Sami yessen yelli-s n yiwen n yimsujji.\r\n"
     ]
    }
   ],
   "source": [
    "!head valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8993612/8993612 [00:09<00:00, 904014.51it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "texts = []\n",
    "\n",
    "for i in tqdm(range(len(train_X))):\n",
    "    texts.append('__label__%s %s'%(train_Y[i], train_X[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-bahasa.txt', 'w') as fopen:\n",
    "    fopen.write('\\n'.join(texts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial-avatar",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-accident",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [Malaya/example/doc2vec](https://github.com/huseinzol05/Malaya/tree/master/example/doc2vec).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-sarah",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This module trained on both standard and local (included social media) language structures, so it is save to use for both.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inside-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.02 s, sys: 3.72 s, total: 6.74 s\n",
      "Wall time: 2.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/dev/malaya/malaya/tokenizer.py:208: FutureWarning: Possible nested set at position 3372\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:208: FutureWarning: Possible nested set at position 3890\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polished-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = 'Pemuda mogok lapar desak kerajaan prihatin isu iklim'\n",
    "string2 = 'Perbincangan isu pembalakan perlu babit kerajaan negeri'\n",
    "string3 = 'kerajaan perlu kisah isu iklim, pemuda mogok lapar'\n",
    "string4 = 'Kerajaan dicadang tubuh jawatankuasa khas tangani isu alam sekitar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increasing-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "news1 = 'Tun Dr Mahathir Mohamad mengakui pembubaran Parlimen bagi membolehkan pilihan raya diadakan tidak sesuai dilaksanakan pada masa ini berikutan isu COVID-19'\n",
    "tweet1 = 'DrM sembang pilihan raya tak boleh buat sebab COVID 19'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-hurricane",
   "metadata": {},
   "source": [
    "### Word Vector\n",
    "\n",
    "```python\n",
    "def wordvector(wv):\n",
    "    \"\"\"\n",
    "    Doc2vec interface for text similarity using Word Vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wv: object\n",
    "        malaya.wordvector.WordVector object.\n",
    "        should have `get_vector_by_name` method.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: malaya.similarity.doc2vec.Doc2VecSimilarity\n",
    "    \"\"\"\n",
    "\n",
    "    if not hasattr(wv, 'get_vector_by_name'):\n",
    "        raise ValueError('wordvector must have `get_vector_by_name` method')\n",
    "    return Doc2VecSimilarity(wv)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-perspective",
   "metadata": {},
   "source": [
    "#### Using Interface\n",
    "\n",
    "I will use `malaya.wordvector.load(model = 'news')`, pretty accurate related to local issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_news, embedded_news = malaya.wordvector.load(model = 'news')\n",
    "w2v = malaya.wordvector.WordVector(embedded_news, vocab_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "educated-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41 µs, sys: 0 ns, total: 41 µs\n",
      "Wall time: 43.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "doc2vec = malaya.similarity.doc2vec.wordvector(w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-recommendation",
   "metadata": {},
   "source": [
    "#### predict batch of strings with probability\n",
    "\n",
    "```python\n",
    "def predict_proba(\n",
    "    self,\n",
    "    left_strings: List[str],\n",
    "    right_strings: List[str],\n",
    "    aggregation: Callable = np.mean,\n",
    "    similarity: str = 'cosine',\n",
    "    soft: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    calculate similarity for two different batch of texts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    left_strings : list of str\n",
    "    right_strings : list of str\n",
    "    aggregation : Callable, optional (default=numpy.mean)\n",
    "    similarity : str, optional (default='mean')\n",
    "        similarity supported. Allowed values:\n",
    "\n",
    "        * ``'cosine'`` - cosine similarity.\n",
    "        * ``'euclidean'`` - euclidean similarity.\n",
    "        * ``'manhattan'`` - manhattan similarity.\n",
    "    soft: bool, optional (default=False)\n",
    "        word not inside word vector will replace with nearest word if True, else, will skip.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: List[float]\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "strong-minute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.97 ms, sys: 0 ns, total: 1.97 ms\n",
      "Wall time: 10.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.89971105])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "doc2vec.predict_proba([string1], [string2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coral-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.39 ms, total: 2.39 ms\n",
      "Wall time: 1.79 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.91679387, 0.82348571])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "doc2vec.predict_proba([string1, string2], [string3, string4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outer-sphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 992 µs, sys: 952 µs, total: 1.94 ms\n",
      "Wall time: 1.23 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.91679387, 0.78542261])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "doc2vec.predict_proba([string1, string2], [string3, tweet1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-housing",
   "metadata": {},
   "source": [
    "### Vectorizer Model\n",
    "\n",
    "We can use any Vectorizer models provided by Malaya to use encoder similarity interface, example, BERT, XLNET. Again, these encoder models not trained to do similarity classification, it just encode the strings into vector representation.\n",
    "\n",
    "```python\n",
    "def vectorizer(v):\n",
    "    \"\"\"\n",
    "    Doc2vec interface for text similarity using Encoder model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    v: object\n",
    "        encoder interface object, BERT, XLNET.\n",
    "        should have `vectorize` method.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: malaya.similarity.doc2vec.VectorizerSimilarity\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-johns",
   "metadata": {},
   "source": [
    "#### using ALXLNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smaller-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "alxlnet = malaya.transformer.load(model = 'alxlnet')\n",
    "doc2vec_vectorizer = malaya.similarity.doc2vec.vectorizer(alxlnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-setting",
   "metadata": {},
   "source": [
    "#### predict for 2 strings with probability\n",
    "\n",
    "```python\n",
    "def predict_proba(\n",
    "    self,\n",
    "    left_strings: List[str],\n",
    "    right_strings: List[str],\n",
    "    similarity: str = 'cosine',\n",
    "):\n",
    "    \"\"\"\n",
    "    calculate similarity for two different batch of texts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    left_strings : list of str\n",
    "    right_strings : list of str\n",
    "    similarity : str, optional (default='mean')\n",
    "        similarity supported. Allowed values:\n",
    "\n",
    "        * ``'cosine'`` - cosine similarity.\n",
    "        * ``'euclidean'`` - euclidean similarity.\n",
    "        * ``'manhattan'`` - manhattan similarity.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: List[float]\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tight-colors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 457 ms, sys: 99.9 ms, total: 557 ms\n",
      "Wall time: 286 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8906925], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "doc2vec_vectorizer.predict_proba([string1], [string2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "upset-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 386 ms, sys: 29.7 ms, total: 416 ms\n",
      "Wall time: 49 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6371902, 0.6291744], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "doc2vec_vectorizer.predict_proba([string1, string2], [string3, string4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

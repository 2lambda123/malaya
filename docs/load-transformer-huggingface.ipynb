{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [Malaya/example/transformer-huggingface](https://github.com/huseinzol05/Malaya/tree/master/example/transformer-huggingface).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the list of dataset we pretrained,\n",
    "\n",
    "Standard Bahasa dataset, \n",
    "\n",
    "1. [Malay-dataset/dumping](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping).\n",
    "2. [Malay-dataset/pure-text](https://github.com/huseinzol05/Malay-Dataset/tree/master/pure-text).\n",
    "\n",
    "Bahasa social media,\n",
    "\n",
    "1. [Malay-dataset/dumping/instagram](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping/instagram).\n",
    "2. [Malay-dataset/dumping/twitter](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping/twitter).\n",
    "\n",
    "Singlish / Manglish,\n",
    "\n",
    "1. [Malay-dataset/dumping/singlish](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping/singlish-text).\n",
    "2. [Malay-dataset/dumping/singapore-news](https://github.com/huseinzol05/Malay-Dataset/tree/master/dumping/singapore-news).\n",
    "\n",
    "**This interface not able us to use it to do custom training**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to download pretrained model for Transformer-Bahasa and use it for custom transfer-learning, you can download it here, https://github.com/huseinzol05/Malaya/tree/master/pretrained-model/, some notebooks to help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 3.46 s, total: 6.56 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list Transformer HuggingFace available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mesolitica/roberta-base-bahasa-cased</th>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/roberta-tiny-bahasa-cased</th>\n",
       "      <td>66.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/bert-base-standard-bahasa-cased</th>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/bert-tiny-standard-bahasa-cased</th>\n",
       "      <td>66.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/roberta-base-standard-bahasa-cased</th>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/roberta-tiny-standard-bahasa-cased</th>\n",
       "      <td>66.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/electra-base-generator-bahasa-cased</th>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/electra-small-generator-bahasa-cased</th>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-mnli-t5-super-tiny-standard-bahasa-cased</th>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-mnli-t5-tiny-standard-bahasa-cased</th>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-mnli-t5-small-standard-bahasa-cased</th>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesolitica/finetune-mnli-t5-base-standard-bahasa-cased</th>\n",
       "      <td>892.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Size (MB)\n",
       "mesolitica/roberta-base-bahasa-cased                    443.0\n",
       "mesolitica/roberta-tiny-bahasa-cased                     66.1\n",
       "mesolitica/bert-base-standard-bahasa-cased              443.0\n",
       "mesolitica/bert-tiny-standard-bahasa-cased               66.1\n",
       "mesolitica/roberta-base-standard-bahasa-cased           443.0\n",
       "mesolitica/roberta-tiny-standard-bahasa-cased            66.1\n",
       "mesolitica/electra-base-generator-bahasa-cased          140.0\n",
       "mesolitica/electra-small-generator-bahasa-cased          19.3\n",
       "mesolitica/finetune-mnli-t5-super-tiny-standard...       50.7\n",
       "mesolitica/finetune-mnli-t5-tiny-standard-bahas...      139.0\n",
       "mesolitica/finetune-mnli-t5-small-standard-baha...      242.0\n",
       "mesolitica/finetune-mnli-t5-base-standard-bahas...      892.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.transformer.available_huggingface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ['Kerajaan galakkan rakyat naik public transport tapi parking kat lrt ada 15. Reserved utk staff rapid je dah berpuluh. Park kereta tepi jalan kang kene saman dgn majlis perbandaran. Kereta pulak senang kene curi. Cctv pun tak ada. Naik grab dah 5-10 ringgit tiap hari. Gampang juga',\n",
    "           'Alaa Tun lek ahhh npe muka masam cmni kn agong kata usaha kerajaan terdahulu sejak selepas merdeka',\n",
    "           \"Orang ramai cakap nurse kerajaan garang. So i tell u this. Most of our local ppl will treat us as hamba abdi and they don't respect us as a nurse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HuggingFace model\n",
    "\n",
    "```python\n",
    "def huggingface(\n",
    "    model: str = 'mesolitica/electra-base-generator-bahasa-cased',\n",
    "    force_check: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load transformer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: str, optional (default='mesolitica/electra-base-generator-bahasa-cased')\n",
    "        Check available models at `malaya.transformer.available_transformer()`.\n",
    "    force_check: bool, optional (default=True)\n",
    "        Force check model one of malaya model.\n",
    "        Set to False if you have your own huggingface model.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = malaya.transformer.huggingface(model = 'mesolitica/electra-base-generator-bahasa-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have random sentences copied from Twitter, searched using `kerajaan` keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization\n",
    "\n",
    "Change a string or batch of strings to latent space / vectors representation.\n",
    "\n",
    "```python\n",
    "def vectorize(\n",
    "    self,\n",
    "    strings: List[str],\n",
    "    method: str = 'last',\n",
    "    method_token: str = 'first',\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Vectorize string inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strings: List[str]\n",
    "    method: str, optional (default='last')\n",
    "        hidden layers supported. Allowed values:\n",
    "\n",
    "        * ``'last'`` - last layer.\n",
    "        * ``'first'`` - first layer.\n",
    "        * ``'mean'`` - average all layers.\n",
    "    method_token: str, optional (default='first')\n",
    "        token layers supported. Allowed values:\n",
    "\n",
    "        * ``'last'`` - last token.\n",
    "        * ``'first'`` - first token.\n",
    "        * ``'mean'`` - average all tokens.\n",
    "\n",
    "        usually pretrained models trained on `first` token for classification task.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: np.array\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 256)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = model.vectorize(strings)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def attention(\n",
    "    self,\n",
    "    strings: List[str],\n",
    "    method: str = 'last',\n",
    "    method_head: str = 'mean',\n",
    "):\n",
    "    \"\"\"\n",
    "    Get attention string inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strings: List[str]\n",
    "    method: str, optional (default='last')\n",
    "        Attention layer supported. Allowed values:\n",
    "\n",
    "        * ``'last'`` - attention from last layer.\n",
    "        * ``'first'`` - attention from first layer.\n",
    "        * ``'mean'`` - average attentions from all layers.\n",
    "    method_head: str, optional (default='mean')\n",
    "        attention head layer supported. Allowed values:\n",
    "\n",
    "        * ``'last'`` - attention from last layer.\n",
    "        * ``'first'`` - attention from first layer.\n",
    "        * ``'mean'`` - average attentions from all layers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : List[List[Tuple[str, float]]]\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can give list of strings or a string to get the attention, in this documentation, I just want to use a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.058868613),\n",
       "  ('Tun', 0.061252564),\n",
       "  ('lek', 0.068989426),\n",
       "  ('ahhh', 0.06439798),\n",
       "  ('npe', 0.05082519),\n",
       "  ('muka', 0.07244482),\n",
       "  ('masam', 0.053202268),\n",
       "  ('cmni', 0.048232816),\n",
       "  ('kn', 0.058161996),\n",
       "  ('agong', 0.06559847),\n",
       "  ('kata', 0.05514033),\n",
       "  ('usaha', 0.057437424),\n",
       "  ('kerajaan', 0.041059926),\n",
       "  ('terdahulu', 0.044371374),\n",
       "  ('sejak', 0.06925424),\n",
       "  ('selepas', 0.069484584),\n",
       "  ('merdeka', 0.061277922)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention([strings[1]], method = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.06183809),\n",
       "  ('Tun', 0.053071994),\n",
       "  ('lek', 0.04778199),\n",
       "  ('ahhh', 0.04694453),\n",
       "  ('npe', 0.052150376),\n",
       "  ('muka', 0.053927913),\n",
       "  ('masam', 0.05807442),\n",
       "  ('cmni', 0.08068735),\n",
       "  ('kn', 0.05034357),\n",
       "  ('agong', 0.054398913),\n",
       "  ('kata', 0.057019003),\n",
       "  ('usaha', 0.058209926),\n",
       "  ('kerajaan', 0.069378614),\n",
       "  ('terdahulu', 0.080670245),\n",
       "  ('sejak', 0.057985097),\n",
       "  ('selepas', 0.06437356),\n",
       "  ('merdeka', 0.053144373)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention([strings[1]], method = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.048754193),\n",
       "  ('Tun', 0.054038025),\n",
       "  ('lek', 0.05312951),\n",
       "  ('ahhh', 0.05706034),\n",
       "  ('npe', 0.04947073),\n",
       "  ('muka', 0.060973253),\n",
       "  ('masam', 0.05763235),\n",
       "  ('cmni', 0.0723617),\n",
       "  ('kn', 0.05290027),\n",
       "  ('agong', 0.053802904),\n",
       "  ('kata', 0.07015141),\n",
       "  ('usaha', 0.06137535),\n",
       "  ('kerajaan', 0.06380818),\n",
       "  ('terdahulu', 0.06389959),\n",
       "  ('sejak', 0.056653723),\n",
       "  ('selepas', 0.0524459),\n",
       "  ('merdeka', 0.07154253)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attention([strings[1]], method = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = malaya.transformer.huggingface(model = 'mesolitica/roberta-base-standard-bahasa-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Alaa', 0.052424457),\n",
       "  ('Tun', 0.08523697),\n",
       "  ('lek', 0.06813959),\n",
       "  ('ahhh', 0.06153968),\n",
       "  ('npe', 0.06513652),\n",
       "  ('muka', 0.059199467),\n",
       "  ('masam', 0.061626367),\n",
       "  ('cmni', 0.06737202),\n",
       "  ('kn', 0.06622731),\n",
       "  ('agong', 0.052743737),\n",
       "  ('kata', 0.067238666),\n",
       "  ('usaha', 0.044102527),\n",
       "  ('kerajaan', 0.060376044),\n",
       "  ('terdahulu', 0.041831747),\n",
       "  ('sejak', 0.04189242),\n",
       "  ('selepas', 0.039302666),\n",
       "  ('merdeka', 0.065609865)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta.attention([strings[1]], method = 'last')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

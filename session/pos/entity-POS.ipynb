{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(string):\n",
    "    string = re.sub('[^A-Za-z0-9\\-\\/ ]+', ' ', string).split()\n",
    "    return [to_title(y.strip()) for y in string]\n",
    "\n",
    "def to_title(string):\n",
    "    if string.isupper():\n",
    "        string = string.title()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pos-data-v3.json','r') as fopen:\n",
    "    dataset = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['뭘봐', '뭘봐', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['ひ', 'ひ', 'PROPN']\n",
      "list index out of range ['ヒ', 'ヒ', 'PROPN']\n",
      "list index out of range ['形聲', '形聲', 'NOUN']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['汉', '汉', 'PROPN']\n",
      "list index out of range ['东', '东', 'PROPN']\n",
      "list index out of range ['王', '王', 'PROPN']\n",
      "list index out of range ['（', '（', 'PROPN']\n",
      "list index out of range ['伊', '伊', 'PROPN']\n",
      "list index out of range ['）', '）', 'PROPN']\n",
      "list index out of range ['ȝ', 'ȝ', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range [\"'\", '_', 'PROPN']\n",
      "list index out of range ['碁', '碁', 'NOUN']\n",
      "list index out of range ['囲碁', '囲碁', 'NOUN']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['会', '会', 'PROPN']\n",
      "list index out of range ['蔡武侯', '蔡武侯', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['+', '+', 'SYM']\n",
      "list index out of range ['+', '+', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['*', '*', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['+', '+', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['~', '~', 'ADJ']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['ОАО', 'оао', 'PROPN']\n",
      "list index out of range ['Газпром', 'газпром', 'PROPN']\n",
      "list index out of range [\"''\", '_', 'PROPN']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['佐々木', '佐々木', 'PROPN']\n",
      "list index out of range ['功', '功', 'PROPN']\n",
      "list index out of range ['ɳ', 'ɳ', 'PROPN']\n",
      "list index out of range ['ʂ', 'ʂ', 'PROPN']\n",
      "list index out of range ['ʈ', 'ʈ', 'PROPN']\n",
      "list index out of range ['ɖ', 'ɖ', 'PROPN']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range [\"'\", '_', 'NOUN']\n",
      "list index out of range [\"'\", '_', 'PROPN']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['鉄の森', '鉄の森', 'PROPN']\n",
      "list index out of range ['アイゼンヴァルト', 'アイゼンヴァルト', 'PROPN']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['+', '+', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['壽', '壽', 'PROPN']\n",
      "list index out of range ['陽', '陽', 'PROPN']\n",
      "list index out of range ['裴叔業', '裴叔業', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['#', '#', 'SYM']\n",
      "list index out of range ['+', '+', 'SYM']\n",
      "list index out of range ['فيروز', 'فيروز', 'PROPN']\n",
      "list index out of range ['الديلامي', 'الديلامي', 'PROPN']\n",
      "list index out of range ['נביאים', 'נביאים', 'NOUN']\n",
      "list index out of range ['ראשונים', 'ראשונים', 'NOUN']\n",
      "list index out of range ['נביאים', 'נביאים', 'NOUN']\n",
      "list index out of range ['جامع', 'جامع', 'PROPN']\n",
      "list index out of range ['الرئيس', 'الرئيس', 'PROPN']\n",
      "list index out of range ['الصالح', 'الصالح', 'PROPN']\n",
      "list index out of range ['—', '—', 'NOUN']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['ä', 'ä', 'PROPN']\n",
      "list index out of range ['ʈ', 'ʈ', 'PROPN']\n",
      "list index out of range ['ʈʰ', 'ʈʰ', 'PROPN']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range [\"''\", '_', 'PROPN']\n",
      "list index out of range ['€', '€', 'SYM']\n",
      "list index out of range ['\\u200e', '\\u200e', 'VERB']\n",
      "list index out of range ['\\u200e', '\\u200e', 'NOUN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['$', '$', 'SYM']\n",
      "list index out of range ['Α', 'α', 'PROPN']\n",
      "list index out of range ['А', 'а', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['$', '$', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['おる', 'おる', 'PROPN']\n",
      "list index out of range ['いる', 'いる', 'PROPN']\n",
      "list index out of range ['じゃ', 'じゃ', 'PROPN']\n",
      "list index out of range ['や', 'や', 'PROPN']\n",
      "list index out of range ['だ', 'だ', 'PROPN']\n",
      "list index out of range ['～', '～', 'PROPN']\n",
      "list index out of range ['ん', 'ん', 'PROPN']\n",
      "list index out of range ['わから', 'わから', 'PROPN']\n",
      "list index out of range ['ん', 'ん', 'PROPN']\n",
      "list index out of range ['～', '～', 'PROPN']\n",
      "list index out of range ['ない', 'ない', 'PROPN']\n",
      "list index out of range ['わからない', 'わからない', 'PROPN']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['#', '#', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['#', '#', 'SYM']\n",
      "list index out of range ['#', '#', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['×', '×', 'NOUN']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['–', '–', 'NUM']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['続', '続', 'PROPN']\n",
      "list index out of range ['・', '・', 'PROPN']\n",
      "list index out of range ['三', '三', 'PROPN']\n",
      "list index out of range ['丁目', '丁目', 'PROPN']\n",
      "list index out of range ['の', 'の', 'PROPN']\n",
      "list index out of range ['夕日', '夕日', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['Ἑλλάδος', 'ἑλλάδος', 'PROPN']\n",
      "list index out of range ['παίδευσις', 'παίδευσις', 'PROPN']\n",
      "list index out of range ['€', '€', 'SYM']\n",
      "list index out of range ['ê', 'ê', 'PROPN']\n",
      "list index out of range ['é', 'é', 'PROPN']\n",
      "list index out of range ['è', 'è', 'PROPN']\n",
      "list index out of range ['ë', 'ë', 'PROPN']\n",
      "list index out of range ['ē', 'ē', 'PROPN']\n",
      "list index out of range ['ĕ', 'ĕ', 'PROPN']\n",
      "list index out of range ['ě', 'ě', 'PROPN']\n",
      "list index out of range ['ẽ', 'ẽ', 'PROPN']\n",
      "list index out of range ['ė', 'ė', 'PROPN']\n",
      "list index out of range ['ę', 'ę', 'PROPN']\n",
      "list index out of range ['ẻ', 'ẻ', 'PROPN']\n",
      "list index out of range ['ö', 'ö', 'PROPN']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['.', '.', 'PROPN']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['بندر', 'بندر', 'PROPN']\n",
      "list index out of range ['عباس', 'عباس', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['+', '+', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['$', '$', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['珠海', '珠海', 'PROPN']\n",
      "list index out of range [\"''\", '_', 'NOUN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['서종', '서종', 'PROPN']\n",
      "list index out of range ['제', '제', 'PROPN']\n",
      "list index out of range ['±', '±', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['仙', '仙', 'PROPN']\n",
      "list index out of range ['仚', '仚', 'PROPN']\n",
      "list index out of range ['僊', '僊', 'PROPN']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['腹切り', '腹切り', 'PROPN']\n",
      "list index out of range ['§', '§', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['육식', '육식', 'PROPN']\n",
      "list index out of range ['동물', '동물', 'PROPN']\n",
      "list index out of range ['도망자', '도망자', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['الغرب', 'الغرب', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['سدوم', 'سدوم', 'PROPN']\n",
      "list index out of range ['عمورة', 'عمورة', 'PROPN']\n",
      "list index out of range ['高雄', '高雄', 'PROPN']\n",
      "list index out of range ['大眾', '大眾', 'PROPN']\n",
      "list index out of range ['捷', '捷', 'PROPN']\n",
      "list index out of range ['運', '運', 'PROPN']\n",
      "list index out of range ['系統', '系統', 'PROPN']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['=', '=', 'SYM']\n",
      "list index out of range ['亳', '亳', 'PROPN']\n",
      "list index out of range ['°', '°', 'SYM']\n",
      "list index out of range ['المعقبات', 'المعقبات', 'PROPN']\n",
      "list index out of range ['%', '%', 'SYM']\n",
      "list index out of range ['#', '#', 'SYM']\n",
      "list index out of range ['#', '#', 'SYM']\n",
      "list index out of range ['#', '#', 'SYM']\n",
      "list index out of range ['#', '#', 'SYM']\n",
      "list index out of range ['%', '%', 'SYM']\n"
     ]
    }
   ],
   "source": [
    "texts, labels = [], []\n",
    "for i in dataset:\n",
    "    try:\n",
    "        texts.append(process_string(i[0])[0].lower())\n",
    "        labels.append(i[-1])\n",
    "    except Exception as e:\n",
    "        print(e, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {'PAD': 0,'NUM':1,'UNK':2}\n",
    "tag2idx = {'PAD': 0}\n",
    "char2idx = {'PAD': 0}\n",
    "word_idx = 3\n",
    "tag_idx = 1\n",
    "char_idx = 1\n",
    "\n",
    "def parse_XY(texts, labels):\n",
    "    global word2idx, tag2idx, char2idx, word_idx, tag_idx, char_idx\n",
    "    X, Y = [], []\n",
    "    for no, text in enumerate(texts):\n",
    "        text = to_title(text)\n",
    "        tag = labels[no]\n",
    "        for c in text:\n",
    "            if c not in char2idx:\n",
    "                char2idx[c] = char_idx\n",
    "                char_idx += 1\n",
    "        if tag not in tag2idx:\n",
    "            tag2idx[tag] = tag_idx\n",
    "            tag_idx += 1\n",
    "        Y.append(tag2idx[tag])\n",
    "        if text not in word2idx:\n",
    "            word2idx[text] = word_idx\n",
    "            word_idx += 1\n",
    "        X.append(word2idx[text])\n",
    "    return X, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = parse_XY(texts, labels)\n",
    "idx2word={idx: tag for tag, idx in word2idx.items()}\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "def iter_seq(x):\n",
    "    return np.array([x[i: i+seq_len] for i in range(0, len(x)-seq_len, 1)])\n",
    "\n",
    "def to_train_seq(*args):\n",
    "    return [iter_seq(x) for x in args]\n",
    "\n",
    "def generate_char_seq(batch):\n",
    "    x = [[len(idx2word[i]) for i in k] for k in batch]\n",
    "    maxlen = max([j for i in x for j in i])\n",
    "    temp = np.zeros((batch.shape[0],batch.shape[1],maxlen),dtype=np.int32)\n",
    "    for i in range(batch.shape[0]):\n",
    "        for k in range(batch.shape[1]):\n",
    "            for no, c in enumerate(idx2word[batch[i,k]]):\n",
    "                temp[i,k,-1-no] = char2idx[c]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103367, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq, Y_seq = to_train_seq(X, Y)\n",
    "X_char_seq = generate_char_seq(X_seq)\n",
    "X_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('concat-pos.json','w') as fopen:\n",
    "    fopen.write(json.dumps({'idx2tag':idx2tag,'idx2word':idx2word,\n",
    "           'word2idx':word2idx,'tag2idx':tag2idx,'char2idx':char2idx}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_seq_3d = [to_categorical(i, num_classes=len(tag2idx)) for i in Y_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_X, test_X, train_Y, test_Y, train_char, test_char = train_test_split(X_seq, Y_seq_3d, X_char_seq, \n",
    "                                                                           test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib as tf_contrib\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "\n",
    "class EntityNetwork:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        decay_steps,\n",
    "        decay_rate,\n",
    "        story_length,\n",
    "        vocab_size,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        dim_word,\n",
    "        dim_char,\n",
    "        hidden_size_char,\n",
    "        hidden_size_word,\n",
    "        word2idx,\n",
    "        char2idx,\n",
    "        dropout = 0.8,\n",
    "        initializer = tf.random_normal_initializer(stddev = 0.1),\n",
    "        clip_gradients = 5.0,\n",
    "        use_bi_lstm = False,\n",
    "    ):\n",
    "        \"\"\"init all hyperparameter here\"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.learning_rate = tf.Variable(\n",
    "            learning_rate, trainable = False, name = 'learning_rate'\n",
    "        )\n",
    "        self.learning_rate_decay_half_op = tf.assign(\n",
    "            self.learning_rate, self.learning_rate * 0.5\n",
    "        )\n",
    "        self.initializer = initializer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.clip_gradients = clip_gradients\n",
    "        self.story_length = story_length\n",
    "        self.block_size = 20\n",
    "        self.use_bi_lstm = use_bi_lstm\n",
    "        self.dimension = (\n",
    "            self.hidden_size * 2 if self.use_bi_lstm else self.hidden_size\n",
    "        )\n",
    "        self.story = tf.placeholder(\n",
    "            tf.int32, [None, self.story_length, None], name = 'story'\n",
    "        )\n",
    "        self.labels = tf.placeholder(\n",
    "            tf.int32, shape = [None, None, None], name = 'input_y'\n",
    "        )\n",
    "        self.char_ids = tf.placeholder(\n",
    "            tf.int32, shape = [None, None, None], name = 'char_ids'\n",
    "        )\n",
    "        self.query = tf.placeholder(tf.int32, [None, None], name = 'question')\n",
    "        self.sequence_length = tf.shape(self.query)[1]\n",
    "        self.batch_size = tf.shape(self.query)[0]\n",
    "        self.lengths = tf.count_nonzero(self.query, 1)\n",
    "        self.dropout_keep_prob = dropout\n",
    "\n",
    "        self.global_step = tf.Variable(\n",
    "            0, trainable = False, name = 'Global_Step'\n",
    "        )\n",
    "        self.epoch_step = tf.Variable(0, trainable = False, name = 'Epoch_Step')\n",
    "        self.epoch_increment = tf.assign(\n",
    "            self.epoch_step, tf.add(self.epoch_step, tf.constant(1))\n",
    "        )\n",
    "        self.decay_steps, self.decay_rate = decay_steps, decay_rate\n",
    "\n",
    "        self.instantiate_weights()\n",
    "        logits = self.inference()\n",
    "\n",
    "        self.word_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(word2idx), dim_word], stddev = 1.0 / np.sqrt(dim_word)\n",
    "            )\n",
    "        )\n",
    "        self.char_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(char2idx), dim_char], stddev = 1.0 / np.sqrt(dim_char)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        word_embedded = tf.nn.embedding_lookup(self.word_embeddings, self.query)\n",
    "        char_embedded = tf.nn.embedding_lookup(\n",
    "            self.char_embeddings, self.char_ids\n",
    "        )\n",
    "        s = tf.shape(char_embedded)\n",
    "        char_embedded = tf.reshape(\n",
    "            char_embedded, shape = [s[0] * s[1], s[-2], dim_char]\n",
    "        )\n",
    "\n",
    "        def cells(size, name, reuse = False):\n",
    "            return tf.contrib.rnn.DropoutWrapper(\n",
    "                rnn.LSTMCell(size, reuse = reuse, name=name),\n",
    "                state_keep_prob = dropout,\n",
    "                output_keep_prob = dropout,\n",
    "            )\n",
    "\n",
    "        cell_chars = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [cells(hidden_size_char,'char') for _ in range(num_layers)],\n",
    "            \n",
    "        )\n",
    "        cell_words = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [cells(hidden_size_word,'word') for _ in range(num_layers)]\n",
    "        )\n",
    "        char_embedded, _ = tf.nn.dynamic_rnn(\n",
    "            cell_chars, char_embedded, dtype = tf.float32\n",
    "        )\n",
    "        output = tf.reshape(\n",
    "            char_embedded[:, -1], shape = [s[0], s[1], hidden_size_char]\n",
    "        )\n",
    "        word_embedded = tf.concat([word_embedded, output], axis = -1)\n",
    "        word_embedded, _ = tf.nn.dynamic_rnn(\n",
    "            cell_words, word_embedded, dtype = tf.float32\n",
    "        )\n",
    "        logits = tf.tile(tf.expand_dims(logits,axis=1),[1,self.sequence_length,1])\n",
    "        word_embedded = tf.multiply(word_embedded, logits)\n",
    "        logits = tf.layers.dense(word_embedded, len(idx2tag))\n",
    "        y_t = tf.argmax(self.labels, 2)\n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\n",
    "            logits, y_t, self.lengths\n",
    "        )\n",
    "        self.cost = tf.reduce_mean(-log_likelihood)\n",
    "        mask = tf.sequence_mask(self.lengths, maxlen = self.sequence_length)\n",
    "        self.tags_seq, tags_score = tf.contrib.crf.crf_decode(\n",
    "            logits, transition_params, self.lengths\n",
    "        )\n",
    "        self.tags_seq = tf.identity(self.tags_seq, name = 'logits')\n",
    "\n",
    "        y_t = tf.cast(y_t, tf.int32)\n",
    "        self.prediction = tf.boolean_mask(self.tags_seq, mask)\n",
    "        mask_label = tf.boolean_mask(y_t, mask)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        self.optimizer = self.train()\n",
    "\n",
    "    def inference(self):\n",
    "        self.embedding_with_mask()\n",
    "        if self.use_bi_lstm:\n",
    "            self.input_encoder_bi_lstm()\n",
    "        else:\n",
    "            self.input_encoder_bow()\n",
    "        self.hidden_state = self.rnn_story()\n",
    "        logits = self.output_module()\n",
    "        return logits\n",
    "\n",
    "    def output_module(self):\n",
    "        p = tf.nn.softmax(\n",
    "            tf.multiply(\n",
    "                tf.expand_dims(self.query_embedding, axis = 1),\n",
    "                self.hidden_state,\n",
    "            )\n",
    "        )\n",
    "        return tf.reduce_sum(tf.multiply(p, self.hidden_state), axis = 1)\n",
    "\n",
    "    def rnn_story(self):\n",
    "        input_split = tf.split(\n",
    "            self.story_embedding, self.story_length, axis = 1\n",
    "        )\n",
    "        input_list = [tf.squeeze(x, axis = 1) for x in input_split]\n",
    "        h_all = tf.get_variable(\n",
    "            'hidden_states',\n",
    "            shape = [self.block_size, self.dimension],\n",
    "            initializer = self.initializer,\n",
    "        )\n",
    "        w_all = tf.get_variable(\n",
    "            'keys',\n",
    "            shape = [self.block_size, self.dimension],\n",
    "            initializer = self.initializer,\n",
    "        )\n",
    "        w_all_expand = tf.tile(\n",
    "            tf.expand_dims(w_all, axis = 0), [self.batch_size, 1, 1]\n",
    "        )\n",
    "        h_all_expand = tf.tile(\n",
    "            tf.expand_dims(h_all, axis = 0), [self.batch_size, 1, 1]\n",
    "        )\n",
    "        for i, input in enumerate(input_list):\n",
    "            h_all_expand = self.cell(input, h_all_expand, w_all_expand, i)\n",
    "        return h_all_expand\n",
    "\n",
    "    def embedding_with_mask(self):\n",
    "        self.story_embedding = tf.nn.embedding_lookup(\n",
    "            self.Embedding, self.story\n",
    "        )\n",
    "        self.query_embedding = tf.nn.embedding_lookup(\n",
    "            self.Embedding, self.query\n",
    "        )\n",
    "\n",
    "    def input_encoder_bow(self):\n",
    "        self.story_embedding = tf.reduce_sum(self.story_embedding, axis = 2)\n",
    "        self.query_embedding = tf.reduce_sum(self.query_embedding, axis = 1)\n",
    "\n",
    "    def input_encoder_bi_lstm(self):\n",
    "        \"\"\"\n",
    "        use bi-directional lstm to encode query_embedding:[batch_size,sequence_length,embed_size]\n",
    "        and story_embedding:[batch_size,story_length,sequence_length,embed_size]\n",
    "        output:query_embedding:[batch_size,hidden_size*2]\n",
    "        story_embedding:[batch_size,self.story_length,self.hidden_size*2]\n",
    "        \"\"\"\n",
    "        lstm_fw_cell = rnn.BasicLSTMCell(self.hidden_size)\n",
    "        lstm_bw_cell = rnn.BasicLSTMCell(self.hidden_size)\n",
    "        if self.dropout_keep_prob is not None:\n",
    "            lstm_fw_cell = rnn.DropoutWrapper(\n",
    "                lstm_fw_cell, output_keep_prob = self.dropout_keep_prob\n",
    "            )\n",
    "            lstm_bw_cell == rnn.DropoutWrapper(\n",
    "                lstm_bw_cell, output_keep_prob = self.dropout_keep_prob\n",
    "            )\n",
    "        query_hidden_output, _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "            lstm_fw_cell,\n",
    "            lstm_bw_cell,\n",
    "            self.query_embedding,\n",
    "            dtype = tf.float32,\n",
    "            scope = 'query_rnn',\n",
    "        )\n",
    "        query_hidden_output = tf.concat(query_hidden_output, axis = 2)\n",
    "        self.query_embedding = tf.reduce_sum(query_hidden_output, axis = 1)\n",
    "        self.story_embedding = tf.reshape(\n",
    "            self.story_embedding,\n",
    "            shape = (\n",
    "                -1,\n",
    "                self.story_length * self.sequence_length,\n",
    "                self.embed_size,\n",
    "            ),\n",
    "        )\n",
    "        lstm_fw_cell_story = rnn.BasicLSTMCell(self.hidden_size)\n",
    "        lstm_bw_cell_story = rnn.BasicLSTMCell(self.hidden_size)\n",
    "        if self.dropout_keep_prob is not None:\n",
    "            lstm_fw_cell_story = rnn.DropoutWrapper(\n",
    "                lstm_fw_cell_story, output_keep_prob = self.dropout_keep_prob\n",
    "            )\n",
    "\n",
    "    def instantiate_weights(self):\n",
    "        \"\"\"define all weights here\"\"\"\n",
    "\n",
    "        with tf.variable_scope('dynamic_memory'):\n",
    "            self.U = tf.get_variable(\n",
    "                'U',\n",
    "                shape = [self.dimension, self.dimension],\n",
    "                initializer = self.initializer,\n",
    "            )\n",
    "            self.V = tf.get_variable(\n",
    "                'V',\n",
    "                shape = [self.dimension, self.dimension],\n",
    "                initializer = self.initializer,\n",
    "            )\n",
    "            self.W = tf.get_variable(\n",
    "                'W',\n",
    "                shape = [self.dimension, self.dimension],\n",
    "                initializer = self.initializer,\n",
    "            )\n",
    "            self.h_bias = tf.get_variable('h_bias', shape = [self.dimension])\n",
    "            self.h2_bias = tf.get_variable('h2_bias', shape = [self.dimension])\n",
    "\n",
    "        with tf.variable_scope('embedding_projection'):\n",
    "            self.Embedding = tf.get_variable(\n",
    "                'Embedding',\n",
    "                shape = [self.vocab_size, self.embed_size],\n",
    "                initializer = self.initializer,\n",
    "            )\n",
    "\n",
    "    def cell(self, s_t, h_all, w_all, i):\n",
    "        s_t_expand = tf.expand_dims(s_t, axis = 1)\n",
    "        g = tf.nn.sigmoid(\n",
    "            tf.multiply(s_t_expand, h_all) + tf.multiply(s_t_expand, w_all)\n",
    "        )\n",
    "\n",
    "        h_candidate_part1 = (\n",
    "            tf.matmul(tf.reshape(h_all, shape = (-1, self.dimension)), self.U)\n",
    "            + tf.matmul(tf.reshape(w_all, shape = (-1, self.dimension)), self.V)\n",
    "            + self.h_bias\n",
    "        )\n",
    "\n",
    "        h_candidate_part1 = tf.reshape(\n",
    "            h_candidate_part1,\n",
    "            shape = (self.batch_size, self.block_size, self.dimension),\n",
    "        )\n",
    "        h_candidate_part2 = tf.expand_dims(\n",
    "            tf.matmul(s_t, self.W) + self.h2_bias, axis = 1\n",
    "        )\n",
    "        h_candidate = self.activation(\n",
    "            h_candidate_part1 + h_candidate_part2,\n",
    "            scope = 'h_candidate' + str(i),\n",
    "        )\n",
    "\n",
    "        h_all = h_all + tf.multiply(g, h_candidate)\n",
    "\n",
    "        h_all = tf.nn.l2_normalize(h_all, -1)\n",
    "        return h_all\n",
    "\n",
    "    def activation(self, features, scope = None):\n",
    "        with tf.variable_scope(scope, 'PReLU', initializer = self.initializer):\n",
    "            alpha = tf.get_variable('alpha', features.get_shape().as_list()[1:])\n",
    "            pos = tf.nn.relu(features)\n",
    "            neg = alpha * (features - tf.abs(features)) * 0.5\n",
    "            return pos + neg\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"based on the loss, use SGD to update parameter\"\"\"\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            self.learning_rate,\n",
    "            self.global_step,\n",
    "            self.decay_steps,\n",
    "            self.decay_rate,\n",
    "            staircase = True,\n",
    "        )\n",
    "        self.learning_rate_ = learning_rate\n",
    "        train_op = tf_contrib.layers.optimize_loss(\n",
    "            self.cost,\n",
    "            global_step = self.global_step,\n",
    "            learning_rate = learning_rate,\n",
    "            optimizer = 'Adam',\n",
    "            clip_gradients = self.clip_gradients,\n",
    "        )\n",
    "        return train_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dim_word = 64\n",
    "dim_char = 128\n",
    "learning_rate = 1e-3\n",
    "hidden_size_char = 64\n",
    "hidden_size_word = 64\n",
    "num_layers = 2\n",
    "batch_size = 32\n",
    "decay_step = 1e4\n",
    "decay_rate = 1.0\n",
    "story_len = 1\n",
    "\n",
    "model = EntityNetwork(\n",
    "    learning_rate,\n",
    "    decay_step,\n",
    "    decay_rate,\n",
    "    story_len,\n",
    "    len(idx2word),\n",
    "    dim_word,\n",
    "    dim_word,\n",
    "    num_layers,\n",
    "    dim_word,\n",
    "    dim_char,\n",
    "    hidden_size_char,\n",
    "    hidden_size_word,\n",
    "    word2idx,\n",
    "    char2idx\n",
    ")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2908/2908 [13:33<00:00,  3.66it/s, accuracy=0.837, cost=30.8]\n",
      "test minibatch loop: 100%|██████████| 324/324 [00:58<00:00,  5.48it/s, accuracy=0.84, cost=26.4] \n",
      "train minibatch loop:   0%|          | 0/2908 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 871.7990927696228\n",
      "epoch: 0, training loss: 65.961979, training acc: 0.500273, valid loss: 24.691260, valid acc: 0.838172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2908/2908 [13:32<00:00,  3.47it/s, accuracy=0.923, cost=11.9]\n",
      "test minibatch loop: 100%|██████████| 324/324 [00:58<00:00,  5.65it/s, accuracy=0.96, cost=7.56] \n",
      "train minibatch loop:   0%|          | 0/2908 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 870.7760932445526\n",
      "epoch: 1, training loss: 15.270024, training acc: 0.903563, valid loss: 9.331125, valid acc: 0.945404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2908/2908 [16:07<00:00,  3.70it/s, accuracy=0.95, cost=7.61] \n",
      "test minibatch loop: 100%|██████████| 324/324 [00:58<00:00,  5.84it/s, accuracy=1, cost=2.92]    \n",
      "train minibatch loop:   0%|          | 0/2908 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 1026.7641150951385\n",
      "epoch: 2, training loss: 6.383206, training acc: 0.961041, valid loss: 4.414704, valid acc: 0.975494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2908/2908 [13:31<00:00,  3.66it/s, accuracy=0.983, cost=3.17]\n",
      "test minibatch loop: 100%|██████████| 324/324 [00:58<00:00,  5.60it/s, accuracy=1, cost=1.18]    \n",
      "train minibatch loop:   0%|          | 0/2908 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 870.1128623485565\n",
      "epoch: 3, training loss: 3.279976, training acc: 0.979698, valid loss: 2.628626, valid acc: 0.986820\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2908/2908 [13:32<00:00,  3.88it/s, accuracy=0.99, cost=2.5]   \n",
      "test minibatch loop: 100%|██████████| 324/324 [00:59<00:00,  5.37it/s, accuracy=1, cost=0.696]    \n",
      "train minibatch loop:   0%|          | 0/2908 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 871.584011554718\n",
      "epoch: 4, training loss: 2.142017, training acc: 0.986532, valid loss: 1.892530, valid acc: 0.991021\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop:  22%|██▏       | 640/2908 [02:58<10:38,  3.55it/s, accuracy=0.982, cost=2.81] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-59ec0c078c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x_expand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_char\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             },\n\u001b[1;32m     22\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for e in range(7):\n",
    "    lasttime = time.time()\n",
    "    train_acc, train_loss, test_acc, test_loss = 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = train_X[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        batch_char = train_char[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_y = train_Y[i : min(i + batch_size, train_X.shape[0])]\n",
    "        acc, cost, _ = sess.run(\n",
    "            [model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.query: batch_x,\n",
    "                model.story: batch_x_expand,\n",
    "                model.char_ids: batch_char,\n",
    "                model.labels: batch_y\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "    \n",
    "    pbar = tqdm(\n",
    "        range(0, len(test_X), batch_size), desc = 'test minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        batch_char = test_char[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "        acc, cost = sess.run(\n",
    "            [model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.query: batch_x,\n",
    "                model.story: batch_x_expand,\n",
    "                model.char_ids: batch_char,\n",
    "                model.labels: batch_y\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "    \n",
    "    train_loss /= len(train_X) / batch_size\n",
    "    train_acc /= len(train_X) / batch_size\n",
    "    test_loss /= len(test_X) / batch_size\n",
    "    test_acc /= len(test_X) / batch_size\n",
    "\n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, valid loss: %f, valid acc: %f\\n'\n",
    "        % (e, train_loss, train_acc, test_loss, test_acc)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            out_i.append(idx2tag[p])\n",
    "        out.append(out_i)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "validation minibatch loop:   0%|          | 0/324 [00:00<?, ?it/s]\u001b[A\n",
      "validation minibatch loop:   0%|          | 1/324 [00:00<01:27,  3.68it/s]\u001b[A\n",
      "validation minibatch loop:   1%|          | 2/324 [00:00<01:16,  4.18it/s]\u001b[A\n",
      "validation minibatch loop:   1%|          | 3/324 [00:00<01:06,  4.83it/s]\u001b[A\n",
      "validation minibatch loop:   1%|          | 4/324 [00:00<01:02,  5.16it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 5/324 [00:00<00:58,  5.47it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 6/324 [00:01<00:56,  5.65it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 7/324 [00:01<00:54,  5.80it/s]\u001b[A\n",
      "validation minibatch loop:   2%|▏         | 8/324 [00:01<00:49,  6.42it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 9/324 [00:01<00:50,  6.30it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 10/324 [00:01<00:47,  6.58it/s]\u001b[A\n",
      "validation minibatch loop:   3%|▎         | 11/324 [00:01<00:46,  6.78it/s]\u001b[A\n",
      "validation minibatch loop:   4%|▎         | 12/324 [00:01<00:47,  6.57it/s]\u001b[A\n",
      "validation minibatch loop:   4%|▍         | 13/324 [00:02<00:48,  6.44it/s]\u001b[A\n",
      "validation minibatch loop:   4%|▍         | 14/324 [00:02<00:48,  6.33it/s]\u001b[A\n",
      "validation minibatch loop:   5%|▍         | 15/324 [00:02<00:46,  6.60it/s]\u001b[A\n",
      "validation minibatch loop:   5%|▍         | 16/324 [00:02<00:48,  6.40it/s]\u001b[A\n",
      "validation minibatch loop:   5%|▌         | 17/324 [00:02<00:49,  6.26it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▌         | 18/324 [00:02<00:50,  6.02it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▌         | 19/324 [00:03<00:51,  5.95it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▌         | 20/324 [00:03<00:51,  5.93it/s]\u001b[A\n",
      "validation minibatch loop:   6%|▋         | 21/324 [00:03<00:50,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:   7%|▋         | 22/324 [00:03<00:50,  6.00it/s]\u001b[A\n",
      "validation minibatch loop:   7%|▋         | 23/324 [00:03<00:51,  5.85it/s]\u001b[A\n",
      "validation minibatch loop:   7%|▋         | 24/324 [00:03<00:49,  6.10it/s]\u001b[A\n",
      "validation minibatch loop:   8%|▊         | 25/324 [00:04<00:49,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:   8%|▊         | 26/324 [00:04<00:50,  5.95it/s]\u001b[A\n",
      "validation minibatch loop:   8%|▊         | 27/324 [00:04<00:49,  5.97it/s]\u001b[A\n",
      "validation minibatch loop:   9%|▊         | 28/324 [00:04<00:45,  6.54it/s]\u001b[A\n",
      "validation minibatch loop:   9%|▉         | 29/324 [00:04<00:45,  6.49it/s]\u001b[A\n",
      "validation minibatch loop:   9%|▉         | 30/324 [00:04<00:46,  6.29it/s]\u001b[A\n",
      "validation minibatch loop:  10%|▉         | 31/324 [00:05<00:47,  6.17it/s]\u001b[A\n",
      "validation minibatch loop:  10%|▉         | 32/324 [00:05<00:47,  6.10it/s]\u001b[A\n",
      "validation minibatch loop:  10%|█         | 33/324 [00:05<00:47,  6.16it/s]\u001b[A\n",
      "validation minibatch loop:  10%|█         | 34/324 [00:05<00:47,  6.06it/s]\u001b[A\n",
      "validation minibatch loop:  11%|█         | 35/324 [00:05<00:47,  6.06it/s]\u001b[A\n",
      "validation minibatch loop:  11%|█         | 36/324 [00:05<00:45,  6.36it/s]\u001b[A\n",
      "validation minibatch loop:  11%|█▏        | 37/324 [00:05<00:42,  6.73it/s]\u001b[A\n",
      "validation minibatch loop:  12%|█▏        | 38/324 [00:06<00:42,  6.80it/s]\u001b[A\n",
      "validation minibatch loop:  12%|█▏        | 39/324 [00:06<00:43,  6.57it/s]\u001b[A\n",
      "validation minibatch loop:  12%|█▏        | 40/324 [00:06<00:43,  6.58it/s]\u001b[A\n",
      "validation minibatch loop:  13%|█▎        | 41/324 [00:06<00:43,  6.48it/s]\u001b[A\n",
      "validation minibatch loop:  13%|█▎        | 42/324 [00:06<00:45,  6.23it/s]\u001b[A\n",
      "validation minibatch loop:  13%|█▎        | 43/324 [00:06<00:44,  6.25it/s]\u001b[A\n",
      "validation minibatch loop:  14%|█▎        | 44/324 [00:07<00:44,  6.29it/s]\u001b[A\n",
      "validation minibatch loop:  14%|█▍        | 45/324 [00:07<00:44,  6.21it/s]\u001b[A\n",
      "validation minibatch loop:  14%|█▍        | 46/324 [00:07<00:46,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▍        | 47/324 [00:07<00:43,  6.38it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▍        | 48/324 [00:07<00:44,  6.16it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▌        | 49/324 [00:07<00:44,  6.22it/s]\u001b[A\n",
      "validation minibatch loop:  15%|█▌        | 50/324 [00:08<00:44,  6.15it/s]\u001b[A\n",
      "validation minibatch loop:  16%|█▌        | 51/324 [00:08<00:45,  6.06it/s]\u001b[A\n",
      "validation minibatch loop:  16%|█▌        | 52/324 [00:08<00:45,  6.00it/s]\u001b[A\n",
      "validation minibatch loop:  16%|█▋        | 53/324 [00:08<00:44,  6.05it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 54/324 [00:08<00:44,  6.12it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 55/324 [00:08<00:43,  6.20it/s]\u001b[A\n",
      "validation minibatch loop:  17%|█▋        | 56/324 [00:09<00:42,  6.30it/s]\u001b[A\n",
      "validation minibatch loop:  18%|█▊        | 57/324 [00:09<00:43,  6.19it/s]\u001b[A\n",
      "validation minibatch loop:  18%|█▊        | 58/324 [00:09<00:43,  6.12it/s]\u001b[A\n",
      "validation minibatch loop:  18%|█▊        | 59/324 [00:09<00:40,  6.59it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▊        | 60/324 [00:09<00:41,  6.33it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▉        | 61/324 [00:09<00:38,  6.79it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▉        | 62/324 [00:09<00:39,  6.60it/s]\u001b[A\n",
      "validation minibatch loop:  19%|█▉        | 63/324 [00:10<00:40,  6.46it/s]\u001b[A\n",
      "validation minibatch loop:  20%|█▉        | 64/324 [00:10<00:40,  6.47it/s]\u001b[A\n",
      "validation minibatch loop:  20%|██        | 65/324 [00:10<00:40,  6.35it/s]\u001b[A\n",
      "validation minibatch loop:  20%|██        | 66/324 [00:10<00:40,  6.30it/s]\u001b[A\n",
      "validation minibatch loop:  21%|██        | 67/324 [00:10<00:38,  6.68it/s]\u001b[A\n",
      "validation minibatch loop:  21%|██        | 68/324 [00:10<00:38,  6.59it/s]\u001b[A\n",
      "validation minibatch loop:  21%|██▏       | 69/324 [00:11<00:38,  6.55it/s]\u001b[A\n",
      "validation minibatch loop:  22%|██▏       | 70/324 [00:11<00:40,  6.30it/s]\u001b[A\n",
      "validation minibatch loop:  22%|██▏       | 71/324 [00:11<00:39,  6.34it/s]\u001b[A\n",
      "validation minibatch loop:  22%|██▏       | 72/324 [00:11<00:40,  6.17it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 73/324 [00:11<00:38,  6.53it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 74/324 [00:11<00:40,  6.12it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 75/324 [00:12<00:43,  5.74it/s]\u001b[A\n",
      "validation minibatch loop:  23%|██▎       | 76/324 [00:12<00:42,  5.85it/s]\u001b[A\n",
      "validation minibatch loop:  24%|██▍       | 77/324 [00:12<00:41,  5.89it/s]\u001b[A\n",
      "validation minibatch loop:  24%|██▍       | 78/324 [00:12<00:42,  5.80it/s]\u001b[A\n",
      "validation minibatch loop:  24%|██▍       | 79/324 [00:12<00:42,  5.81it/s]\u001b[A\n",
      "validation minibatch loop:  25%|██▍       | 80/324 [00:12<00:41,  5.87it/s]\u001b[A\n",
      "validation minibatch loop:  25%|██▌       | 81/324 [00:13<00:41,  5.89it/s]\u001b[A\n",
      "validation minibatch loop:  25%|██▌       | 82/324 [00:13<00:40,  5.93it/s]\u001b[A\n",
      "validation minibatch loop:  26%|██▌       | 83/324 [00:13<00:39,  6.05it/s]\u001b[A\n",
      "validation minibatch loop:  26%|██▌       | 84/324 [00:13<00:38,  6.24it/s]\u001b[A\n",
      "validation minibatch loop:  26%|██▌       | 85/324 [00:13<00:38,  6.22it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 86/324 [00:13<00:39,  6.02it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 87/324 [00:14<00:39,  6.01it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 88/324 [00:14<00:39,  5.98it/s]\u001b[A\n",
      "validation minibatch loop:  27%|██▋       | 89/324 [00:14<00:37,  6.29it/s]\u001b[A\n",
      "validation minibatch loop:  28%|██▊       | 90/324 [00:14<00:38,  6.15it/s]\u001b[A\n",
      "validation minibatch loop:  28%|██▊       | 91/324 [00:14<00:38,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  28%|██▊       | 92/324 [00:14<00:40,  5.78it/s]\u001b[A\n",
      "validation minibatch loop:  29%|██▊       | 93/324 [00:15<00:38,  5.96it/s]\u001b[A\n",
      "validation minibatch loop:  29%|██▉       | 94/324 [00:15<00:38,  5.97it/s]\u001b[A\n",
      "validation minibatch loop:  29%|██▉       | 95/324 [00:15<00:35,  6.41it/s]\u001b[A\n",
      "validation minibatch loop:  30%|██▉       | 96/324 [00:15<00:35,  6.36it/s]\u001b[A\n",
      "validation minibatch loop:  30%|██▉       | 97/324 [00:15<00:36,  6.18it/s]\u001b[A\n",
      "validation minibatch loop:  30%|███       | 98/324 [00:15<00:36,  6.11it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███       | 99/324 [00:16<00:37,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███       | 100/324 [00:16<00:37,  6.02it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███       | 101/324 [00:16<00:36,  6.05it/s]\u001b[A\n",
      "validation minibatch loop:  31%|███▏      | 102/324 [00:16<00:34,  6.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation minibatch loop:  32%|███▏      | 103/324 [00:16<00:34,  6.46it/s]\u001b[A\n",
      "validation minibatch loop:  32%|███▏      | 104/324 [00:16<00:34,  6.34it/s]\u001b[A\n",
      "validation minibatch loop:  32%|███▏      | 105/324 [00:16<00:35,  6.13it/s]\u001b[A\n",
      "validation minibatch loop:  33%|███▎      | 106/324 [00:17<00:34,  6.39it/s]\u001b[A\n",
      "validation minibatch loop:  33%|███▎      | 107/324 [00:17<00:34,  6.29it/s]\u001b[A\n",
      "validation minibatch loop:  33%|███▎      | 108/324 [00:17<00:34,  6.22it/s]\u001b[A\n",
      "validation minibatch loop:  34%|███▎      | 109/324 [00:17<00:34,  6.16it/s]\u001b[A\n",
      "validation minibatch loop:  34%|███▍      | 110/324 [00:17<00:35,  6.03it/s]\u001b[A\n",
      "validation minibatch loop:  34%|███▍      | 111/324 [00:17<00:34,  6.11it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▍      | 112/324 [00:18<00:34,  6.13it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▍      | 113/324 [00:18<00:34,  6.20it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▌      | 114/324 [00:18<00:33,  6.22it/s]\u001b[A\n",
      "validation minibatch loop:  35%|███▌      | 115/324 [00:18<00:33,  6.23it/s]\u001b[A\n",
      "validation minibatch loop:  36%|███▌      | 116/324 [00:18<00:33,  6.24it/s]\u001b[A\n",
      "validation minibatch loop:  36%|███▌      | 117/324 [00:18<00:33,  6.24it/s]\u001b[A\n",
      "validation minibatch loop:  36%|███▋      | 118/324 [00:19<00:34,  6.06it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 119/324 [00:19<00:33,  6.20it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 120/324 [00:19<00:32,  6.30it/s]\u001b[A\n",
      "validation minibatch loop:  37%|███▋      | 121/324 [00:19<00:32,  6.19it/s]\u001b[A\n",
      "validation minibatch loop:  38%|███▊      | 122/324 [00:19<00:33,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  38%|███▊      | 123/324 [00:19<00:33,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:  38%|███▊      | 124/324 [00:20<00:33,  6.00it/s]\u001b[A\n",
      "validation minibatch loop:  39%|███▊      | 125/324 [00:20<00:32,  6.04it/s]\u001b[A\n",
      "validation minibatch loop:  39%|███▉      | 126/324 [00:20<00:32,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  39%|███▉      | 127/324 [00:20<00:30,  6.42it/s]\u001b[A\n",
      "validation minibatch loop:  40%|███▉      | 128/324 [00:20<00:30,  6.51it/s]\u001b[A\n",
      "validation minibatch loop:  40%|███▉      | 129/324 [00:20<00:30,  6.32it/s]\u001b[A\n",
      "validation minibatch loop:  40%|████      | 130/324 [00:20<00:30,  6.42it/s]\u001b[A\n",
      "validation minibatch loop:  40%|████      | 131/324 [00:21<00:30,  6.31it/s]\u001b[A\n",
      "validation minibatch loop:  41%|████      | 132/324 [00:21<00:30,  6.24it/s]\u001b[A\n",
      "validation minibatch loop:  41%|████      | 133/324 [00:21<00:30,  6.17it/s]\u001b[A\n",
      "validation minibatch loop:  41%|████▏     | 134/324 [00:21<00:31,  6.10it/s]\u001b[A\n",
      "validation minibatch loop:  42%|████▏     | 135/324 [00:21<00:30,  6.10it/s]\u001b[A\n",
      "validation minibatch loop:  42%|████▏     | 136/324 [00:21<00:30,  6.10it/s]\u001b[A\n",
      "validation minibatch loop:  42%|████▏     | 137/324 [00:22<00:30,  6.08it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 138/324 [00:22<00:30,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 139/324 [00:22<00:30,  6.08it/s]\u001b[A\n",
      "validation minibatch loop:  43%|████▎     | 140/324 [00:22<00:29,  6.23it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▎     | 141/324 [00:22<00:30,  6.03it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▍     | 142/324 [00:22<00:30,  6.05it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▍     | 143/324 [00:23<00:29,  6.11it/s]\u001b[A\n",
      "validation minibatch loop:  44%|████▍     | 144/324 [00:23<00:30,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:  45%|████▍     | 145/324 [00:23<00:29,  5.98it/s]\u001b[A\n",
      "validation minibatch loop:  45%|████▌     | 146/324 [00:23<00:28,  6.14it/s]\u001b[A\n",
      "validation minibatch loop:  45%|████▌     | 147/324 [00:23<00:28,  6.30it/s]\u001b[A\n",
      "validation minibatch loop:  46%|████▌     | 148/324 [00:23<00:28,  6.22it/s]\u001b[A\n",
      "validation minibatch loop:  46%|████▌     | 149/324 [00:24<00:27,  6.29it/s]\u001b[A\n",
      "validation minibatch loop:  46%|████▋     | 150/324 [00:24<00:27,  6.30it/s]\u001b[A\n",
      "validation minibatch loop:  47%|████▋     | 151/324 [00:24<00:26,  6.47it/s]\u001b[A\n",
      "validation minibatch loop:  47%|████▋     | 152/324 [00:24<00:27,  6.31it/s]\u001b[A\n",
      "validation minibatch loop:  47%|████▋     | 153/324 [00:24<00:27,  6.27it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 154/324 [00:24<00:27,  6.13it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 155/324 [00:25<00:27,  6.10it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 156/324 [00:25<00:27,  6.04it/s]\u001b[A\n",
      "validation minibatch loop:  48%|████▊     | 157/324 [00:25<00:27,  6.12it/s]\u001b[A\n",
      "validation minibatch loop:  49%|████▉     | 158/324 [00:25<00:28,  5.90it/s]\u001b[A\n",
      "validation minibatch loop:  49%|████▉     | 159/324 [00:25<00:26,  6.19it/s]\u001b[A\n",
      "validation minibatch loop:  49%|████▉     | 160/324 [00:25<00:26,  6.13it/s]\u001b[A\n",
      "validation minibatch loop:  50%|████▉     | 161/324 [00:26<00:26,  6.08it/s]\u001b[A\n",
      "validation minibatch loop:  50%|█████     | 162/324 [00:26<00:26,  6.00it/s]\u001b[A\n",
      "validation minibatch loop:  50%|█████     | 163/324 [00:26<00:27,  5.85it/s]\u001b[A\n",
      "validation minibatch loop:  51%|█████     | 164/324 [00:26<00:25,  6.27it/s]\u001b[A\n",
      "validation minibatch loop:  51%|█████     | 165/324 [00:26<00:24,  6.46it/s]\u001b[A\n",
      "validation minibatch loop:  51%|█████     | 166/324 [00:26<00:24,  6.55it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 167/324 [00:27<00:25,  6.27it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 168/324 [00:27<00:24,  6.40it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 169/324 [00:27<00:24,  6.35it/s]\u001b[A\n",
      "validation minibatch loop:  52%|█████▏    | 170/324 [00:27<00:24,  6.33it/s]\u001b[A\n",
      "validation minibatch loop:  53%|█████▎    | 171/324 [00:27<00:24,  6.16it/s]\u001b[A\n",
      "validation minibatch loop:  53%|█████▎    | 172/324 [00:27<00:27,  5.61it/s]\u001b[A\n",
      "validation minibatch loop:  53%|█████▎    | 173/324 [00:28<00:27,  5.56it/s]\u001b[A\n",
      "validation minibatch loop:  54%|█████▎    | 174/324 [00:28<00:26,  5.76it/s]\u001b[A\n",
      "validation minibatch loop:  54%|█████▍    | 175/324 [00:28<00:25,  5.89it/s]\u001b[A\n",
      "validation minibatch loop:  54%|█████▍    | 176/324 [00:28<00:23,  6.33it/s]\u001b[A\n",
      "validation minibatch loop:  55%|█████▍    | 177/324 [00:28<00:22,  6.55it/s]\u001b[A\n",
      "validation minibatch loop:  55%|█████▍    | 178/324 [00:28<00:22,  6.61it/s]\u001b[A\n",
      "validation minibatch loop:  55%|█████▌    | 179/324 [00:28<00:22,  6.45it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▌    | 180/324 [00:29<00:24,  5.96it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▌    | 181/324 [00:29<00:23,  6.00it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▌    | 182/324 [00:29<00:23,  6.00it/s]\u001b[A\n",
      "validation minibatch loop:  56%|█████▋    | 183/324 [00:29<00:23,  6.06it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 184/324 [00:29<00:22,  6.16it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 185/324 [00:29<00:22,  6.19it/s]\u001b[A\n",
      "validation minibatch loop:  57%|█████▋    | 186/324 [00:30<00:22,  6.16it/s]\u001b[A\n",
      "validation minibatch loop:  58%|█████▊    | 187/324 [00:30<00:21,  6.28it/s]\u001b[A\n",
      "validation minibatch loop:  58%|█████▊    | 188/324 [00:30<00:22,  6.18it/s]\u001b[A\n",
      "validation minibatch loop:  58%|█████▊    | 189/324 [00:30<00:21,  6.21it/s]\u001b[A\n",
      "validation minibatch loop:  59%|█████▊    | 190/324 [00:30<00:21,  6.29it/s]\u001b[A\n",
      "validation minibatch loop:  59%|█████▉    | 191/324 [00:30<00:21,  6.16it/s]\u001b[A\n",
      "validation minibatch loop:  59%|█████▉    | 192/324 [00:31<00:21,  6.21it/s]\u001b[A\n",
      "validation minibatch loop:  60%|█████▉    | 193/324 [00:31<00:19,  6.67it/s]\u001b[A\n",
      "validation minibatch loop:  60%|█████▉    | 194/324 [00:31<00:19,  6.68it/s]\u001b[A\n",
      "validation minibatch loop:  60%|██████    | 195/324 [00:31<00:18,  6.87it/s]\u001b[A\n",
      "validation minibatch loop:  60%|██████    | 196/324 [00:31<00:18,  6.76it/s]\u001b[A\n",
      "validation minibatch loop:  61%|██████    | 197/324 [00:31<00:19,  6.54it/s]\u001b[A\n",
      "validation minibatch loop:  61%|██████    | 198/324 [00:31<00:19,  6.41it/s]\u001b[A\n",
      "validation minibatch loop:  61%|██████▏   | 199/324 [00:32<00:19,  6.53it/s]\u001b[A\n",
      "validation minibatch loop:  62%|██████▏   | 200/324 [00:32<00:19,  6.33it/s]\u001b[A\n",
      "validation minibatch loop:  62%|██████▏   | 201/324 [00:32<00:19,  6.18it/s]\u001b[A\n",
      "validation minibatch loop:  62%|██████▏   | 202/324 [00:32<00:20,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 203/324 [00:32<00:20,  6.03it/s]\u001b[A\n",
      "validation minibatch loop:  63%|██████▎   | 204/324 [00:32<00:19,  6.05it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation minibatch loop:  63%|██████▎   | 205/324 [00:33<00:19,  6.12it/s]\u001b[A\n",
      "validation minibatch loop:  64%|██████▎   | 206/324 [00:33<00:18,  6.43it/s]\u001b[A\n",
      "validation minibatch loop:  64%|██████▍   | 207/324 [00:33<00:18,  6.46it/s]\u001b[A\n",
      "validation minibatch loop:  64%|██████▍   | 208/324 [00:33<00:17,  6.62it/s]\u001b[A\n",
      "validation minibatch loop:  65%|██████▍   | 209/324 [00:33<00:17,  6.42it/s]\u001b[A\n",
      "validation minibatch loop:  65%|██████▍   | 210/324 [00:33<00:17,  6.33it/s]\u001b[A\n",
      "validation minibatch loop:  65%|██████▌   | 211/324 [00:34<00:17,  6.34it/s]\u001b[A\n",
      "validation minibatch loop:  65%|██████▌   | 212/324 [00:34<00:17,  6.25it/s]\u001b[A\n",
      "validation minibatch loop:  66%|██████▌   | 213/324 [00:34<00:17,  6.22it/s]\u001b[A\n",
      "validation minibatch loop:  66%|██████▌   | 214/324 [00:34<00:17,  6.14it/s]\u001b[A\n",
      "validation minibatch loop:  66%|██████▋   | 215/324 [00:34<00:17,  6.17it/s]\u001b[A\n",
      "validation minibatch loop:  67%|██████▋   | 216/324 [00:34<00:18,  5.89it/s]\u001b[A\n",
      "validation minibatch loop:  67%|██████▋   | 217/324 [00:35<00:18,  5.91it/s]\u001b[A\n",
      "validation minibatch loop:  67%|██████▋   | 218/324 [00:35<00:18,  5.84it/s]\u001b[A\n",
      "validation minibatch loop:  68%|██████▊   | 219/324 [00:35<00:18,  5.56it/s]\u001b[A\n",
      "validation minibatch loop:  68%|██████▊   | 220/324 [00:35<00:18,  5.71it/s]\u001b[A\n",
      "validation minibatch loop:  68%|██████▊   | 221/324 [00:35<00:17,  5.88it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▊   | 222/324 [00:35<00:17,  5.97it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▉   | 223/324 [00:36<00:16,  5.97it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▉   | 224/324 [00:36<00:16,  6.09it/s]\u001b[A\n",
      "validation minibatch loop:  69%|██████▉   | 225/324 [00:36<00:16,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  70%|██████▉   | 226/324 [00:36<00:16,  6.06it/s]\u001b[A\n",
      "validation minibatch loop:  70%|███████   | 227/324 [00:36<00:14,  6.49it/s]\u001b[A\n",
      "validation minibatch loop:  70%|███████   | 228/324 [00:36<00:16,  5.90it/s]\u001b[A\n",
      "validation minibatch loop:  71%|███████   | 229/324 [00:37<00:15,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:  71%|███████   | 230/324 [00:37<00:15,  6.08it/s]\u001b[A\n",
      "validation minibatch loop:  71%|███████▏  | 231/324 [00:37<00:15,  6.09it/s]\u001b[A\n",
      "validation minibatch loop:  72%|███████▏  | 232/324 [00:37<00:15,  5.98it/s]\u001b[A\n",
      "validation minibatch loop:  72%|███████▏  | 233/324 [00:37<00:15,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:  72%|███████▏  | 234/324 [00:37<00:15,  5.82it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 235/324 [00:38<00:14,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 236/324 [00:38<00:13,  6.35it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 237/324 [00:38<00:13,  6.27it/s]\u001b[A\n",
      "validation minibatch loop:  73%|███████▎  | 238/324 [00:38<00:14,  6.14it/s]\u001b[A\n",
      "validation minibatch loop:  74%|███████▍  | 239/324 [00:38<00:13,  6.37it/s]\u001b[A\n",
      "validation minibatch loop:  74%|███████▍  | 240/324 [00:38<00:13,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  74%|███████▍  | 241/324 [00:39<00:13,  6.15it/s]\u001b[A\n",
      "validation minibatch loop:  75%|███████▍  | 242/324 [00:39<00:13,  5.96it/s]\u001b[A\n",
      "validation minibatch loop:  75%|███████▌  | 243/324 [00:39<00:13,  5.82it/s]\u001b[A\n",
      "validation minibatch loop:  75%|███████▌  | 244/324 [00:39<00:13,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  76%|███████▌  | 245/324 [00:39<00:12,  6.16it/s]\u001b[A\n",
      "validation minibatch loop:  76%|███████▌  | 246/324 [00:39<00:12,  6.35it/s]\u001b[A\n",
      "validation minibatch loop:  76%|███████▌  | 247/324 [00:39<00:11,  6.73it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 248/324 [00:40<00:11,  6.79it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 249/324 [00:40<00:11,  6.68it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 250/324 [00:40<00:11,  6.32it/s]\u001b[A\n",
      "validation minibatch loop:  77%|███████▋  | 251/324 [00:40<00:10,  6.70it/s]\u001b[A\n",
      "validation minibatch loop:  78%|███████▊  | 252/324 [00:40<00:11,  6.51it/s]\u001b[A\n",
      "validation minibatch loop:  78%|███████▊  | 253/324 [00:40<00:11,  6.15it/s]\u001b[A\n",
      "validation minibatch loop:  78%|███████▊  | 254/324 [00:41<00:11,  5.98it/s]\u001b[A\n",
      "validation minibatch loop:  79%|███████▊  | 255/324 [00:41<00:11,  6.04it/s]\u001b[A\n",
      "validation minibatch loop:  79%|███████▉  | 256/324 [00:41<00:10,  6.36it/s]\u001b[A\n",
      "validation minibatch loop:  79%|███████▉  | 257/324 [00:41<00:10,  6.33it/s]\u001b[A\n",
      "validation minibatch loop:  80%|███████▉  | 258/324 [00:41<00:11,  5.88it/s]\u001b[A\n",
      "validation minibatch loop:  80%|███████▉  | 259/324 [00:41<00:11,  5.91it/s]\u001b[A\n",
      "validation minibatch loop:  80%|████████  | 260/324 [00:42<00:10,  6.01it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████  | 261/324 [00:42<00:10,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████  | 262/324 [00:42<00:10,  6.02it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████  | 263/324 [00:42<00:10,  6.02it/s]\u001b[A\n",
      "validation minibatch loop:  81%|████████▏ | 264/324 [00:42<00:10,  5.73it/s]\u001b[A\n",
      "validation minibatch loop:  82%|████████▏ | 265/324 [00:42<00:09,  6.02it/s]\u001b[A\n",
      "validation minibatch loop:  82%|████████▏ | 266/324 [00:43<00:09,  6.31it/s]\u001b[A\n",
      "validation minibatch loop:  82%|████████▏ | 267/324 [00:43<00:09,  6.29it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 268/324 [00:43<00:08,  6.80it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 269/324 [00:43<00:08,  6.57it/s]\u001b[A\n",
      "validation minibatch loop:  83%|████████▎ | 270/324 [00:43<00:08,  6.52it/s]\u001b[A\n",
      "validation minibatch loop:  84%|████████▎ | 271/324 [00:43<00:08,  6.14it/s]\u001b[A\n",
      "validation minibatch loop:  84%|████████▍ | 272/324 [00:43<00:08,  6.10it/s]\u001b[A\n",
      "validation minibatch loop:  84%|████████▍ | 273/324 [00:44<00:08,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▍ | 274/324 [00:44<00:08,  5.98it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▍ | 275/324 [00:44<00:08,  5.89it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▌ | 276/324 [00:44<00:07,  6.14it/s]\u001b[A\n",
      "validation minibatch loop:  85%|████████▌ | 277/324 [00:44<00:07,  6.06it/s]\u001b[A\n",
      "validation minibatch loop:  86%|████████▌ | 278/324 [00:44<00:07,  5.97it/s]\u001b[A\n",
      "validation minibatch loop:  86%|████████▌ | 279/324 [00:45<00:07,  6.00it/s]\u001b[A\n",
      "validation minibatch loop:  86%|████████▋ | 280/324 [00:45<00:07,  6.11it/s]\u001b[A\n",
      "validation minibatch loop:  87%|████████▋ | 281/324 [00:45<00:07,  6.06it/s]\u001b[A\n",
      "validation minibatch loop:  87%|████████▋ | 282/324 [00:45<00:06,  6.05it/s]\u001b[A\n",
      "validation minibatch loop:  87%|████████▋ | 283/324 [00:45<00:06,  6.14it/s]\u001b[A\n",
      "validation minibatch loop:  88%|████████▊ | 284/324 [00:45<00:06,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  88%|████████▊ | 285/324 [00:46<00:06,  6.05it/s]\u001b[A\n",
      "validation minibatch loop:  88%|████████▊ | 286/324 [00:46<00:06,  5.98it/s]\u001b[A\n",
      "validation minibatch loop:  89%|████████▊ | 287/324 [00:46<00:06,  6.05it/s]\u001b[A\n",
      "validation minibatch loop:  89%|████████▉ | 288/324 [00:46<00:06,  5.96it/s]\u001b[A\n",
      "validation minibatch loop:  89%|████████▉ | 289/324 [00:46<00:06,  5.77it/s]\u001b[A\n",
      "validation minibatch loop:  90%|████████▉ | 290/324 [00:46<00:05,  5.88it/s]\u001b[A\n",
      "validation minibatch loop:  90%|████████▉ | 291/324 [00:47<00:05,  5.95it/s]\u001b[A\n",
      "validation minibatch loop:  90%|█████████ | 292/324 [00:47<00:05,  6.02it/s]\u001b[A\n",
      "validation minibatch loop:  90%|█████████ | 293/324 [00:47<00:05,  6.03it/s]\u001b[A\n",
      "validation minibatch loop:  91%|█████████ | 294/324 [00:47<00:05,  5.99it/s]\u001b[A\n",
      "validation minibatch loop:  91%|█████████ | 295/324 [00:47<00:04,  6.02it/s]\u001b[A\n",
      "validation minibatch loop:  91%|█████████▏| 296/324 [00:47<00:04,  6.32it/s]\u001b[A\n",
      "validation minibatch loop:  92%|█████████▏| 297/324 [00:48<00:04,  6.27it/s]\u001b[A\n",
      "validation minibatch loop:  92%|█████████▏| 298/324 [00:48<00:04,  6.12it/s]\u001b[A\n",
      "validation minibatch loop:  92%|█████████▏| 299/324 [00:48<00:04,  6.08it/s]\u001b[A\n",
      "validation minibatch loop:  93%|█████████▎| 300/324 [00:48<00:04,  5.90it/s]\u001b[A\n",
      "validation minibatch loop:  93%|█████████▎| 301/324 [00:48<00:03,  5.98it/s]\u001b[A\n",
      "validation minibatch loop:  93%|█████████▎| 302/324 [00:48<00:03,  6.31it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▎| 303/324 [00:49<00:03,  6.37it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▍| 304/324 [00:49<00:03,  6.21it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▍| 305/324 [00:49<00:03,  6.18it/s]\u001b[A\n",
      "validation minibatch loop:  94%|█████████▍| 306/324 [00:49<00:02,  6.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation minibatch loop:  95%|█████████▍| 307/324 [00:49<00:02,  6.07it/s]\u001b[A\n",
      "validation minibatch loop:  95%|█████████▌| 308/324 [00:49<00:02,  6.09it/s]\u001b[A\n",
      "validation minibatch loop:  95%|█████████▌| 309/324 [00:50<00:02,  6.43it/s]\u001b[A\n",
      "validation minibatch loop:  96%|█████████▌| 310/324 [00:50<00:02,  6.47it/s]\u001b[A\n",
      "validation minibatch loop:  96%|█████████▌| 311/324 [00:50<00:02,  6.33it/s]\u001b[A\n",
      "validation minibatch loop:  96%|█████████▋| 312/324 [00:50<00:01,  6.48it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 313/324 [00:50<00:01,  6.40it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 314/324 [00:50<00:01,  6.34it/s]\u001b[A\n",
      "validation minibatch loop:  97%|█████████▋| 315/324 [00:51<00:01,  6.21it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 316/324 [00:51<00:01,  6.19it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 317/324 [00:51<00:01,  6.63it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 318/324 [00:51<00:00,  6.37it/s]\u001b[A\n",
      "validation minibatch loop:  98%|█████████▊| 319/324 [00:51<00:00,  6.29it/s]\u001b[A\n",
      "validation minibatch loop:  99%|█████████▉| 320/324 [00:51<00:00,  5.97it/s]\u001b[A\n",
      "validation minibatch loop:  99%|█████████▉| 321/324 [00:51<00:00,  6.00it/s]\u001b[A\n",
      "validation minibatch loop:  99%|█████████▉| 322/324 [00:52<00:00,  6.31it/s]\u001b[A\n",
      "validation minibatch loop: 100%|█████████▉| 323/324 [00:52<00:00,  6.59it/s]\u001b[A\n",
      "validation minibatch loop: 100%|██████████| 324/324 [00:52<00:00,  6.68it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "real_Y, predict_Y = [], []\n",
    "\n",
    "pbar = tqdm(\n",
    "    range(0, len(test_X), batch_size), desc = 'validation minibatch loop'\n",
    ")\n",
    "for i in pbar:\n",
    "    batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "    batch_char = test_char[i : min(i + batch_size, test_X.shape[0])]\n",
    "    batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "    predicted = pred2label(sess.run(model.tags_seq,\n",
    "            feed_dict = {\n",
    "                model.query: batch_x,\n",
    "                model.story: batch_x_expand,\n",
    "                model.char_ids: batch_char,\n",
    "            },\n",
    "    ))\n",
    "    real = pred2label(np.argmax(batch_y, axis = 2))\n",
    "    predict_Y.extend(predicted)\n",
    "    real_Y.extend(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ADJ       0.98      0.98      0.98     22626\n",
      "        ADP       0.99      0.99      0.99     60045\n",
      "        ADV       0.97      0.98      0.98     23537\n",
      "        AUX       0.99      0.99      0.99      5195\n",
      "      CCONJ       0.99      0.99      0.99     18357\n",
      "        DET       0.99      0.99      0.99     19762\n",
      "       NOUN       0.99      0.99      0.99    134505\n",
      "        NUM       0.99      0.99      0.99     22083\n",
      "       PART       0.97      0.97      0.97      2924\n",
      "       PRON       0.99      0.99      0.99     23783\n",
      "      PROPN       0.99      0.99      0.99    114144\n",
      "      SCONJ       0.96      0.95      0.95      7534\n",
      "        SYM       0.97      0.98      0.97      1335\n",
      "       VERB       0.99      0.99      0.99     60834\n",
      "          X       0.93      0.68      0.79       186\n",
      "\n",
      "avg / total       0.99      0.99      0.99    516850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.array(real_Y).ravel(), np.array(predict_Y).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dynamic_memory/U',\n",
       " 'dynamic_memory/V',\n",
       " 'dynamic_memory/W',\n",
       " 'dynamic_memory/h_bias',\n",
       " 'dynamic_memory/h2_bias',\n",
       " 'embedding_projection/Embedding',\n",
       " 'hidden_states',\n",
       " 'keys',\n",
       " 'h_candidate0/alpha',\n",
       " 'Variable',\n",
       " 'Variable_1',\n",
       " 'rnn/multi_rnn_cell/cell_0/char/kernel',\n",
       " 'rnn/multi_rnn_cell/cell_0/char/bias',\n",
       " 'rnn/multi_rnn_cell/cell_1/char/kernel',\n",
       " 'rnn/multi_rnn_cell/cell_1/char/bias',\n",
       " 'rnn/multi_rnn_cell/cell_0/word/kernel',\n",
       " 'rnn/multi_rnn_cell/cell_0/word/bias',\n",
       " 'rnn/multi_rnn_cell/cell_1/word/kernel',\n",
       " 'rnn/multi_rnn_cell/cell_1/word/bias',\n",
       " 'dense/kernel',\n",
       " 'dense/bias',\n",
       " 'transitions',\n",
       " 'logits']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'entity-pos/model.ckpt')\n",
    "\n",
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'OptimizeLoss' not in n.name\n",
    "        and 'Global_Step' not in n.name\n",
    "        and 'Epoch_Step' not in n.name\n",
    "        and 'learning_rate' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))\n",
    "        \n",
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from entity-pos/model.ckpt\n",
      "INFO:tensorflow:Froze 22 variables.\n",
      "INFO:tensorflow:Converted 22 variables to const ops.\n",
      "926 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('entity-pos', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('entity-pos/frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'KUALA LUMPUR: Sempena sambutan Aidilfitri minggu depan, Perdana Menteri Tun Dr Mahathir Mohamad dan Menteri Pengangkutan Anthony Loke Siew Fook menitipkan pesanan khas kepada orang ramai yang mahu pulang ke kampung halaman masing-masing. Dalam video pendek terbitan Jabatan Keselamatan Jalan Raya (JKJR) itu, Dr Mahathir menasihati mereka supaya berhenti berehat dan tidur sebentar  sekiranya mengantuk ketika memandu.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_str_idx(corpus, dic, UNK = 0):\n",
    "    maxlen = max([len(i) for i in corpus])\n",
    "    X = np.zeros((len(corpus), maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i][:maxlen][::-1]):\n",
    "            val = dic[k] if k in dic else UNK\n",
    "            X[i, -1 - no] = val\n",
    "    return X\n",
    "\n",
    "def generate_char_seq(batch, idx2word, char2idx):\n",
    "    x = [[len(idx2word[i]) for i in k] for k in batch]\n",
    "    maxlen = max([j for i in x for j in i])\n",
    "    temp = np.zeros((batch.shape[0], batch.shape[1], maxlen), dtype = np.int32)\n",
    "    for i in range(batch.shape[0]):\n",
    "        for k in range(batch.shape[1]):\n",
    "            for no, c in enumerate(idx2word[batch[i, k]].lower()):\n",
    "                temp[i, k, -1 - no] = char2idx[c]\n",
    "    return temp\n",
    "\n",
    "sequence = process_string(string)\n",
    "X_seq = char_str_idx([sequence], word2idx, 2)\n",
    "X_char_seq = generate_char_seq(X_seq, idx2word, char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kuala PROPN\n",
      "Lumpur PROPN\n",
      "Sempena PROPN\n",
      "sambutan NOUN\n",
      "Aidilfitri NOUN\n",
      "minggu VERB\n",
      "depan SCONJ\n",
      "Perdana PROPN\n",
      "Menteri PROPN\n",
      "Tun X\n",
      "Dr VERB\n",
      "Mahathir DET\n",
      "Mohamad VERB\n",
      "dan CCONJ\n",
      "Menteri NOUN\n",
      "Pengangkutan DET\n",
      "Anthony DET\n",
      "Loke NOUN\n",
      "Siew DET\n",
      "Fook NOUN\n",
      "menitipkan DET\n",
      "pesanan NOUN\n",
      "khas ADJ\n",
      "kepada ADP\n",
      "orang NOUN\n",
      "ramai ADJ\n",
      "yang PRON\n",
      "mahu ADV\n",
      "pulang VERB\n",
      "ke ADP\n",
      "kampung NOUN\n",
      "halaman NOUN\n",
      "masing-masing NOUN\n",
      "Dalam VERB\n",
      "video NOUN\n",
      "pendek ADJ\n",
      "terbitan NOUN\n",
      "Jabatan VERB\n",
      "Keselamatan PROPN\n",
      "Jalan PROPN\n",
      "Raya PROPN\n",
      "Jkjr ADV\n",
      "itu DET\n",
      "Dr DET\n",
      "Mahathir ADV\n",
      "menasihati VERB\n",
      "mereka PRON\n",
      "supaya ADV\n",
      "berhenti VERB\n",
      "berehat NOUN\n",
      "dan CCONJ\n",
      "tidur NOUN\n",
      "sebentar ADV\n",
      "sekiranya PROPN\n",
      "mengantuk PROPN\n",
      "ketika SCONJ\n",
      "memandu VERB\n"
     ]
    }
   ],
   "source": [
    "story = g.get_tensor_by_name('import/story:0')\n",
    "char_ids = g.get_tensor_by_name('import/char_ids:0')\n",
    "question = g.get_tensor_by_name('import/question:0')\n",
    "tags_seq = g.get_tensor_by_name('import/logits:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)\n",
    "batch_x_expand = np.expand_dims(X_seq,axis = 1)\n",
    "predicted = test_sess.run(tags_seq,\n",
    "            feed_dict = {\n",
    "                question: X_seq,\n",
    "                char_ids: X_char_seq,\n",
    "                story: batch_x_expand\n",
    "            })[0]\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    print(sequence[i],idx2tag[predicted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefix Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give initial sentence, then the models will continue to generate the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [Malaya/example/prefix-generator](https://github.com/huseinzol05/Malaya/tree/master/example/prefix-generator).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.74 s, sys: 901 ms, total: 5.64 s\n",
      "Wall time: 8.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import malaya\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GPT2\n",
    "\n",
    "Malaya provided Pretrained GPT2 model, specific to Malay, we called it GPT2-Bahasa. This interface not able us to use it to do custom training.\n",
    "\n",
    "GPT2-Bahasa was pretrained on ~0.9 billion words, and below is the list of dataset we trained,\n",
    "\n",
    "1. [dumping wikipedia (222MB)](https://github.com/huseinzol05/Malaya-Dataset#wikipedia-1).\n",
    "2. [local news (257MB)](https://github.com/huseinzol05/Malaya-Dataset#public-news).\n",
    "3. [local parliament text (45MB)](https://github.com/huseinzol05/Malaya-Dataset#parliament).\n",
    "4. [IIUM Confession (74MB)](https://github.com/huseinzol05/Malaya-Dataset#iium-confession).\n",
    "5. [Wattpad (74MB)](https://github.com/huseinzol05/Malaya-Dataset#wattpad).\n",
    "6. [Academia PDF (42MB)](https://github.com/huseinzol05/Malaya-Dataset#academia-pdf).\n",
    "7. [Common-Crawl (3GB)](https://github.com/huseinzol05/malaya-dataset#common-crawl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to download pretrained model for GPT2-Bahasa and use it for custom transfer-learning, you can download it here, https://github.com/huseinzol05/Malaya/tree/master/pretrained-model/gpt2, some notebooks to help you get started.\n",
    "\n",
    "**Here we hope these models are not use to finetune for spreading fake news**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load model\n",
    "\n",
    "GPT2-Bahasa only available `117M` and `345M` models.\n",
    "\n",
    "1. `117M` size around 442MB.\n",
    "2. `345M` is around 1.2GB.\n",
    "\n",
    "```python\n",
    "def gpt2(\n",
    "    model: str = '345M',\n",
    "    generate_length: int = 256,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int = 40,\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Load GPT2 model to generate a string given a prefix string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str, optional (default='345M')\n",
    "        Model architecture supported. Allowed values:\n",
    "\n",
    "        * ``'117M'`` - GPT2 117M parameters.\n",
    "        * ``'345M'`` - GPT2 345M parameters.\n",
    "\n",
    "    generate_length : int, optional (default=256)\n",
    "        length of sentence to generate.\n",
    "    temperature : float, optional (default=1.0)\n",
    "        temperature value, value should between 0 and 1.\n",
    "    top_k : int, optional (default=40)\n",
    "        top-k in nucleus sampling selection.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: malaya.transformers.gpt2.Model class\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:19: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:140: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:141: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:142: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/gpt2/__init__.py:142: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /Users/huseinzolkepli/Malaya/gpt2/117M/gpt2-bahasa-117M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = malaya.generator.gpt2(model = '117M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'ceritanya sebegini, aku bangun pagi baca surat khabar berita harian, tetiba aku nampak cerita seram, '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate\n",
    "\n",
    "`model.generate` accepts a string.\n",
    "\n",
    "```python\n",
    "def generate(self, string: str):\n",
    "    \"\"\"\n",
    "    generate a text given an initial string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: str\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ceritanya sebegini, aku bangun pagi baca surat khabar berita harian, tetiba aku nampak cerita seram, ara aku yang lain keluar, aku pandang cerita tapi tak ingat, aku takut dan bimbang aku terpaksa marah kerana hati aku yang berada di sekeliling aku tadi tak putus-putus.\n",
      "Dalam diam, aku juga merasa kagum dan terharu bila aku bangun pagi untuk bangun dan tengok kisah seram ni, masa tu aku terus pandang, bila aku berada dalam bilik yang indah, aku tahu tentang benda yang nak diperkatakan.\n",
      "â€œTu sikit, dengan banyak masa aku nak keluar dan keluar aku dah mula bangun pagi, aku nak keluar lagi, lepas tu nanti terus masuk ke bilik sambil nampak benda yang tak ada yang nak diperkatakan.\n",
      "Tak tau cerita tu macam benda yang boleh aku buat kalau rasa macam cerita.\n",
      "Sampai di bilik, aku pun rasa macam, benda yang nak diperkatakan tu bukan benda yang perlu aku buat.\n",
      "Macam tak percaya apa yang aku buat ni?\n",
      "Mungkin benda yang nak diperkatakan itu boleh buat aku jugak, cuma benda yang boleh bagi aku kata tak logik atau memang betul.\n",
      "Cuma yang paling aku nak cakap ni adalah benda pelik yang aku fikir nak nampak yang tak boleh dan kalau tak logik pun tak patut.\n",
      "So, apa kata dorang mainkan benda yang aku cakap ni.\n",
      "Rasa pelik dan amat pelik kan?\n",
      "Macam nak buat orang lain jadi macam benda pelik dan susah sangat nak buat\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/huseinzolkepli/Malaya/gpt2/345M/gpt2-bahasa-345M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = malaya.generator.gpt2(model = '345M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ceritanya sebegini, aku bangun pagi baca surat khabar berita harian, tetiba aku nampak cerita seram, omputeh-uteh cerita lama-lama, seram tak boleh bayang\n",
      "Sebelum kejadian, dalam 2 jam aku buat panggilan polis , lepas tu kira la sendiri nak ke lokasi.\n",
      "Tengok cerita lama..\n",
      "Sekarang ni, apa yang aku lalui, kita yang jaga diri, kita yang jaga kesihatan dan juga kita yang jaga minda dalam hidup.\n",
      "Maka, inilah jalan penyelesaian terbaiknya.\n",
      "Jangan lupakan manusia\n",
      "Orang yang paling ditakuti untuk berjaya dalam hidup, tidak akan jumpa yang tersayang!\n",
      "Jangan rosakkan masa depannya, ingatlah apa yang kita nak buat, walaupun pahit untuk ditelan.\n",
      "Jangan lupakan orang lain - masa depan mereka.\n",
      "Jangan lupakan orang - masa itulah kita yang lebih dicintai.\n",
      "Jangan lupakan orang - orang yang kita sayang, mereka bukan orang yang tersayang!\n",
      "Jangan lupakan orang - orang yang kita cinta, mereka cinta pada kita.\n",
      "Jangan lupakan diri - diri kita - yang kita punya, yang kita tinggal adalah masa lalu kita.\n",
      "Jangan lupakan orang lain - orang yang kita cinta, lebih indah dari masa lalu kita.\n",
      "Jangan lupakan semua orang - orang yang tinggal ataupun hidup.\n",
      "Jangan cuba lupakan diri kita - kerja keras dan selalu ada masa depan kita.\n",
      "Jangan pernah putus rasa - kecewa kerana kita telah banyak berubah.\n",
      "Jangan pernah putus putus asa kerana kita\n"
     ]
    }
   ],
   "source": [
    "string = 'ceritanya sebegini, aku bangun pagi baca surat khabar berita harian, tetiba aku nampak cerita seram, '\n",
    "print(model.generate(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Babble method\n",
    "\n",
    "We also can generate a text like GPT2 using Transformer-Bahasa. Right now only supported BERT, ALBERT and ELECTRA.\n",
    "\n",
    "```python\n",
    "def babble(\n",
    "    string: str,\n",
    "    model,\n",
    "    generate_length: int = 30,\n",
    "    leed_out_len: int = 1,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int = 100,\n",
    "    burnin: int = 15,\n",
    "    batch_size: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use pretrained transformer models to generate a string given a prefix string.\n",
    "    https://github.com/nyu-dl/bert-gen, https://arxiv.org/abs/1902.04094\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string: str\n",
    "    model: object\n",
    "        transformer interface object. Right now only supported BERT, ALBERT.\n",
    "    generate_length : int, optional (default=256)\n",
    "        length of sentence to generate.\n",
    "    leed_out_len : int, optional (default=1)\n",
    "        length of extra masks for each iteration. \n",
    "    temperature: float, optional (default=1.0)\n",
    "        logits * temperature.\n",
    "    top_k: int, optional (default=100)\n",
    "        k for top-k sampling.\n",
    "    burnin: int, optional (default=15)\n",
    "        for the first burnin steps, sample from the entire next word distribution, instead of top_k.\n",
    "    batch_size: int, optional (default=5)\n",
    "        generate sentences size of batch_size.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: List[str]\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you already installed `tensorflow-probability`,\n",
    "\n",
    "```bash\n",
    "pip3 install tensorflow-probability==0.7.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow-probability==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/modeling.py:242: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:79: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:93: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/sampling.py:26: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:115: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:118: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:119: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:121: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:122: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:128: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/Malaya/malaya/transformers/electra/__init__.py:130: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /Users/huseinzolkepli/Malaya/electra-model/base/electra-base/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "electra = malaya.transformer.load(model = 'electra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , terseksa juga hidup di sekeliling aku . Diorang tak tahu sebab diorang tahu titik hitam yang mana kita tengok dari mana kita sendiri nampak cerita ke . Haih .',\n",
       " 'ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , tengah baca benda besar pasal bumbung bilik . Rasanya sejuk macam pulau harapan . So aku baca cerita seram pelik . Jadi sedih juga dengar cerita seram seram ni .',\n",
       " 'ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , lalu ibu ambil pusing bagi buku sejarah . Dah baca marsh pastu aku dah buat thread seram , ada dalam masa terdekat baru bangun . Sedih , hidup lagi',\n",
       " 'ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , mesti seram sampai aku ikut takdir Allah bagi betul2 aib kita kembali menulis mengenai kisah cinta aku ini malam , aku tersedar selepas ada seorang lelaki tersedar .',\n",
       " 'ceritanya sebegini , aku bangun pagi baca surat khabar berita harian , tetiba aku nampak cerita seram , sedangkan yang baca pasal negara berpagarism memang patut berterima kasih . Kata ayah , ingatkan boleh mandi atau bilik pun boleh , kena air dan bukannya ikut kemampuan']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya.generator.babble(string, electra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngrams\n",
    "\n",
    "You can generate ngrams pretty easy using this interface,\n",
    "\n",
    "```python\n",
    "def ngrams(\n",
    "    sequence,\n",
    "    n: int,\n",
    "    pad_left = False,\n",
    "    pad_right = False,\n",
    "    left_pad_symbol = None,\n",
    "    right_pad_symbol = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    generate ngrams.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : List[str]\n",
    "        list of tokenize words.\n",
    "    n : int\n",
    "        ngram size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ngram: list\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('saya', 'suka'), ('suka', 'makan'), ('makan', 'ayam')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'saya suka makan ayam'\n",
    "\n",
    "list(malaya.generator.ngrams(string.split(), n = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 'saya'),\n",
       " ('saya', 'suka'),\n",
       " ('suka', 'makan'),\n",
       " ('makan', 'ayam'),\n",
       " ('ayam', None)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(malaya.generator.ngrams(string.split(), n = 2, pad_left = True, pad_right = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('START', 'saya'),\n",
       " ('saya', 'suka'),\n",
       " ('suka', 'makan'),\n",
       " ('makan', 'ayam'),\n",
       " ('ayam', None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(malaya.generator.ngrams(string.split(), n = 2, pad_left = True, pad_right = True,\n",
    "                            left_pad_symbol = 'START'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('START', 'saya'),\n",
       " ('saya', 'suka'),\n",
       " ('suka', 'makan'),\n",
       " ('makan', 'ayam'),\n",
       " ('ayam', 'END')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(malaya.generator.ngrams(string.split(), n = 2, pad_left = True, pad_right = True,\n",
    "                            left_pad_symbol = 'START', right_pad_symbol = 'END'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

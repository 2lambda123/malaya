{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id_gsd-ud-train.conllu.txt') as fopen:\n",
    "    corpus = fopen.read().split('\\n')\n",
    "    \n",
    "with open('id_gsd-ud-test.conllu.txt') as fopen:\n",
    "    corpus.extend(fopen.read().split('\\n'))\n",
    "    \n",
    "with open('id_gsd-ud-dev.conllu.txt') as fopen:\n",
    "    corpus.extend(fopen.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {'PAD': 0,'NUM':1,'UNK':2}\n",
    "tag2idx = {'PAD': 0}\n",
    "char2idx = {'PAD': 0,'NUM':1,'UNK':2}\n",
    "word_idx = 3\n",
    "tag_idx = 1\n",
    "char_idx = 3\n",
    "\n",
    "def process_string(string):\n",
    "    string = re.sub('[^A-Za-z0-9\\-\\/ ]+', ' ', string).split()\n",
    "    return [to_title(y.strip()) for y in string]\n",
    "\n",
    "def to_title(string):\n",
    "    if string.isupper():\n",
    "        string = string.title()\n",
    "    return string\n",
    "\n",
    "def process_corpus(corpus, until = None):\n",
    "    global word2idx, tag2idx, char2idx, word_idx, tag_idx, char_idx\n",
    "    sentences, words, depends, labels = [], [], [], []\n",
    "    temp_sentence, temp_word, temp_depend, temp_label = [], [], [], []\n",
    "    for sentence in corpus:\n",
    "        if len(sentence):\n",
    "            if sentence[0] == '#':\n",
    "                continue\n",
    "            sentence = sentence.split('\\t')\n",
    "            temp = process_string(sentence[1])\n",
    "            if not len(temp):\n",
    "                sentence[1] = 'EMPTY'\n",
    "            sentence[1] = process_string(sentence[1])[0]\n",
    "            for c in sentence[1]:\n",
    "                if c not in char2idx:\n",
    "                    char2idx[c] = char_idx\n",
    "                    char_idx += 1\n",
    "            if sentence[7] not in tag2idx:\n",
    "                tag2idx[sentence[7]] = tag_idx\n",
    "                tag_idx += 1\n",
    "            if sentence[1] not in word2idx:\n",
    "                word2idx[sentence[1]] = word_idx\n",
    "                word_idx += 1\n",
    "            temp_word.append(word2idx[sentence[1]])\n",
    "            temp_depend.append(int(sentence[6]) + 1)\n",
    "            temp_label.append(tag2idx[sentence[7]])\n",
    "            temp_sentence.append(sentence[1])\n",
    "        else:\n",
    "            words.append(temp_word)\n",
    "            depends.append(temp_depend)\n",
    "            labels.append(temp_label)\n",
    "            sentences.append(temp_sentence)\n",
    "            temp_word = []\n",
    "            temp_depend = []\n",
    "            temp_label = []\n",
    "            temp_sentence = []\n",
    "    return sentences[:-1], words[:-1], depends[:-1], labels[:-1]\n",
    "        \n",
    "sentences, words, depends, labels = process_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5595, 189)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pad_sequences(words,padding='post')\n",
    "depends = pad_sequences(depends,padding='post')\n",
    "labels = pad_sequences(labels,padding='post')\n",
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_char_seq(batch, UNK = 2):\n",
    "    maxlen_c = max([len(k) for k in batch])\n",
    "    x = [[len(i) for i in k] for k in batch]\n",
    "    maxlen = max([j for i in x for j in i])\n",
    "    temp = np.zeros((len(batch),maxlen_c,maxlen),dtype=np.int32)\n",
    "    for i in range(len(batch)):\n",
    "        for k in range(len(batch[i])):\n",
    "            for no, c in enumerate(batch[i][k][:maxlen][::-1]):\n",
    "                temp[i,k,-1-no] = char2idx.get(c, UNK)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {idx: tag for tag, idx in word2idx.items()}\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "char = generate_char_seq(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_X, test_X, train_Y, test_Y, train_depends, test_depends, train_char, test_char = train_test_split(words,\n",
    "                                                                           labels,\n",
    "                                                                           depends,\n",
    "                                                                           char,\n",
    "                                                                           test_size=0.1)\n",
    "train_X = words\n",
    "train_Y = labels\n",
    "train_depends = depends\n",
    "train_char = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_word,\n",
    "        dim_char,\n",
    "        dropout,\n",
    "        learning_rate,\n",
    "        hidden_size_char,\n",
    "        hidden_size_word,\n",
    "        num_layers,\n",
    "        maxlen\n",
    "    ):\n",
    "        def cells(size, reuse = False):\n",
    "            return tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.nn.rnn_cell.LSTMCell(\n",
    "                    size,\n",
    "                    initializer = tf.orthogonal_initializer(),\n",
    "                    reuse = reuse,\n",
    "                ),\n",
    "                output_keep_prob = dropout,\n",
    "            )\n",
    "        \n",
    "        self.word_ids = tf.placeholder(tf.int32, shape = [None, None])\n",
    "        self.char_ids = tf.placeholder(tf.int32, shape = [None, None, None])\n",
    "        self.labels = tf.placeholder(tf.int32, shape = [None, None])\n",
    "        self.depends = tf.placeholder(tf.int32, shape = [None, None])\n",
    "        self.maxlen = tf.shape(self.word_ids)[1]\n",
    "        self.lengths = tf.count_nonzero(self.word_ids, 1)\n",
    "\n",
    "        self.word_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(word2idx), dim_word], stddev = 1.0 / np.sqrt(dim_word)\n",
    "            )\n",
    "        )\n",
    "        self.char_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(char2idx), dim_char], stddev = 1.0 / np.sqrt(dim_char)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        word_embedded = tf.nn.embedding_lookup(\n",
    "            self.word_embeddings, self.word_ids\n",
    "        )\n",
    "        char_embedded = tf.nn.embedding_lookup(\n",
    "            self.char_embeddings, self.char_ids\n",
    "        )\n",
    "        s = tf.shape(char_embedded)\n",
    "        char_embedded = tf.reshape(\n",
    "            char_embedded, shape = [s[0] * s[1], s[-2], dim_char]\n",
    "        )\n",
    "\n",
    "        for n in range(num_layers):\n",
    "            (out_fw, out_bw), (\n",
    "                state_fw,\n",
    "                state_bw,\n",
    "            ) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = cells(hidden_size_char),\n",
    "                cell_bw = cells(hidden_size_char),\n",
    "                inputs = char_embedded,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_char_%d' % (n),\n",
    "            )\n",
    "            char_embedded = tf.concat((out_fw, out_bw), 2)\n",
    "        output = tf.reshape(\n",
    "            char_embedded[:, -1], shape = [s[0], s[1], 2 * hidden_size_char]\n",
    "        )\n",
    "        word_embedded = tf.concat([word_embedded, output], axis = -1)\n",
    "\n",
    "        for n in range(num_layers):\n",
    "            (out_fw, out_bw), (\n",
    "                state_fw,\n",
    "                state_bw,\n",
    "            ) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = cells(hidden_size_word),\n",
    "                cell_bw = cells(hidden_size_word),\n",
    "                inputs = word_embedded,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_word_%d' % (n),\n",
    "            )\n",
    "            word_embedded = tf.concat((out_fw, out_bw), 2)\n",
    "\n",
    "        logits = tf.layers.dense(word_embedded, len(idx2tag))\n",
    "        \n",
    "        tag_embeddings = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [len(idx2tag), dim_word], stddev = 1.0 / np.sqrt(dim_word)\n",
    "            )\n",
    "        )\n",
    "        logits_max = tf.argmax(logits,axis=2,output_type=tf.int32)\n",
    "        lookup_logits = tf.nn.embedding_lookup(\n",
    "            tag_embeddings, logits_max\n",
    "        )\n",
    "        (out_fw, out_bw), _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = cells(hidden_size_word),\n",
    "                cell_bw = cells(hidden_size_word),\n",
    "                inputs = word_embedded,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_word_%d' % (10),\n",
    "            )\n",
    "        \n",
    "        cast_mask = tf.cast(tf.sequence_mask(self.lengths + 1, maxlen = maxlen), dtype = tf.float32)\n",
    "        cast_mask = tf.tile(tf.expand_dims(cast_mask,axis=1),[1,self.maxlen,1]) * 10\n",
    "        \n",
    "        lookup_logits = tf.concat((out_fw, out_bw), 2)\n",
    "        logits_depends = tf.layers.dense(lookup_logits, maxlen)\n",
    "        \n",
    "        logits_depends = tf.multiply(logits_depends, cast_mask)\n",
    "        \n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\n",
    "            logits, self.labels, self.lengths\n",
    "        )\n",
    "        with tf.variable_scope(\"depends\"):\n",
    "            log_likelihood_depends, transition_params_depends = tf.contrib.crf.crf_log_likelihood(\n",
    "                logits_depends, self.depends, self.lengths\n",
    "            )\n",
    "        self.cost = tf.reduce_mean(-log_likelihood) + tf.reduce_mean(-log_likelihood_depends)\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate = learning_rate\n",
    "        ).minimize(self.cost)\n",
    "        \n",
    "        mask = tf.sequence_mask(self.lengths, maxlen = self.maxlen)\n",
    "        \n",
    "        self.tags_seq, _ = tf.contrib.crf.crf_decode(\n",
    "            logits, transition_params, self.lengths\n",
    "        )\n",
    "        self.tags_seq = tf.identity(self.tags_seq, name = 'logits')\n",
    "        \n",
    "        self.tags_seq_depends, _ = tf.contrib.crf.crf_decode(\n",
    "            logits_depends, transition_params_depends, self.lengths\n",
    "        )\n",
    "        self.tags_seq_depends = tf.identity(self.tags_seq_depends, name = 'logits_depends')\n",
    "\n",
    "        self.prediction = tf.boolean_mask(self.tags_seq, mask)\n",
    "        mask_label = tf.boolean_mask(self.labels, mask)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "        self.prediction = tf.boolean_mask(self.tags_seq_depends, mask)\n",
    "        mask_label = tf.boolean_mask(self.depends, mask)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy_depends = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dim_word = 128\n",
    "dim_char = 256\n",
    "dropout = 0.9\n",
    "learning_rate = 1e-3\n",
    "hidden_size_char = 64\n",
    "hidden_size_word = 64\n",
    "num_layers = 2\n",
    "batch_size = 16\n",
    "\n",
    "model = Model(dim_word,dim_char,dropout,learning_rate,hidden_size_char,hidden_size_word,num_layers,\n",
    "             words.shape[1])\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:54<00:00,  1.25it/s, accuracy=0.668, accuracy_depends=0.183, cost=87.1] \n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.80it/s, accuracy=0.667, accuracy_depends=0.156, cost=106] \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 307.36950397491455\n",
      "epoch: 0, training loss: 113.604116, training acc: 0.334303, training depends: 0.132292, valid loss: 89.666181, valid acc: 0.612814, valid depends: 0.180209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:52<00:00,  1.27it/s, accuracy=0.824, accuracy_depends=0.279, cost=65.2]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.873, accuracy_depends=0.217, cost=78.3]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 304.94627022743225\n",
      "epoch: 1, training loss: 73.298046, training acc: 0.723462, training depends: 0.224598, valid loss: 66.050747, valid acc: 0.805965, valid depends: 0.260614\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:49<00:00,  1.25it/s, accuracy=0.851, accuracy_depends=0.401, cost=53.8]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.84it/s, accuracy=0.894, accuracy_depends=0.283, cost=66.2]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.33295607566833\n",
      "epoch: 2, training loss: 58.497387, training acc: 0.814718, training depends: 0.310092, valid loss: 54.758951, valid acc: 0.848820, valid depends: 0.352095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:49<00:00,  1.25it/s, accuracy=0.859, accuracy_depends=0.45, cost=47]   \n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.84it/s, accuracy=0.885, accuracy_depends=0.398, cost=57.2]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.4782962799072\n",
      "epoch: 3, training loss: 49.618007, training acc: 0.845828, training depends: 0.398147, valid loss: 46.800803, valid acc: 0.866843, valid depends: 0.449136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.87, accuracy_depends=0.511, cost=41.3] \n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.9, accuracy_depends=0.441, cost=50.7]  \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 303.01437997817993\n",
      "epoch: 4, training loss: 43.798713, training acc: 0.864436, training depends: 0.464102, valid loss: 41.958503, valid acc: 0.882352, valid depends: 0.500184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.25it/s, accuracy=0.878, accuracy_depends=0.523, cost=38.3]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.84it/s, accuracy=0.894, accuracy_depends=0.491, cost=48.9]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.65866446495056\n",
      "epoch: 5, training loss: 39.696546, training acc: 0.878472, training depends: 0.512806, valid loss: 38.750176, valid acc: 0.891852, valid depends: 0.525846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.27it/s, accuracy=0.912, accuracy_depends=0.527, cost=35.9]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.91, accuracy_depends=0.428, cost=49.3] \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.6099064350128\n",
      "epoch: 6, training loss: 36.642407, training acc: 0.890689, training depends: 0.544802, valid loss: 38.512453, valid acc: 0.899887, valid depends: 0.504156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.25it/s, accuracy=0.92, accuracy_depends=0.576, cost=32.6] \n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.84it/s, accuracy=0.912, accuracy_depends=0.566, cost=41.9]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.74964022636414\n",
      "epoch: 7, training loss: 33.838288, training acc: 0.899438, training depends: 0.573574, valid loss: 32.416899, valid acc: 0.908697, valid depends: 0.602199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.25it/s, accuracy=0.905, accuracy_depends=0.588, cost=31.3]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.84it/s, accuracy=0.925, accuracy_depends=0.441, cost=47.4]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.71827507019043\n",
      "epoch: 8, training loss: 31.085550, training acc: 0.908227, training depends: 0.607838, valid loss: 32.883002, valid acc: 0.914782, valid depends: 0.561821\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.897, accuracy_depends=0.626, cost=28.1]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.91, accuracy_depends=0.536, cost=43.8] \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.8139932155609\n",
      "epoch: 9, training loss: 29.351552, training acc: 0.914069, training depends: 0.626075, valid loss: 29.849570, valid acc: 0.922865, valid depends: 0.607743\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.25it/s, accuracy=0.927, accuracy_depends=0.653, cost=26.4]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.934, accuracy_depends=0.538, cost=37.8]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.7449142932892\n",
      "epoch: 10, training loss: 27.637502, training acc: 0.919449, training depends: 0.643172, valid loss: 27.538111, valid acc: 0.928473, valid depends: 0.637713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.935, accuracy_depends=0.656, cost=24.5]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.925, accuracy_depends=0.622, cost=33.7]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.79065346717834\n",
      "epoch: 11, training loss: 25.440289, training acc: 0.925219, training depends: 0.673297, valid loss: 25.778858, valid acc: 0.931724, valid depends: 0.663602\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.24it/s, accuracy=0.943, accuracy_depends=0.683, cost=22.7]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.81it/s, accuracy=0.932, accuracy_depends=0.59, cost=36.3] \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.62933683395386\n",
      "epoch: 12, training loss: 24.122699, training acc: 0.929413, training depends: 0.687950, valid loss: 26.009962, valid acc: 0.933347, valid depends: 0.651207\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.943, accuracy_depends=0.645, cost=22.4]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.84it/s, accuracy=0.939, accuracy_depends=0.647, cost=31.4]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.6395833492279\n",
      "epoch: 13, training loss: 23.656343, training acc: 0.932355, training depends: 0.686377, valid loss: 22.376074, valid acc: 0.938260, valid depends: 0.719997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.939, accuracy_depends=0.656, cost=22.8]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.84it/s, accuracy=0.937, accuracy_depends=0.633, cost=31.2]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.59862756729126\n",
      "epoch: 14, training loss: 21.349029, training acc: 0.936764, training depends: 0.725945, valid loss: 21.321049, valid acc: 0.944395, valid depends: 0.716793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.943, accuracy_depends=0.729, cost=20.7]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.80it/s, accuracy=0.948, accuracy_depends=0.6, cost=33.4]  \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.7840073108673\n",
      "epoch: 15, training loss: 19.482525, training acc: 0.941480, training depends: 0.754640, valid loss: 23.376568, valid acc: 0.942785, valid depends: 0.669307\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.24it/s, accuracy=0.939, accuracy_depends=0.786, cost=16.8]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.84it/s, accuracy=0.939, accuracy_depends=0.706, cost=27.5]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.6658065319061\n",
      "epoch: 16, training loss: 18.540819, training acc: 0.944208, training depends: 0.764462, valid loss: 19.479202, valid acc: 0.947233, valid depends: 0.741194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.95, accuracy_depends=0.79, cost=16.3]  \n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.83it/s, accuracy=0.957, accuracy_depends=0.769, cost=24.9]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.5469253063202\n",
      "epoch: 17, training loss: 18.119465, training acc: 0.945945, training depends: 0.767728, valid loss: 17.386115, valid acc: 0.949905, valid depends: 0.793675\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:49<00:00,  1.25it/s, accuracy=0.947, accuracy_depends=0.798, cost=15.5]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.962, accuracy_depends=0.715, cost=24.5]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.50203037261963\n",
      "epoch: 18, training loss: 16.895199, training acc: 0.948845, training depends: 0.786115, valid loss: 17.764167, valid acc: 0.949173, valid depends: 0.784863\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.25it/s, accuracy=0.954, accuracy_depends=0.813, cost=14.6]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.955, accuracy_depends=0.74, cost=24]   \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.8649597167969\n",
      "epoch: 19, training loss: 15.900881, training acc: 0.951792, training depends: 0.798421, valid loss: 16.822653, valid acc: 0.954231, valid depends: 0.788080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.969, accuracy_depends=0.87, cost=12.4] \n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.83it/s, accuracy=0.966, accuracy_depends=0.799, cost=21.7]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.54734802246094\n",
      "epoch: 20, training loss: 14.606359, training acc: 0.954795, training depends: 0.818364, valid loss: 15.647238, valid acc: 0.956492, valid depends: 0.801869\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.25it/s, accuracy=0.966, accuracy_depends=0.84, cost=10.6] \n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.82it/s, accuracy=0.964, accuracy_depends=0.83, cost=19.2] \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.83012104034424\n",
      "epoch: 21, training loss: 13.618865, training acc: 0.958872, training depends: 0.831980, valid loss: 13.762990, valid acc: 0.958590, valid depends: 0.839101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.25it/s, accuracy=0.969, accuracy_depends=0.79, cost=12.6] \n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.84it/s, accuracy=0.968, accuracy_depends=0.817, cost=17.6]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.7250463962555\n",
      "epoch: 22, training loss: 12.954482, training acc: 0.959575, training depends: 0.839193, valid loss: 13.363716, valid acc: 0.961949, valid depends: 0.827933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.969, accuracy_depends=0.847, cost=11.5]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.82it/s, accuracy=0.959, accuracy_depends=0.81, cost=18.1] \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.57196974754333\n",
      "epoch: 23, training loss: 12.346895, training acc: 0.962427, training depends: 0.846693, valid loss: 13.538606, valid acc: 0.961974, valid depends: 0.839913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.962, accuracy_depends=0.897, cost=9.42]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.79it/s, accuracy=0.964, accuracy_depends=0.81, cost=17.4] \n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.7886848449707\n",
      "epoch: 24, training loss: 11.754256, training acc: 0.964245, training depends: 0.852127, valid loss: 12.165086, valid acc: 0.964785, valid depends: 0.854131\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.25it/s, accuracy=0.977, accuracy_depends=0.901, cost=7.78]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.83it/s, accuracy=0.962, accuracy_depends=0.862, cost=14.2]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.55317759513855\n",
      "epoch: 25, training loss: 10.910226, training acc: 0.966214, training depends: 0.866050, valid loss: 11.051731, valid acc: 0.966341, valid depends: 0.869671\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:49<00:00,  1.26it/s, accuracy=0.985, accuracy_depends=0.893, cost=7.27]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.82it/s, accuracy=0.968, accuracy_depends=0.855, cost=15.1]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.4679582118988\n",
      "epoch: 26, training loss: 10.355563, training acc: 0.968222, training depends: 0.872719, valid loss: 10.513800, valid acc: 0.968562, valid depends: 0.875760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:49<00:00,  1.25it/s, accuracy=0.966, accuracy_depends=0.882, cost=8.58]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.977, accuracy_depends=0.846, cost=13.1]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.3526186943054\n",
      "epoch: 27, training loss: 9.721893, training acc: 0.970057, training depends: 0.882153, valid loss: 10.249874, valid acc: 0.970564, valid depends: 0.876219\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.25it/s, accuracy=0.973, accuracy_depends=0.87, cost=9.36] \n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.82it/s, accuracy=0.966, accuracy_depends=0.812, cost=15.4]\n",
      "train minibatch loop:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.7226359844208\n",
      "epoch: 28, training loss: 9.570963, training acc: 0.971573, training depends: 0.881705, valid loss: 12.513657, valid acc: 0.969140, valid depends: 0.831850\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 350/350 [04:50<00:00,  1.26it/s, accuracy=0.973, accuracy_depends=0.912, cost=7.45]\n",
      "test minibatch loop: 100%|██████████| 35/35 [00:12<00:00,  2.85it/s, accuracy=0.977, accuracy_depends=0.855, cost=13.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 302.54565358161926\n",
      "epoch: 29, training loss: 9.403749, training acc: 0.971946, training depends: 0.882790, valid loss: 9.385898, valid acc: 0.974280, valid depends: 0.889292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for e in range(30):\n",
    "    lasttime = time.time()\n",
    "    train_acc, train_loss, test_acc, test_loss, train_acc_depends, test_acc_depends = 0, 0, 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = train_X[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_char = train_char[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_y = train_Y[i : min(i + batch_size, train_X.shape[0])]\n",
    "        batch_depends = train_depends[i : min(i + batch_size, train_X.shape[0])]\n",
    "        acc_depends, acc, cost, _ = sess.run(\n",
    "            [model.accuracy_depends, model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.word_ids: batch_x,\n",
    "                model.char_ids: batch_char,\n",
    "                model.labels: batch_y,\n",
    "                model.depends: batch_depends\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        train_acc_depends += acc_depends\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc, accuracy_depends = acc_depends)\n",
    "        \n",
    "    pbar = tqdm(\n",
    "        range(0, len(test_X), batch_size), desc = 'test minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = test_X[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_char = test_char[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_depends = test_depends[i : min(i + batch_size, test_X.shape[0])]\n",
    "        acc_depends, acc, cost = sess.run(\n",
    "            [model.accuracy_depends, model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.word_ids: batch_x,\n",
    "                model.char_ids: batch_char,\n",
    "                model.labels: batch_y,\n",
    "                model.depends: batch_depends\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        test_acc_depends += acc_depends\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc, accuracy_depends = acc_depends)\n",
    "    \n",
    "    train_loss /= len(train_X) / batch_size\n",
    "    train_acc /= len(train_X) / batch_size\n",
    "    train_acc_depends /= len(train_X) / batch_size\n",
    "    test_loss /= len(test_X) / batch_size\n",
    "    test_acc /= len(test_X) / batch_size\n",
    "    test_acc_depends /= len(test_X) / batch_size\n",
    "\n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, training depends: %f, valid loss: %f, valid acc: %f, valid depends: %f\\n'\n",
    "        % (e, train_loss, train_acc, train_acc_depends, test_loss, test_acc, test_acc_depends)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, deps = sess.run([model.tags_seq, model.tags_seq_depends],\n",
    "        feed_dict={model.word_ids:batch_x[:1],\n",
    "                  model.char_ids:batch_char[:1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = seq[0]\n",
    "deps = deps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 10,  1,  4,  7, 21,  8, 12,  7, 20, 10, 18, 11, 15, 17, 21,\n",
       "       10, 21, 20, 10, 17, 15, 17, 21, 10, 21, 20, 15, 17,  7,  8, 15, 17,\n",
       "       21, 10, 21, 20, 10,  3,  1, 13,  3,  9, 14, 22,  7,  8, 21,  7,  7,\n",
       "       21, 20, 10], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[seq>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 10,  1,  4,  7, 21,  8, 12,  7, 20, 10, 18, 11, 15, 17, 21,\n",
       "       10, 21, 20, 10, 17, 15, 17, 21, 10, 21, 20, 15, 17,  7,  8, 15, 17,\n",
       "       21, 10, 21, 20, 10,  3,  1, 13,  3,  9, 14, 22,  7,  8, 21,  7,  7,\n",
       "       21, 20, 10], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y[0][seq>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  6,  6,  6,  1,  9,  9,  6,  9, 12,  9,  9, 15,  9, 17, 15, 21,\n",
       "       21, 21, 15, 23, 21, 25, 23, 29, 29, 29, 24, 31, 16, 35, 31, 37, 33,\n",
       "       39, 40, 40, 32,  7, 43, 47, 42, 43, 44, 47,  6, 49, 49, 49, 49, 53,\n",
       "       53, 53, 33], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps[seq>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  6,  6,  6,  1,  9,  9,  6,  9, 12,  9,  9, 15,  9, 17, 15, 21,\n",
       "       21, 21, 15, 23, 15, 25, 23, 29, 29, 29, 23, 31, 15, 33, 31, 35, 33,\n",
       "       39, 39, 39, 33,  6, 42, 47, 42, 42, 44, 47,  6, 49, 47, 49, 54, 54,\n",
       "       54, 49, 47], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_depends[0][seq>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'tolong tangkap gambar kami'\n",
    "\n",
    "def char_str_idx(corpus, dic, UNK = 0):\n",
    "    maxlen = max([len(i) for i in corpus])\n",
    "    X = np.zeros((len(corpus), maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i][:maxlen]):\n",
    "            val = dic[k] if k in dic else UNK\n",
    "            X[i, no] = val\n",
    "    return X\n",
    "\n",
    "def generate_char_seq(batch, UNK = 2):\n",
    "    maxlen_c = max([len(k) for k in batch])\n",
    "    x = [[len(i) for i in k] for k in batch]\n",
    "    maxlen = max([j for i in x for j in i])\n",
    "    temp = np.zeros((len(batch),maxlen_c,maxlen),dtype=np.int32)\n",
    "    for i in range(len(batch)):\n",
    "        for k in range(len(batch[i])):\n",
    "            for no, c in enumerate(batch[i][k][::-1]):\n",
    "                temp[i,k,-1-no] = char2idx.get(c, UNK)\n",
    "    return temp\n",
    "\n",
    "sequence = process_string(string)[:150]\n",
    "X_seq = char_str_idx([sequence], word2idx, 2)\n",
    "X_char_seq = generate_char_seq([sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, deps = sess.run([model.tags_seq, model.tags_seq_depends],\n",
    "        feed_dict={model.word_ids:X_seq,\n",
    "                  model.char_ids:X_char_seq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 2, 3]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tolong', 'tangkap', 'gambar', 'kami']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nsubj', 'root', 'compound', 'det']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2tag[i] for i in seq[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4, 13,  3]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = []\n",
    "for i in range(len(seq[0])):\n",
    "    string.append('%d\\t%s\\t_\\t_\\t_\\t_\\t%d\\t%s'%(i+1,sequence[i],deps[0,i],idx2tag[seq[0,i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\ttolong\\t_\\t_\\t_\\t_\\t3\\tnsubj',\n",
       " '2\\ttangkap\\t_\\t_\\t_\\t_\\t1\\troot',\n",
       " '3\\tgambar\\t_\\t_\\t_\\t_\\t3\\tcompound',\n",
       " '4\\tkami\\t_\\t_\\t_\\t_\\t4\\tdet']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Placeholder_2',\n",
       " 'Placeholder_3',\n",
       " 'Variable',\n",
       " 'Variable_1',\n",
       " 'bidirectional_rnn_char_0/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_0/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_char_0/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_0/bw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_char_1/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_1/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_char_1/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_char_1/bw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_0/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_0/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_0/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_0/bw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_1/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_1/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_1/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_1/bw/lstm_cell/bias',\n",
       " 'dense/kernel',\n",
       " 'dense/bias',\n",
       " 'Variable_2',\n",
       " 'bidirectional_rnn_word_10/fw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_10/fw/lstm_cell/bias',\n",
       " 'bidirectional_rnn_word_10/bw/lstm_cell/kernel',\n",
       " 'bidirectional_rnn_word_10/bw/lstm_cell/bias',\n",
       " 'dense_1/kernel',\n",
       " 'dense_1/bias',\n",
       " 'transitions',\n",
       " 'depends/transitions',\n",
       " 'logits',\n",
       " 'logits_depends']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'concat-dependency/model.ckpt')\n",
    "\n",
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'logits_depends' in n.name\n",
    "        or 'alphas' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'OptimizeLoss' not in n.name\n",
    "        and 'Global_Step' not in n.name\n",
    "        and 'Epoch_Step' not in n.name\n",
    "        and 'learning_rate' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('concat-dependency.json','w') as fopen:\n",
    "    fopen.write(json.dumps({'idx2tag':idx2tag,'idx2word':idx2word,\n",
    "           'word2idx':word2idx,'tag2idx':tag2idx,'char2idx':char2idx}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))\n",
    "        \n",
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from concat-dependency/model.ckpt\n",
      "INFO:tensorflow:Froze 29 variables.\n",
      "INFO:tensorflow:Converted 29 variables to const ops.\n",
      "2135 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('concat-dependency', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('concat-dependency/frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4 13  3]] [[3 1 3 4]]\n"
     ]
    }
   ],
   "source": [
    "word_ids = g.get_tensor_by_name('import/Placeholder:0')\n",
    "char_ids = g.get_tensor_by_name('import/Placeholder_1:0')\n",
    "tags_seq = g.get_tensor_by_name('import/logits:0')\n",
    "depends_seq = g.get_tensor_by_name('import/logits_depends:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)\n",
    "seq, deps = test_sess.run([tags_seq, depends_seq],\n",
    "            feed_dict = {\n",
    "                word_ids: X_seq,\n",
    "                char_ids: X_char_seq,\n",
    "            })\n",
    "\n",
    "print(seq,deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['import/logits_depends',\n",
       " 'import/cond_3/Merge',\n",
       " 'import/cond_3/ReverseSequence_1',\n",
       " 'import/cond_3/concat',\n",
       " 'import/cond_3/concat/axis',\n",
       " 'import/cond_3/Squeeze_2',\n",
       " 'import/cond_3/rnn_1/transpose_1',\n",
       " 'import/cond_3/rnn_1/concat_2',\n",
       " 'import/cond_3/rnn_1/concat_2/axis',\n",
       " 'import/cond_3/rnn_1/concat_2/values_0',\n",
       " 'import/cond_3/rnn_1/range_1',\n",
       " 'import/cond_3/rnn_1/range_1/delta',\n",
       " 'import/cond_3/rnn_1/range_1/start',\n",
       " 'import/cond_3/rnn_1/Rank_1',\n",
       " 'import/cond_3/rnn_1/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'import/cond_3/rnn_1/TensorArrayStack/range',\n",
       " 'import/cond_3/rnn_1/TensorArrayStack/range/delta',\n",
       " 'import/cond_3/rnn_1/TensorArrayStack/range/start',\n",
       " 'import/cond_3/rnn_1/TensorArrayStack/TensorArraySizeV3',\n",
       " 'import/cond_3/rnn_1/while/Exit_2',\n",
       " 'import/cond_3/rnn_1/while/NextIteration_3',\n",
       " 'import/cond_3/rnn_1/while/NextIteration_2',\n",
       " 'import/cond_3/rnn_1/while/NextIteration_1',\n",
       " 'import/cond_3/rnn_1/while/NextIteration',\n",
       " 'import/cond_3/rnn_1/while/add_1',\n",
       " 'import/cond_3/rnn_1/while/add_1/y',\n",
       " 'import/cond_3/rnn_1/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'import/cond_3/rnn_1/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'import/cond_3/rnn_1/while/Select_1',\n",
       " 'import/cond_3/rnn_1/while/Select',\n",
       " 'import/cond_3/rnn_1/while/Select/Enter',\n",
       " 'import/cond_3/rnn_1/while/ExpandDims',\n",
       " 'import/cond_3/rnn_1/while/ExpandDims/dim',\n",
       " 'import/cond_3/rnn_1/while/GatherNd',\n",
       " 'import/cond_3/rnn_1/while/stack',\n",
       " 'import/cond_3/rnn_1/while/range',\n",
       " 'import/cond_3/rnn_1/while/range/delta',\n",
       " 'import/cond_3/rnn_1/while/range/start',\n",
       " 'import/cond_3/rnn_1/while/strided_slice',\n",
       " 'import/cond_3/rnn_1/while/strided_slice/stack_2',\n",
       " 'import/cond_3/rnn_1/while/strided_slice/stack_1',\n",
       " 'import/cond_3/rnn_1/while/strided_slice/stack',\n",
       " 'import/cond_3/rnn_1/while/Shape',\n",
       " 'import/cond_3/rnn_1/while/Squeeze',\n",
       " 'import/cond_3/rnn_1/while/GreaterEqual',\n",
       " 'import/cond_3/rnn_1/while/GreaterEqual/Enter',\n",
       " 'import/cond_3/rnn_1/while/TensorArrayReadV3',\n",
       " 'import/cond_3/rnn_1/while/TensorArrayReadV3/Enter_1',\n",
       " 'import/cond_3/rnn_1/while/TensorArrayReadV3/Enter',\n",
       " 'import/cond_3/rnn_1/while/add',\n",
       " 'import/cond_3/rnn_1/while/add/y',\n",
       " 'import/cond_3/rnn_1/while/Identity_3',\n",
       " 'import/cond_3/rnn_1/while/Identity_2',\n",
       " 'import/cond_3/rnn_1/while/Identity_1',\n",
       " 'import/cond_3/rnn_1/while/Identity',\n",
       " 'import/cond_3/rnn_1/while/Switch_3',\n",
       " 'import/cond_3/rnn_1/while/Switch_2',\n",
       " 'import/cond_3/rnn_1/while/Switch_1',\n",
       " 'import/cond_3/rnn_1/while/Switch',\n",
       " 'import/cond_3/rnn_1/while/LoopCond',\n",
       " 'import/cond_3/rnn_1/while/LogicalAnd',\n",
       " 'import/cond_3/rnn_1/while/Less_1',\n",
       " 'import/cond_3/rnn_1/while/Less_1/Enter',\n",
       " 'import/cond_3/rnn_1/while/Less',\n",
       " 'import/cond_3/rnn_1/while/Less/Enter',\n",
       " 'import/cond_3/rnn_1/while/Merge_3',\n",
       " 'import/cond_3/rnn_1/while/Merge_2',\n",
       " 'import/cond_3/rnn_1/while/Merge_1',\n",
       " 'import/cond_3/rnn_1/while/Merge',\n",
       " 'import/cond_3/rnn_1/while/Enter_3',\n",
       " 'import/cond_3/rnn_1/while/Enter_2',\n",
       " 'import/cond_3/rnn_1/while/Enter_1',\n",
       " 'import/cond_3/rnn_1/while/Enter',\n",
       " 'import/cond_3/rnn_1/while/iteration_counter',\n",
       " 'import/cond_3/rnn_1/Minimum',\n",
       " 'import/cond_3/rnn_1/Maximum',\n",
       " 'import/cond_3/rnn_1/Maximum/x',\n",
       " 'import/cond_3/rnn_1/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'import/cond_3/rnn_1/TensorArrayUnstack/range',\n",
       " 'import/cond_3/rnn_1/TensorArrayUnstack/range/delta',\n",
       " 'import/cond_3/rnn_1/TensorArrayUnstack/range/start',\n",
       " 'import/cond_3/rnn_1/TensorArrayUnstack/strided_slice',\n",
       " 'import/cond_3/rnn_1/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'import/cond_3/rnn_1/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'import/cond_3/rnn_1/TensorArrayUnstack/strided_slice/stack',\n",
       " 'import/cond_3/rnn_1/TensorArrayUnstack/Shape',\n",
       " 'import/cond_3/rnn_1/TensorArray_1',\n",
       " 'import/cond_3/rnn_1/TensorArray',\n",
       " 'import/cond_3/rnn_1/time',\n",
       " 'import/cond_3/rnn_1/Max',\n",
       " 'import/cond_3/rnn_1/Const_3',\n",
       " 'import/cond_3/rnn_1/zeros',\n",
       " 'import/cond_3/rnn_1/zeros/Const',\n",
       " 'import/cond_3/rnn_1/concat_1',\n",
       " 'import/cond_3/rnn_1/concat_1/axis',\n",
       " 'import/cond_3/rnn_1/Const_1',\n",
       " 'import/cond_3/rnn_1/ExpandDims',\n",
       " 'import/cond_3/rnn_1/ExpandDims/dim',\n",
       " 'import/cond_3/rnn_1/strided_slice_2',\n",
       " 'import/cond_3/rnn_1/strided_slice_2/stack_2',\n",
       " 'import/cond_3/rnn_1/strided_slice_2/stack_1',\n",
       " 'import/cond_3/rnn_1/strided_slice_2/stack',\n",
       " 'import/cond_3/rnn_1/Shape_3',\n",
       " 'import/cond_3/rnn_1/strided_slice_1',\n",
       " 'import/cond_3/rnn_1/strided_slice_1/stack_2',\n",
       " 'import/cond_3/rnn_1/strided_slice_1/stack_1',\n",
       " 'import/cond_3/rnn_1/strided_slice_1/stack',\n",
       " 'import/cond_3/rnn_1/Shape_2',\n",
       " 'import/cond_3/rnn_1/CheckSeqLen',\n",
       " 'import/cond_3/rnn_1/Assert/Assert',\n",
       " 'import/cond_3/rnn_1/Assert/Assert/data_2',\n",
       " 'import/cond_3/rnn_1/Assert/Assert/data_0',\n",
       " 'import/cond_3/rnn_1/All',\n",
       " 'import/cond_3/rnn_1/Const',\n",
       " 'import/cond_3/rnn_1/Equal',\n",
       " 'import/cond_3/rnn_1/stack',\n",
       " 'import/cond_3/rnn_1/Shape_1',\n",
       " 'import/cond_3/rnn_1/strided_slice',\n",
       " 'import/cond_3/rnn_1/strided_slice/stack_2',\n",
       " 'import/cond_3/rnn_1/strided_slice/stack_1',\n",
       " 'import/cond_3/rnn_1/strided_slice/stack',\n",
       " 'import/cond_3/rnn_1/Shape',\n",
       " 'import/cond_3/rnn_1/sequence_length',\n",
       " 'import/cond_3/rnn_1/ToInt32',\n",
       " 'import/cond_3/rnn_1/transpose',\n",
       " 'import/cond_3/rnn_1/concat',\n",
       " 'import/cond_3/rnn_1/concat/axis',\n",
       " 'import/cond_3/rnn_1/concat/values_0',\n",
       " 'import/cond_3/rnn_1/range',\n",
       " 'import/cond_3/rnn_1/range/delta',\n",
       " 'import/cond_3/rnn_1/range/start',\n",
       " 'import/cond_3/rnn_1/Rank',\n",
       " 'import/cond_3/ExpandDims_2',\n",
       " 'import/cond_3/ExpandDims_2/dim',\n",
       " 'import/cond_3/Cast_1',\n",
       " 'import/cond_3/ArgMax_1',\n",
       " 'import/cond_3/ArgMax_1/dimension',\n",
       " 'import/cond_3/ReverseSequence',\n",
       " 'import/cond_3/rnn/transpose_1',\n",
       " 'import/cond_3/rnn/concat_2',\n",
       " 'import/cond_3/rnn/concat_2/axis',\n",
       " 'import/cond_3/rnn/concat_2/values_0',\n",
       " 'import/cond_3/rnn/range_1',\n",
       " 'import/cond_3/rnn/range_1/delta',\n",
       " 'import/cond_3/rnn/range_1/start',\n",
       " 'import/cond_3/rnn/Rank_1',\n",
       " 'import/cond_3/rnn/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'import/cond_3/rnn/TensorArrayStack/range',\n",
       " 'import/cond_3/rnn/TensorArrayStack/range/delta',\n",
       " 'import/cond_3/rnn/TensorArrayStack/range/start',\n",
       " 'import/cond_3/rnn/TensorArrayStack/TensorArraySizeV3',\n",
       " 'import/cond_3/rnn/while/Exit_3',\n",
       " 'import/cond_3/rnn/while/Exit_2',\n",
       " 'import/cond_3/rnn/while/NextIteration_3',\n",
       " 'import/cond_3/rnn/while/NextIteration_2',\n",
       " 'import/cond_3/rnn/while/NextIteration_1',\n",
       " 'import/cond_3/rnn/while/NextIteration',\n",
       " 'import/cond_3/rnn/while/add_3',\n",
       " 'import/cond_3/rnn/while/add_3/y',\n",
       " 'import/cond_3/rnn/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'import/cond_3/rnn/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'import/cond_3/rnn/while/Select_1',\n",
       " 'import/cond_3/rnn/while/Select',\n",
       " 'import/cond_3/rnn/while/Select/Enter',\n",
       " 'import/cond_3/rnn/while/Cast',\n",
       " 'import/cond_3/rnn/while/ArgMax',\n",
       " 'import/cond_3/rnn/while/ArgMax/dimension',\n",
       " 'import/cond_3/rnn/while/add_2',\n",
       " 'import/cond_3/rnn/while/Max',\n",
       " 'import/cond_3/rnn/while/Max/reduction_indices',\n",
       " 'import/cond_3/rnn/while/add_1',\n",
       " 'import/cond_3/rnn/while/add_1/Enter',\n",
       " 'import/cond_3/rnn/while/ExpandDims',\n",
       " 'import/cond_3/rnn/while/ExpandDims/dim',\n",
       " 'import/cond_3/rnn/while/GreaterEqual',\n",
       " 'import/cond_3/rnn/while/GreaterEqual/Enter',\n",
       " 'import/cond_3/rnn/while/TensorArrayReadV3',\n",
       " 'import/cond_3/rnn/while/TensorArrayReadV3/Enter_1',\n",
       " 'import/cond_3/rnn/while/TensorArrayReadV3/Enter',\n",
       " 'import/cond_3/rnn/while/add',\n",
       " 'import/cond_3/rnn/while/add/y',\n",
       " 'import/cond_3/rnn/while/Identity_3',\n",
       " 'import/cond_3/rnn/while/Identity_2',\n",
       " 'import/cond_3/rnn/while/Identity_1',\n",
       " 'import/cond_3/rnn/while/Identity',\n",
       " 'import/cond_3/rnn/while/Switch_3',\n",
       " 'import/cond_3/rnn/while/Switch_2',\n",
       " 'import/cond_3/rnn/while/Switch_1',\n",
       " 'import/cond_3/rnn/while/Switch',\n",
       " 'import/cond_3/rnn/while/LoopCond',\n",
       " 'import/cond_3/rnn/while/LogicalAnd',\n",
       " 'import/cond_3/rnn/while/Less_1',\n",
       " 'import/cond_3/rnn/while/Less_1/Enter',\n",
       " 'import/cond_3/rnn/while/Less',\n",
       " 'import/cond_3/rnn/while/Less/Enter',\n",
       " 'import/cond_3/rnn/while/Merge_3',\n",
       " 'import/cond_3/rnn/while/Merge_2',\n",
       " 'import/cond_3/rnn/while/Merge_1',\n",
       " 'import/cond_3/rnn/while/Merge',\n",
       " 'import/cond_3/rnn/while/Enter_3',\n",
       " 'import/cond_3/rnn/while/Enter_2',\n",
       " 'import/cond_3/rnn/while/Enter_1',\n",
       " 'import/cond_3/rnn/while/Enter',\n",
       " 'import/cond_3/rnn/while/iteration_counter',\n",
       " 'import/cond_3/rnn/Minimum',\n",
       " 'import/cond_3/rnn/Maximum',\n",
       " 'import/cond_3/rnn/Maximum/x',\n",
       " 'import/cond_3/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'import/cond_3/rnn/TensorArrayUnstack/range',\n",
       " 'import/cond_3/rnn/TensorArrayUnstack/range/delta',\n",
       " 'import/cond_3/rnn/TensorArrayUnstack/range/start',\n",
       " 'import/cond_3/rnn/TensorArrayUnstack/strided_slice',\n",
       " 'import/cond_3/rnn/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'import/cond_3/rnn/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'import/cond_3/rnn/TensorArrayUnstack/strided_slice/stack',\n",
       " 'import/cond_3/rnn/TensorArrayUnstack/Shape',\n",
       " 'import/cond_3/rnn/TensorArray_1',\n",
       " 'import/cond_3/rnn/TensorArray',\n",
       " 'import/cond_3/rnn/time',\n",
       " 'import/cond_3/rnn/Max',\n",
       " 'import/cond_3/rnn/Const_3',\n",
       " 'import/cond_3/rnn/zeros',\n",
       " 'import/cond_3/rnn/zeros/Const',\n",
       " 'import/cond_3/rnn/concat_1',\n",
       " 'import/cond_3/rnn/concat_1/axis',\n",
       " 'import/cond_3/rnn/Const_1',\n",
       " 'import/cond_3/rnn/ExpandDims',\n",
       " 'import/cond_3/rnn/ExpandDims/dim',\n",
       " 'import/cond_3/rnn/strided_slice_2',\n",
       " 'import/cond_3/rnn/strided_slice_2/stack_2',\n",
       " 'import/cond_3/rnn/strided_slice_2/stack_1',\n",
       " 'import/cond_3/rnn/strided_slice_2/stack',\n",
       " 'import/cond_3/rnn/Shape_3',\n",
       " 'import/cond_3/rnn/strided_slice_1',\n",
       " 'import/cond_3/rnn/strided_slice_1/stack_2',\n",
       " 'import/cond_3/rnn/strided_slice_1/stack_1',\n",
       " 'import/cond_3/rnn/strided_slice_1/stack',\n",
       " 'import/cond_3/rnn/Shape_2',\n",
       " 'import/cond_3/rnn/CheckSeqLen',\n",
       " 'import/cond_3/rnn/Assert/Assert',\n",
       " 'import/cond_3/rnn/Assert/Assert/data_2',\n",
       " 'import/cond_3/rnn/Assert/Assert/data_0',\n",
       " 'import/cond_3/rnn/All',\n",
       " 'import/cond_3/rnn/Const',\n",
       " 'import/cond_3/rnn/Equal',\n",
       " 'import/cond_3/rnn/stack',\n",
       " 'import/cond_3/rnn/Shape_1',\n",
       " 'import/cond_3/rnn/strided_slice',\n",
       " 'import/cond_3/rnn/strided_slice/stack_2',\n",
       " 'import/cond_3/rnn/strided_slice/stack_1',\n",
       " 'import/cond_3/rnn/strided_slice/stack',\n",
       " 'import/cond_3/rnn/Shape',\n",
       " 'import/cond_3/rnn/sequence_length',\n",
       " 'import/cond_3/rnn/ToInt32',\n",
       " 'import/cond_3/rnn/transpose',\n",
       " 'import/cond_3/rnn/concat',\n",
       " 'import/cond_3/rnn/concat/axis',\n",
       " 'import/cond_3/rnn/concat/values_0',\n",
       " 'import/cond_3/rnn/range',\n",
       " 'import/cond_3/rnn/range/delta',\n",
       " 'import/cond_3/rnn/range/start',\n",
       " 'import/cond_3/rnn/Rank',\n",
       " 'import/cond_3/Maximum',\n",
       " 'import/cond_3/sub',\n",
       " 'import/cond_3/sub/Switch',\n",
       " 'import/cond_3/sub/y',\n",
       " 'import/cond_3/Const',\n",
       " 'import/cond_3/Slice_1',\n",
       " 'import/cond_3/Slice_1/size',\n",
       " 'import/cond_3/Slice_1/begin',\n",
       " 'import/cond_3/Squeeze_1',\n",
       " 'import/cond_3/Slice',\n",
       " 'import/cond_3/Slice/Switch',\n",
       " 'import/cond_3/Slice/size',\n",
       " 'import/cond_3/Slice/begin',\n",
       " 'import/cond_3/ExpandDims_1',\n",
       " 'import/cond_3/ExpandDims_1/Switch',\n",
       " 'import/cond_3/ExpandDims_1/dim',\n",
       " 'import/cond_3/Cast',\n",
       " 'import/cond_3/ExpandDims',\n",
       " 'import/cond_3/ExpandDims/dim',\n",
       " 'import/cond_3/ArgMax',\n",
       " 'import/cond_3/ArgMax/dimension',\n",
       " 'import/cond_3/Squeeze',\n",
       " 'import/cond_3/Squeeze/Switch',\n",
       " 'import/cond_3/pred_id',\n",
       " 'import/cond_3/switch_f',\n",
       " 'import/cond_3/switch_t',\n",
       " 'import/cond_3/Switch',\n",
       " 'import/Equal_3',\n",
       " 'import/Equal_3/y',\n",
       " 'import/strided_slice_10',\n",
       " 'import/strided_slice_10/stack_2',\n",
       " 'import/strided_slice_10/stack_1',\n",
       " 'import/strided_slice_10/stack',\n",
       " 'import/Shape_5',\n",
       " 'import/logits',\n",
       " 'import/cond_2/Merge',\n",
       " 'import/cond_2/ReverseSequence_1',\n",
       " 'import/cond_2/concat',\n",
       " 'import/cond_2/concat/axis',\n",
       " 'import/cond_2/Squeeze_2',\n",
       " 'import/cond_2/rnn_1/transpose_1',\n",
       " 'import/cond_2/rnn_1/concat_2',\n",
       " 'import/cond_2/rnn_1/concat_2/axis',\n",
       " 'import/cond_2/rnn_1/concat_2/values_0',\n",
       " 'import/cond_2/rnn_1/range_1',\n",
       " 'import/cond_2/rnn_1/range_1/delta',\n",
       " 'import/cond_2/rnn_1/range_1/start',\n",
       " 'import/cond_2/rnn_1/Rank_1',\n",
       " 'import/cond_2/rnn_1/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'import/cond_2/rnn_1/TensorArrayStack/range',\n",
       " 'import/cond_2/rnn_1/TensorArrayStack/range/delta',\n",
       " 'import/cond_2/rnn_1/TensorArrayStack/range/start',\n",
       " 'import/cond_2/rnn_1/TensorArrayStack/TensorArraySizeV3',\n",
       " 'import/cond_2/rnn_1/while/Exit_2',\n",
       " 'import/cond_2/rnn_1/while/NextIteration_3',\n",
       " 'import/cond_2/rnn_1/while/NextIteration_2',\n",
       " 'import/cond_2/rnn_1/while/NextIteration_1',\n",
       " 'import/cond_2/rnn_1/while/NextIteration',\n",
       " 'import/cond_2/rnn_1/while/add_1',\n",
       " 'import/cond_2/rnn_1/while/add_1/y',\n",
       " 'import/cond_2/rnn_1/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'import/cond_2/rnn_1/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'import/cond_2/rnn_1/while/Select_1',\n",
       " 'import/cond_2/rnn_1/while/Select',\n",
       " 'import/cond_2/rnn_1/while/Select/Enter',\n",
       " 'import/cond_2/rnn_1/while/ExpandDims',\n",
       " 'import/cond_2/rnn_1/while/ExpandDims/dim',\n",
       " 'import/cond_2/rnn_1/while/GatherNd',\n",
       " 'import/cond_2/rnn_1/while/stack',\n",
       " 'import/cond_2/rnn_1/while/range',\n",
       " 'import/cond_2/rnn_1/while/range/delta',\n",
       " 'import/cond_2/rnn_1/while/range/start',\n",
       " 'import/cond_2/rnn_1/while/strided_slice',\n",
       " 'import/cond_2/rnn_1/while/strided_slice/stack_2',\n",
       " 'import/cond_2/rnn_1/while/strided_slice/stack_1',\n",
       " 'import/cond_2/rnn_1/while/strided_slice/stack',\n",
       " 'import/cond_2/rnn_1/while/Shape',\n",
       " 'import/cond_2/rnn_1/while/Squeeze',\n",
       " 'import/cond_2/rnn_1/while/GreaterEqual',\n",
       " 'import/cond_2/rnn_1/while/GreaterEqual/Enter',\n",
       " 'import/cond_2/rnn_1/while/TensorArrayReadV3',\n",
       " 'import/cond_2/rnn_1/while/TensorArrayReadV3/Enter_1',\n",
       " 'import/cond_2/rnn_1/while/TensorArrayReadV3/Enter',\n",
       " 'import/cond_2/rnn_1/while/add',\n",
       " 'import/cond_2/rnn_1/while/add/y',\n",
       " 'import/cond_2/rnn_1/while/Identity_3',\n",
       " 'import/cond_2/rnn_1/while/Identity_2',\n",
       " 'import/cond_2/rnn_1/while/Identity_1',\n",
       " 'import/cond_2/rnn_1/while/Identity',\n",
       " 'import/cond_2/rnn_1/while/Switch_3',\n",
       " 'import/cond_2/rnn_1/while/Switch_2',\n",
       " 'import/cond_2/rnn_1/while/Switch_1',\n",
       " 'import/cond_2/rnn_1/while/Switch',\n",
       " 'import/cond_2/rnn_1/while/LoopCond',\n",
       " 'import/cond_2/rnn_1/while/LogicalAnd',\n",
       " 'import/cond_2/rnn_1/while/Less_1',\n",
       " 'import/cond_2/rnn_1/while/Less_1/Enter',\n",
       " 'import/cond_2/rnn_1/while/Less',\n",
       " 'import/cond_2/rnn_1/while/Less/Enter',\n",
       " 'import/cond_2/rnn_1/while/Merge_3',\n",
       " 'import/cond_2/rnn_1/while/Merge_2',\n",
       " 'import/cond_2/rnn_1/while/Merge_1',\n",
       " 'import/cond_2/rnn_1/while/Merge',\n",
       " 'import/cond_2/rnn_1/while/Enter_3',\n",
       " 'import/cond_2/rnn_1/while/Enter_2',\n",
       " 'import/cond_2/rnn_1/while/Enter_1',\n",
       " 'import/cond_2/rnn_1/while/Enter',\n",
       " 'import/cond_2/rnn_1/while/iteration_counter',\n",
       " 'import/cond_2/rnn_1/Minimum',\n",
       " 'import/cond_2/rnn_1/Maximum',\n",
       " 'import/cond_2/rnn_1/Maximum/x',\n",
       " 'import/cond_2/rnn_1/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'import/cond_2/rnn_1/TensorArrayUnstack/range',\n",
       " 'import/cond_2/rnn_1/TensorArrayUnstack/range/delta',\n",
       " 'import/cond_2/rnn_1/TensorArrayUnstack/range/start',\n",
       " 'import/cond_2/rnn_1/TensorArrayUnstack/strided_slice',\n",
       " 'import/cond_2/rnn_1/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'import/cond_2/rnn_1/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'import/cond_2/rnn_1/TensorArrayUnstack/strided_slice/stack',\n",
       " 'import/cond_2/rnn_1/TensorArrayUnstack/Shape',\n",
       " 'import/cond_2/rnn_1/TensorArray_1',\n",
       " 'import/cond_2/rnn_1/TensorArray',\n",
       " 'import/cond_2/rnn_1/time',\n",
       " 'import/cond_2/rnn_1/Max',\n",
       " 'import/cond_2/rnn_1/Const_3',\n",
       " 'import/cond_2/rnn_1/zeros',\n",
       " 'import/cond_2/rnn_1/zeros/Const',\n",
       " 'import/cond_2/rnn_1/concat_1',\n",
       " 'import/cond_2/rnn_1/concat_1/axis',\n",
       " 'import/cond_2/rnn_1/Const_1',\n",
       " 'import/cond_2/rnn_1/ExpandDims',\n",
       " 'import/cond_2/rnn_1/ExpandDims/dim',\n",
       " 'import/cond_2/rnn_1/strided_slice_2',\n",
       " 'import/cond_2/rnn_1/strided_slice_2/stack_2',\n",
       " 'import/cond_2/rnn_1/strided_slice_2/stack_1',\n",
       " 'import/cond_2/rnn_1/strided_slice_2/stack',\n",
       " 'import/cond_2/rnn_1/Shape_3',\n",
       " 'import/cond_2/rnn_1/strided_slice_1',\n",
       " 'import/cond_2/rnn_1/strided_slice_1/stack_2',\n",
       " 'import/cond_2/rnn_1/strided_slice_1/stack_1',\n",
       " 'import/cond_2/rnn_1/strided_slice_1/stack',\n",
       " 'import/cond_2/rnn_1/Shape_2',\n",
       " 'import/cond_2/rnn_1/CheckSeqLen',\n",
       " 'import/cond_2/rnn_1/Assert/Assert',\n",
       " 'import/cond_2/rnn_1/Assert/Assert/data_2',\n",
       " 'import/cond_2/rnn_1/Assert/Assert/data_0',\n",
       " 'import/cond_2/rnn_1/All',\n",
       " 'import/cond_2/rnn_1/Const',\n",
       " 'import/cond_2/rnn_1/Equal',\n",
       " 'import/cond_2/rnn_1/stack',\n",
       " 'import/cond_2/rnn_1/Shape_1',\n",
       " 'import/cond_2/rnn_1/strided_slice',\n",
       " 'import/cond_2/rnn_1/strided_slice/stack_2',\n",
       " 'import/cond_2/rnn_1/strided_slice/stack_1',\n",
       " 'import/cond_2/rnn_1/strided_slice/stack',\n",
       " 'import/cond_2/rnn_1/Shape',\n",
       " 'import/cond_2/rnn_1/sequence_length',\n",
       " 'import/cond_2/rnn_1/ToInt32',\n",
       " 'import/cond_2/rnn_1/transpose',\n",
       " 'import/cond_2/rnn_1/concat',\n",
       " 'import/cond_2/rnn_1/concat/axis',\n",
       " 'import/cond_2/rnn_1/concat/values_0',\n",
       " 'import/cond_2/rnn_1/range',\n",
       " 'import/cond_2/rnn_1/range/delta',\n",
       " 'import/cond_2/rnn_1/range/start',\n",
       " 'import/cond_2/rnn_1/Rank',\n",
       " 'import/cond_2/ExpandDims_2',\n",
       " 'import/cond_2/ExpandDims_2/dim',\n",
       " 'import/cond_2/Cast_1',\n",
       " 'import/cond_2/ArgMax_1',\n",
       " 'import/cond_2/ArgMax_1/dimension',\n",
       " 'import/cond_2/ReverseSequence',\n",
       " 'import/cond_2/rnn/transpose_1',\n",
       " 'import/cond_2/rnn/concat_2',\n",
       " 'import/cond_2/rnn/concat_2/axis',\n",
       " 'import/cond_2/rnn/concat_2/values_0',\n",
       " 'import/cond_2/rnn/range_1',\n",
       " 'import/cond_2/rnn/range_1/delta',\n",
       " 'import/cond_2/rnn/range_1/start',\n",
       " 'import/cond_2/rnn/Rank_1',\n",
       " 'import/cond_2/rnn/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'import/cond_2/rnn/TensorArrayStack/range',\n",
       " 'import/cond_2/rnn/TensorArrayStack/range/delta',\n",
       " 'import/cond_2/rnn/TensorArrayStack/range/start',\n",
       " 'import/cond_2/rnn/TensorArrayStack/TensorArraySizeV3',\n",
       " 'import/cond_2/rnn/while/Exit_3',\n",
       " 'import/cond_2/rnn/while/Exit_2',\n",
       " 'import/cond_2/rnn/while/NextIteration_3',\n",
       " 'import/cond_2/rnn/while/NextIteration_2',\n",
       " 'import/cond_2/rnn/while/NextIteration_1',\n",
       " 'import/cond_2/rnn/while/NextIteration',\n",
       " 'import/cond_2/rnn/while/add_3',\n",
       " 'import/cond_2/rnn/while/add_3/y',\n",
       " 'import/cond_2/rnn/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'import/cond_2/rnn/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'import/cond_2/rnn/while/Select_1',\n",
       " 'import/cond_2/rnn/while/Select',\n",
       " 'import/cond_2/rnn/while/Select/Enter',\n",
       " 'import/cond_2/rnn/while/Cast',\n",
       " 'import/cond_2/rnn/while/ArgMax',\n",
       " 'import/cond_2/rnn/while/ArgMax/dimension',\n",
       " 'import/cond_2/rnn/while/add_2',\n",
       " 'import/cond_2/rnn/while/Max',\n",
       " 'import/cond_2/rnn/while/Max/reduction_indices',\n",
       " 'import/cond_2/rnn/while/add_1',\n",
       " 'import/cond_2/rnn/while/add_1/Enter',\n",
       " 'import/cond_2/rnn/while/ExpandDims',\n",
       " 'import/cond_2/rnn/while/ExpandDims/dim',\n",
       " 'import/cond_2/rnn/while/GreaterEqual',\n",
       " 'import/cond_2/rnn/while/GreaterEqual/Enter',\n",
       " 'import/cond_2/rnn/while/TensorArrayReadV3',\n",
       " 'import/cond_2/rnn/while/TensorArrayReadV3/Enter_1',\n",
       " 'import/cond_2/rnn/while/TensorArrayReadV3/Enter',\n",
       " 'import/cond_2/rnn/while/add',\n",
       " 'import/cond_2/rnn/while/add/y',\n",
       " 'import/cond_2/rnn/while/Identity_3',\n",
       " 'import/cond_2/rnn/while/Identity_2',\n",
       " 'import/cond_2/rnn/while/Identity_1',\n",
       " 'import/cond_2/rnn/while/Identity',\n",
       " 'import/cond_2/rnn/while/Switch_3',\n",
       " 'import/cond_2/rnn/while/Switch_2',\n",
       " 'import/cond_2/rnn/while/Switch_1',\n",
       " 'import/cond_2/rnn/while/Switch',\n",
       " 'import/cond_2/rnn/while/LoopCond',\n",
       " 'import/cond_2/rnn/while/LogicalAnd',\n",
       " 'import/cond_2/rnn/while/Less_1',\n",
       " 'import/cond_2/rnn/while/Less_1/Enter',\n",
       " 'import/cond_2/rnn/while/Less',\n",
       " 'import/cond_2/rnn/while/Less/Enter',\n",
       " 'import/cond_2/rnn/while/Merge_3',\n",
       " 'import/cond_2/rnn/while/Merge_2',\n",
       " 'import/cond_2/rnn/while/Merge_1',\n",
       " 'import/cond_2/rnn/while/Merge',\n",
       " 'import/cond_2/rnn/while/Enter_3',\n",
       " 'import/cond_2/rnn/while/Enter_2',\n",
       " 'import/cond_2/rnn/while/Enter_1',\n",
       " 'import/cond_2/rnn/while/Enter',\n",
       " 'import/cond_2/rnn/while/iteration_counter',\n",
       " 'import/cond_2/rnn/Minimum',\n",
       " 'import/cond_2/rnn/Maximum',\n",
       " 'import/cond_2/rnn/Maximum/x',\n",
       " 'import/cond_2/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'import/cond_2/rnn/TensorArrayUnstack/range',\n",
       " 'import/cond_2/rnn/TensorArrayUnstack/range/delta',\n",
       " 'import/cond_2/rnn/TensorArrayUnstack/range/start',\n",
       " 'import/cond_2/rnn/TensorArrayUnstack/strided_slice',\n",
       " 'import/cond_2/rnn/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'import/cond_2/rnn/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'import/cond_2/rnn/TensorArrayUnstack/strided_slice/stack',\n",
       " 'import/cond_2/rnn/TensorArrayUnstack/Shape',\n",
       " 'import/cond_2/rnn/TensorArray_1',\n",
       " 'import/cond_2/rnn/TensorArray',\n",
       " 'import/cond_2/rnn/time',\n",
       " 'import/cond_2/rnn/Max',\n",
       " 'import/cond_2/rnn/Const_3',\n",
       " 'import/cond_2/rnn/zeros',\n",
       " 'import/cond_2/rnn/zeros/Const',\n",
       " 'import/cond_2/rnn/concat_1',\n",
       " 'import/cond_2/rnn/concat_1/axis',\n",
       " 'import/cond_2/rnn/Const_1',\n",
       " 'import/cond_2/rnn/ExpandDims',\n",
       " 'import/cond_2/rnn/ExpandDims/dim',\n",
       " 'import/cond_2/rnn/strided_slice_2',\n",
       " 'import/cond_2/rnn/strided_slice_2/stack_2',\n",
       " 'import/cond_2/rnn/strided_slice_2/stack_1',\n",
       " 'import/cond_2/rnn/strided_slice_2/stack',\n",
       " 'import/cond_2/rnn/Shape_3',\n",
       " 'import/cond_2/rnn/strided_slice_1',\n",
       " 'import/cond_2/rnn/strided_slice_1/stack_2',\n",
       " 'import/cond_2/rnn/strided_slice_1/stack_1',\n",
       " 'import/cond_2/rnn/strided_slice_1/stack',\n",
       " 'import/cond_2/rnn/Shape_2',\n",
       " 'import/cond_2/rnn/CheckSeqLen',\n",
       " 'import/cond_2/rnn/Assert/Assert',\n",
       " 'import/cond_2/rnn/Assert/Assert/data_2',\n",
       " 'import/cond_2/rnn/Assert/Assert/data_0',\n",
       " 'import/cond_2/rnn/All',\n",
       " 'import/cond_2/rnn/Const',\n",
       " 'import/cond_2/rnn/Equal',\n",
       " 'import/cond_2/rnn/stack',\n",
       " 'import/cond_2/rnn/Shape_1',\n",
       " 'import/cond_2/rnn/strided_slice',\n",
       " 'import/cond_2/rnn/strided_slice/stack_2',\n",
       " 'import/cond_2/rnn/strided_slice/stack_1',\n",
       " 'import/cond_2/rnn/strided_slice/stack',\n",
       " 'import/cond_2/rnn/Shape',\n",
       " 'import/cond_2/rnn/sequence_length',\n",
       " 'import/cond_2/rnn/ToInt32',\n",
       " 'import/cond_2/rnn/transpose',\n",
       " 'import/cond_2/rnn/concat',\n",
       " 'import/cond_2/rnn/concat/axis',\n",
       " 'import/cond_2/rnn/concat/values_0',\n",
       " 'import/cond_2/rnn/range',\n",
       " 'import/cond_2/rnn/range/delta',\n",
       " 'import/cond_2/rnn/range/start',\n",
       " 'import/cond_2/rnn/Rank',\n",
       " 'import/cond_2/Maximum',\n",
       " 'import/cond_2/sub',\n",
       " 'import/cond_2/sub/Switch',\n",
       " 'import/cond_2/sub/y',\n",
       " 'import/cond_2/Const',\n",
       " 'import/cond_2/Slice_1',\n",
       " 'import/cond_2/Slice_1/size',\n",
       " 'import/cond_2/Slice_1/begin',\n",
       " 'import/cond_2/Squeeze_1',\n",
       " 'import/cond_2/Slice',\n",
       " 'import/cond_2/Slice/Switch',\n",
       " 'import/cond_2/Slice/size',\n",
       " 'import/cond_2/Slice/begin',\n",
       " 'import/cond_2/ExpandDims_1',\n",
       " 'import/cond_2/ExpandDims_1/Switch',\n",
       " 'import/cond_2/ExpandDims_1/dim',\n",
       " 'import/cond_2/Cast',\n",
       " 'import/cond_2/ExpandDims',\n",
       " 'import/cond_2/ExpandDims/dim',\n",
       " 'import/cond_2/ArgMax',\n",
       " 'import/cond_2/ArgMax/dimension',\n",
       " 'import/cond_2/Squeeze',\n",
       " 'import/cond_2/Squeeze/Switch',\n",
       " 'import/cond_2/pred_id',\n",
       " 'import/cond_2/switch_f',\n",
       " 'import/cond_2/switch_t',\n",
       " 'import/cond_2/Switch',\n",
       " 'import/Equal_2',\n",
       " 'import/Equal_2/y',\n",
       " 'import/strided_slice_9',\n",
       " 'import/strided_slice_9/stack_2',\n",
       " 'import/strided_slice_9/stack_1',\n",
       " 'import/strided_slice_9/stack',\n",
       " 'import/Shape_4',\n",
       " 'import/depends/transitions/read',\n",
       " 'import/depends/transitions',\n",
       " 'import/transitions/read',\n",
       " 'import/transitions',\n",
       " 'import/Mul_2',\n",
       " 'import/dense_1/BiasAdd',\n",
       " 'import/dense_1/Tensordot',\n",
       " 'import/dense_1/Tensordot/concat_1',\n",
       " 'import/dense_1/Tensordot/concat_1/axis',\n",
       " 'import/dense_1/Tensordot/Const_2',\n",
       " 'import/dense_1/Tensordot/MatMul',\n",
       " 'import/dense_1/Tensordot/Reshape_1',\n",
       " 'import/dense_1/Tensordot/Reshape_1/shape',\n",
       " 'import/dense_1/Tensordot/transpose_1',\n",
       " 'import/dense_1/Tensordot/transpose_1/perm',\n",
       " 'import/dense_1/Tensordot/Reshape',\n",
       " 'import/dense_1/Tensordot/transpose',\n",
       " 'import/dense_1/Tensordot/stack',\n",
       " 'import/dense_1/Tensordot/concat',\n",
       " 'import/dense_1/Tensordot/concat/axis',\n",
       " 'import/dense_1/Tensordot/Prod_1',\n",
       " 'import/dense_1/Tensordot/Const_1',\n",
       " 'import/dense_1/Tensordot/Prod',\n",
       " 'import/dense_1/Tensordot/Const',\n",
       " 'import/dense_1/Tensordot/GatherV2_1',\n",
       " 'import/dense_1/Tensordot/GatherV2_1/axis',\n",
       " 'import/dense_1/Tensordot/GatherV2',\n",
       " 'import/dense_1/Tensordot/GatherV2/axis',\n",
       " 'import/dense_1/Tensordot/Shape',\n",
       " 'import/dense_1/Tensordot/free',\n",
       " 'import/dense_1/Tensordot/axes',\n",
       " 'import/dense_1/bias/read',\n",
       " 'import/dense_1/bias',\n",
       " 'import/dense_1/kernel/read',\n",
       " 'import/dense_1/kernel',\n",
       " 'import/concat_5',\n",
       " 'import/concat_5/axis',\n",
       " 'import/mul_1',\n",
       " 'import/mul_1/y',\n",
       " 'import/Tile',\n",
       " 'import/Tile/multiples',\n",
       " 'import/Tile/multiples/2',\n",
       " 'import/Tile/multiples/0',\n",
       " 'import/ExpandDims',\n",
       " 'import/ExpandDims/dim',\n",
       " 'import/Cast',\n",
       " 'import/SequenceMask/Less',\n",
       " 'import/SequenceMask/Cast',\n",
       " 'import/SequenceMask/ExpandDims',\n",
       " 'import/SequenceMask/ExpandDims/dim',\n",
       " 'import/SequenceMask/Range',\n",
       " 'import/SequenceMask/Const_2',\n",
       " 'import/SequenceMask/Const_1',\n",
       " 'import/SequenceMask/Const',\n",
       " 'import/add',\n",
       " 'import/add/y',\n",
       " 'import/ReverseV2_4',\n",
       " 'import/ReverseV2_4/axis',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/transpose_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/concat_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/concat_2/axis',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/concat_2/values_0',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/range_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/range_1/delta',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/range_1/start',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/Rank_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayStack/range',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayStack/range/delta',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayStack/range/start',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Exit_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/NextIteration_4',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/NextIteration_3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/NextIteration_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/NextIteration_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/NextIteration',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/add_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/add_1/y',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/mul',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/div',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/Floor',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/add',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/random_uniform',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/random_uniform/mul',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/random_uniform/sub',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/random_uniform/RandomUniform',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/random_uniform/max',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/random_uniform/min',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/Shape',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/dropout/keep_prob',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/mul_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/Tanh_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/Sigmoid_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/add_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/mul_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/Tanh',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/Sigmoid_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/mul',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/Sigmoid',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/add',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/add/y',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/split',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/split/split_dim',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/BiasAdd',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/MatMul',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/MatMul/Enter',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/concat',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/lstm_cell/concat/axis',\n",
       " 'import/bidirectional_rnn_word_10/bw/lstm_cell/bias/read',\n",
       " 'import/bidirectional_rnn_word_10/bw/lstm_cell/bias',\n",
       " 'import/bidirectional_rnn_word_10/bw/lstm_cell/kernel/read',\n",
       " 'import/bidirectional_rnn_word_10/bw/lstm_cell/kernel',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/TensorArrayReadV3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/TensorArrayReadV3/Enter_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/TensorArrayReadV3/Enter',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/add',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/add/y',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Identity_4',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Identity_3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Identity_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Identity_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Identity',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Switch_4',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Switch_3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Switch_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Switch_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Switch',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/LoopCond',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/LogicalAnd',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Less_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Less_1/Enter',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Less',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Less/Enter',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Merge_4',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Merge_3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Merge_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Merge_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Merge',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Enter_4',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Enter_3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Enter_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Enter_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/Enter',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/while/iteration_counter',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/Minimum',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/Maximum',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/Maximum/x',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayUnstack/range',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayUnstack/range/delta',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayUnstack/range/start',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayUnstack/strided_slice',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArrayUnstack/Shape',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArray_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/TensorArray',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/time',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/strided_slice_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/strided_slice_1/stack_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/strided_slice_1/stack_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/strided_slice_1/stack',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/Shape_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/strided_slice',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/strided_slice/stack_2',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/strided_slice/stack_1',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/strided_slice/stack',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/Shape',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/transpose',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/concat',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/concat/axis',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/concat/values_0',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/range',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/range/delta',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/range/start',\n",
       " 'import/bidirectional_rnn_word_10/bw/bw/Rank',\n",
       " 'import/bidirectional_rnn_word_10/bw/ReverseV2',\n",
       " 'import/bidirectional_rnn_word_10/bw/ReverseV2/axis',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/transpose_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/concat_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/concat_2/axis',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/concat_2/values_0',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/range_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/range_1/delta',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/range_1/start',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/Rank_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayStack/range',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayStack/range/delta',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayStack/range/start',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Exit_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/NextIteration_4',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/NextIteration_3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/NextIteration_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/NextIteration_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/NextIteration',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/add_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/add_1/y',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/mul',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/div',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/Floor',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/add',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/random_uniform',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/random_uniform/mul',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/random_uniform/sub',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/random_uniform/RandomUniform',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/random_uniform/max',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/random_uniform/min',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/Shape',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/dropout/keep_prob',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/mul_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/Tanh_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/Sigmoid_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/add_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/mul_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/Tanh',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/Sigmoid_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/mul',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/Sigmoid',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/add',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/add/y',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/split',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/split/split_dim',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/BiasAdd',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/MatMul',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/MatMul/Enter',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/concat',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/lstm_cell/concat/axis',\n",
       " 'import/bidirectional_rnn_word_10/fw/lstm_cell/bias/read',\n",
       " 'import/bidirectional_rnn_word_10/fw/lstm_cell/bias',\n",
       " 'import/bidirectional_rnn_word_10/fw/lstm_cell/kernel/read',\n",
       " 'import/bidirectional_rnn_word_10/fw/lstm_cell/kernel',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/TensorArrayReadV3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/TensorArrayReadV3/Enter_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/TensorArrayReadV3/Enter',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/add',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/add/y',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Identity_4',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Identity_3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Identity_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Identity_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Identity',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Switch_4',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Switch_3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Switch_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Switch_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Switch',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/LoopCond',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/LogicalAnd',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Less_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Less_1/Enter',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Less',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Less/Enter',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Merge_4',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Merge_3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Merge_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Merge_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Merge',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Enter_4',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Enter_3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Enter_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Enter_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/Enter',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/while/iteration_counter',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/Minimum',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/Maximum',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/Maximum/x',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayUnstack/range',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayUnstack/range/delta',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayUnstack/range/start',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayUnstack/strided_slice',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArrayUnstack/Shape',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArray_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/TensorArray',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/time',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/strided_slice_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/strided_slice_1/stack_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/strided_slice_1/stack_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/strided_slice_1/stack',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/Shape_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/strided_slice',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/strided_slice/stack_2',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/strided_slice/stack_1',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/strided_slice/stack',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/Shape',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/transpose',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/concat',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/concat/axis',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/concat/values_0',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/range',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/range/delta',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/range/start',\n",
       " 'import/bidirectional_rnn_word_10/fw/fw/Rank',\n",
       " 'import/Variable_2',\n",
       " 'import/dense/BiasAdd',\n",
       " 'import/dense/Tensordot',\n",
       " 'import/dense/Tensordot/concat_1',\n",
       " 'import/dense/Tensordot/concat_1/axis',\n",
       " 'import/dense/Tensordot/Const_2',\n",
       " 'import/dense/Tensordot/MatMul',\n",
       " 'import/dense/Tensordot/Reshape_1',\n",
       " 'import/dense/Tensordot/Reshape_1/shape',\n",
       " 'import/dense/Tensordot/transpose_1',\n",
       " 'import/dense/Tensordot/transpose_1/perm',\n",
       " 'import/dense/Tensordot/Reshape',\n",
       " 'import/dense/Tensordot/transpose',\n",
       " 'import/dense/Tensordot/stack',\n",
       " 'import/dense/Tensordot/concat',\n",
       " 'import/dense/Tensordot/concat/axis',\n",
       " 'import/dense/Tensordot/Prod_1',\n",
       " 'import/dense/Tensordot/Const_1',\n",
       " 'import/dense/Tensordot/Prod',\n",
       " 'import/dense/Tensordot/Const',\n",
       " 'import/dense/Tensordot/GatherV2_1',\n",
       " 'import/dense/Tensordot/GatherV2_1/axis',\n",
       " 'import/dense/Tensordot/GatherV2',\n",
       " 'import/dense/Tensordot/GatherV2/axis',\n",
       " 'import/dense/Tensordot/Shape',\n",
       " 'import/dense/Tensordot/free',\n",
       " 'import/dense/Tensordot/axes',\n",
       " 'import/dense/bias/read',\n",
       " 'import/dense/bias',\n",
       " 'import/dense/kernel/read',\n",
       " 'import/dense/kernel',\n",
       " 'import/concat_4',\n",
       " 'import/concat_4/axis',\n",
       " 'import/ReverseV2_3',\n",
       " 'import/ReverseV2_3/axis',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/transpose_1',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/concat_2',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/concat_2/axis',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/concat_2/values_0',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/range_1',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/range_1/delta',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/range_1/start',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/Rank_1',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/TensorArrayStack/range',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/TensorArrayStack/range/delta',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/TensorArrayStack/range/start',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/Exit_2',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/NextIteration_4',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/NextIteration_3',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/NextIteration_2',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/NextIteration_1',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/NextIteration',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/add_1',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/add_1/y',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/mul',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/div',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/Floor',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/add',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/random_uniform',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/random_uniform/mul',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/random_uniform/sub',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/random_uniform/RandomUniform',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/random_uniform/max',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/random_uniform/min',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/Shape',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/dropout/keep_prob',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/lstm_cell/mul_2',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/lstm_cell/Tanh_1',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/lstm_cell/Sigmoid_2',\n",
       " 'import/bidirectional_rnn_word_1/bw/bw/while/lstm_cell/add_1',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.name for n in g.as_graph_def().node][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = g.get_tensor_by_name('import/transitions:0')\n",
    "w = g.get_tensor_by_name('import/Variable:0')\n",
    "e = g.get_tensor_by_name('import/depends/transitions:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = test_sess.run([q,w,e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21707, 128)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD',\n",
       " 'acl',\n",
       " 'advcl',\n",
       " 'advmod',\n",
       " 'amod',\n",
       " 'appos',\n",
       " 'aux',\n",
       " 'case',\n",
       " 'cc',\n",
       " 'ccomp',\n",
       " 'compound',\n",
       " 'compound:plur',\n",
       " 'conj',\n",
       " 'cop',\n",
       " 'csubj',\n",
       " 'csubj:pass',\n",
       " 'dep',\n",
       " 'det',\n",
       " 'fixed',\n",
       " 'flat',\n",
       " 'iobj',\n",
       " 'mark',\n",
       " 'nmod',\n",
       " 'nsubj',\n",
       " 'nsubj:pass',\n",
       " 'nummod',\n",
       " 'obj',\n",
       " 'obl',\n",
       " 'parataxis',\n",
       " 'punct',\n",
       " 'root',\n",
       " 'xcomp']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(idx2tag.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
